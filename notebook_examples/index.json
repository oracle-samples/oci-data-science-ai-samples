[
  {
    "developed_on": "automlx_p38_cpu_v2",
    "filename": "automlx-anomaly_detection.ipynb",
    "keywords": [
      "automlx",
      "anomaly detection"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_AnomalyDetection.ipynb",
    "size": 1817110,
    "summary": "Build an anomaly detection model using the experimental, fully unsupervised anomaly detection pipeline in Oracle AutoMLx for the public Credit Card Fraud dataset.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining an Anomaly Detector using AutoMLx - Experimental"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-classifier.ipynb",
    "keywords": [
      "automlx",
      "classification",
      "classifier"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Classification.ipynb",
    "size": 7045225,
    "summary": "Build a classifier using the Oracle AutoMLx tool and binary data set of Census income data.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining a Classifier using AutoMLx"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-fairness.ipynb",
    "keywords": [
      "automlx",
      "fairness"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Fairness.ipynb",
    "size": 5277687,
    "summary": "Develop a model and evaluate its fairness",
    "time_created": "2023-05-29T15:52:02",
    "title": "Fairness with AutoMLx"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-regression.ipynb",
    "keywords": [
      "automlx",
      "regression"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Regression.ipynb",
    "size": 7466599,
    "summary": "Build a regressor using Oracle AutoMLx and a pricing data set. Training options will be explored and the resulting AutoMLx models will be evaluated.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining a Regressor using AutoMLx"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-text_classification.ipynb",
    "keywords": [
      "automlx",
      "text classification",
      "text classifier"
    ],
    "license": "Universal Permissive License v 1.0.",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Classification_Text.ipynb",
    "size": 4614269,
    "summary": "build a classifier using the Oracle AutoMLx tool for the public 20newsgroup dataset",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining a Text Classifier using AutoMLx"
  },
  {
    "developed_on": "computervision_p37_cpu_v1",
    "filename": "audi-autonomous_driving-oracle_open_data.ipynb",
    "keywords": [
      "autonomous driving",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19650,
    "summary": "Download, process and display autonomous driving data, and map LiDAR data onto images.",
    "time_created": "2023-03-30T09:13:20",
    "title": "Audi Autonomous Driving Dataset Repository"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "big_data_service-(BDS)-livy.ipynb",
    "keywords": [
      "bds",
      "big data service",
      "livy"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 46207,
    "summary": "Work interactively with a BDS cluster using Livy and two different connection techniques, SparkMagic (for a notebook environment) and with REST.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Using Livy on the Big Data Service"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "read-write-big_data_service-(BDS).ipynb",
    "keywords": [
      "bds",
      "fsspec"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 21304,
    "summary": "Manage data using fsspec file system. Read and save data using pandas and pyarrow through fsspec file system.",
    "time_created": "2023-03-29T11:04:51",
    "title": "How to Read Data with fsspec from Oracle Big Data Service (BDS)"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "aqua-deploy-llm-byoc.ipynb",
    "keywords": [
      "byoc",
      "llm",
      "quick action",
      "deploy"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 22095,
    "summary": "Deploy and perform inferencing using AI Quick Action models.",
    "time_created": "2024-09-19T12:37:06",
    "title": "Deploy LLM Models using BYOC"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "use_of_cohere_embed_models_for_semantic_search_in_oci_opensearch.ipynb",
    "keywords": [
      "cohere",
      "OpenSearch",
      "RAG",
      "Retrieval Augmented Generative"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13485,
    "summary": "Set up a retrieval-augmented generative QA using OCI OpenSearch as a retriever.",
    "time_created": "2023-12-13T09:27:01",
    "title": "Retrieval Augmented Generative Question Answer Using OCI OpenSearch as Retriever"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "pyspark-data_catalog-hive_metastore-data_flow.ipynb",
    "keywords": [
      "data catalog metastore",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19211,
    "summary": "Write and test a Data Flow batch application using the Oracle Cloud Infrastructure (OCI) Data Catalog Metastore. Configure the job, run the application and clean up resources.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Using Data Catalog Metastore with DataFlow"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "data_labeling-text_classification.ipynb",
    "keywords": [
      "data labeling",
      "text classification"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 22443,
    "summary": "Use the Oracle Cloud Infrastructure (OCI) Data Labeling service to efficiently build enriched, labeled datasets for the purpose of accurately training AI/ML models. This notebook demonstrates operations that can be performed using the Advanced Data Science (ADS) Data Labeling module.",
    "time_created": "2023-03-30T10:01:38",
    "title": "Text Classification with Data Labeling Service Integration"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "pyspark-data_catalog-hive_metastore.ipynb",
    "keywords": [
      "dcat",
      "data catalog metastore",
      "pyspark"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 17252,
    "summary": "Configure and use PySpark to process data in the Oracle Cloud Infrastructure (OCI) Data Catalog metastore, including common operations like creating and loading data from the metastore.",
    "time_created": "2023-03-30T10:32:35",
    "title": "Using Data Catalog Metastore with PySpark"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_quickstart.ipynb",
    "keywords": [
      "feature store"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 28591,
    "summary": "Introduction to the Oracle Cloud Infrastructure Feature Store.Use feature store for feature ingestion        and feature querying",
    "time_created": "2023-12-28T23:07:47",
    "title": "Using feature store for feature ingestion and feature querying"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_embeddings.ipynb",
    "keywords": [
      "feature store",
      "llm",
      "embeddings"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 32540,
    "summary": "Feature store to store embeddings, version embeddings and time travel of embeddings.",
    "time_created": "2023-12-28T23:07:47",
    "title": "Using feature store for storage, retrieval, versioning and time travel of embeddings"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_pii_redaction_and_transformation.ipynb",
    "keywords": [
      "feature store",
      "querying"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 29015,
    "summary": "Use feature store to perform PII data redaction, summarization, translation using openai.",
    "time_created": "2023-12-28T23:07:47",
    "title": "Use feature store to perform PII data redaction, summarization, translation using openai"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_schema_evolution.ipynb",
    "keywords": [
      "feature store",
      "querying",
      "schema enforcement",
      "schema evolution"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 27955,
    "summary": "Perform Schema Enforcement and Schema Evolution in Feature Store when materialising the data.",
    "time_created": "2023-12-28T23:07:47",
    "title": "Schema Enforcement and Schema Evolution in Feature Store"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_spark_magic.ipynb",
    "keywords": [
      "feature store",
      "querying",
      "spark magic",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 21964,
    "summary": "Run Feature Store on interactive Spark workloads on a long lasting Data Flow Cluster.",
    "time_created": "2023-12-28T23:07:47",
    "title": "Data Flow Studio : Big Data Operations in Feature Store."
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_querying.ipynb",
    "keywords": [
      "feature store",
      "querying"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 41629,
    "summary": "Using feature store to transform, store and query your data using pandas like interface to query and join",
    "time_created": "2023-12-28T23:07:47",
    "title": "Feature store handling querying operations"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_medical_synthetic_data_openai.ipynb",
    "keywords": [
      "feature store",
      "querying",
      "synthetic data generation"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 29222,
    "summary": "Feature store quickstart guide to perform synthetic data generation using openai",
    "time_created": "2023-12-28T23:07:47",
    "title": "Using feature store for synthetic data generation using openai"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_embeddings_openai.ipynb",
    "keywords": [
      "feature store",
      "querying"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 32071,
    "summary": "Feature store quickstart guide to perform feature querying using pandas like interface for query and join.",
    "time_created": "2023-12-28T23:07:47",
    "title": "Using feature store for feature querying using pandas like interface for query and join"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_ehr_data.ipynb",
    "keywords": [
      "feature store",
      "querying"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 32148,
    "summary": "Feature store quickstart guide to perform feature querying using pandas like interface for query and join.",
    "time_created": "2023-12-28T23:07:47",
    "title": "Using feature store for feature querying using pandas like interface for query and join"
  },
  {
    "developed_on": "fspyspark32_p38_cpu_v3",
    "filename": "feature_store_streaming_data_frame.ipynb",
    "keywords": [
      "feature store",
      "querying",
      "streaming"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 24197,
    "summary": "Carrying out schema enforcement and schema evolution on Feature Store.",
    "time_created": "2024-01-02T04:45:29",
    "title": "Enhancing Real-time Capabilities: Streaming Use Cases in Feature Store."
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "train-register-deploy-other-frameworks.ipynb",
    "keywords": [
      "generic model",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 21046,
    "summary": "Train, register, and deploy a generic model",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a Generic Model"
  },
  {
    "developed_on": "pypgx2310_p38_cpu_v1",
    "filename": "graph_insight-autonomous_database.ipynb",
    "keywords": [
      "graph_insight",
      "autonomous_database"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 121386,
    "summary": "Access",
    "time_created": "2023-06-05T07:46:16",
    "title": "Bank Graph Example Notebook"
  },
  {
    "developed_on": "pytorch110_p38_cpu_v1",
    "filename": "train-register-deploy-huggingface-pipeline.ipynb",
    "keywords": [
      "huggingface",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 15957,
    "summary": "Train, register, and deploy a huggingface pipeline.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, register, and deploy HuggingFace Pipeline"
  },
  {
    "developed_on": "sklearnex202130_p37_cpu_v1",
    "filename": "accelerate-scikit_learn-with-intel_extension.ipynb",
    "keywords": [
      "intel",
      "intel extension",
      "scikit-learn",
      "scikit learn"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 9596,
    "summary": "Enhance performance of scikit-learn models using the Intel(R) oneAPI Data Analytics Library. Train a k-means model using both sklearn and the accelerated Intel library and compare performance.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Intel Extension for Scikit-Learn"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "big_data_service-(BDS)-kerberos.ipynb",
    "keywords": [
      "kerberos",
      "big data service",
      "bds"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19691,
    "summary": "Connect to Oracle Big Data services using Kerberos.",
    "time_created": "2023-03-27T11:14:06",
    "title": "Connect to Oracle Big Data Service"
  },
  {
    "developed_on": "pytorch21_p39_gpu_v1",
    "filename": "deploy-langchain-as-oci-data-science-model-deployment.ipynb",
    "keywords": [
      "langchain",
      "deploy model",
      "register model",
      "LLM"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 14166,
    "summary": "Deploy LangChain applications as OCI data science model deployment",
    "time_created": "2023-12-06T13:37:52",
    "title": "Deploy LangChain Application as OCI Data Science Model Deployment"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-forecasting.ipynb",
    "keywords": [
      "language services",
      "string manipulation",
      "regex",
      "regular expression",
      "natural language processing",
      "NLP",
      "part-of-speech tagging",
      "named entity recognition",
      "sentiment analysis",
      "custom plugins"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Forecasting.ipynb",
    "size": 5638148,
    "summary": "Use Oracle AutoMLx to build a forecast model with real-world data sets.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building a Forecaster using AutoMLx"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "natural_language_processing.ipynb",
    "keywords": [
      "language services",
      "string manipulation",
      "regex",
      "regular expression",
      "natural language processing",
      "NLP",
      "part-of-speech tagging",
      "named entity recognition",
      "sentiment analysis",
      "custom plugins"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 36063,
    "summary": "Use the ADS SDK to process and manipulate strings. This notebook includes regular expression matching and natural language (NLP) parsing, including part-of-speech tagging, named entity recognition, and sentiment analysis. It also shows how to create and use custom plugins specific to your specific needs.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Natural Language Processing"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "train-register-deploy-lightgbm.ipynb",
    "keywords": [
      "lightgbm",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12292,
    "summary": "Train, register, and deploy a LightGBM model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a LightGBM Model"
  },
  {
    "developed_on": "dbexp_p38_cpu_v1",
    "filename": "model_version_set.ipynb",
    "keywords": [
      "model",
      "model experiments",
      "model version set"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 20067,
    "summary": "A model version set is a way to track the relationships between models. As a container, the model version set takes a collection of models. Those models are assigned a sequential version number based on the order they are entered into the model version set.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Introduction to Model Version Set"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "model_evaluation-with-ADSEvaluator.ipynb",
    "keywords": [
      "model evaluation",
      "binary classification",
      "regression",
      "multi-class classification",
      "imbalanced dataset",
      "synthetic dataset"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 35837,
    "summary": "Train and evaluate different types of models: binary classification using an imbalanced dataset, multi-class classification using a synthetically generated dataset consisting of three equally distributed classes, and a regression using a synthetically generated dataset with positive targets.",
    "time_created": "2023-03-30T10:45:38",
    "title": "Model Evaluation with ADSEvaluator"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "text_classification-model_explanation-lime.ipynb",
    "keywords": [
      "nlp",
      "lime",
      "model_explanation",
      "text_classification",
      "text_explanation"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 16325,
    "summary": "Perform model explanations on an NLP classifier using the locally interpretable model explanations technique (LIME).",
    "time_created": "2023-03-30T10:32:35",
    "title": "Text Classification and Model Explanations using LIME"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "onnx-integration-ads.ipynb",
    "keywords": [
      "onnx",
      "deploy model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 15896,
    "summary": "Extract text from common formats (e.g. PDF and Word) into plain text. Customize this process for individual use cases.",
    "time_created": "2023-08-01T08:18:30",
    "title": "ONNX Integration with the Accelerated Data Science (ADS) SDK"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "pipelines-ml_lifecycle.ipynb",
    "keywords": [
      "pipelines",
      "pipeline step",
      "jobs pipeline"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 36402,
    "summary": "Create and use ML pipelines through the entire machine learning lifecycle",
    "time_created": "2023-03-26T22:51:01",
    "title": "Working with Pipelines"
  },
  {
    "developed_on": "pypgx2310_p38_cpu_v1",
    "filename": "pypgx-graph_analytics-machine_learning.ipynb",
    "keywords": [
      "pypgx",
      "graph analytics",
      "pgx"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 885240,
    "summary": "Use Oracle's Graph Analytics libraries to demonstrate graph algorithms, graph machine learning models, and use the property graph query language (PGQL)",
    "time_created": "2023-03-26T22:51:01",
    "title": "Graph Analytics and Graph Machine Learning with PyPGX"
  },
  {
    "developed_on": "pyspark24_p37_cpu_v3",
    "filename": "pyspark-data_flow-application.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 10021,
    "summary": "Develop local PySpark applications and work with remote clusters using Data Flow.",
    "time_created": "2023-06-02T14:57:56",
    "title": "PySpark"
  },
  {
    "developed_on": "pyspark32_p38_cpu_v2",
    "filename": "pyspark-data_flow_studio-introduction.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 144930,
    "summary": "Run interactive Spark workloads on a long lasting Oracle Cloud Infrastructure Data Flow Spark cluster through Apache Livy integration. Data Flow Spark Magic is used for interactively working with remote Spark clusters through Livy, a Spark REST server, in Jupyter notebooks. It includes a set of magic commands for interactively running Spark code.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Introduction to the Oracle Cloud Infrastructure Data Flow Studio"
  },
  {
    "developed_on": "pyspark32_p38_cpu_v1",
    "filename": "pyspark-data_flow_studio-spark_nlp.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 17270,
    "summary": "Demonstrates how to use Spark NLP within a long lasting Oracle Cloud Infrastructure Data Flow cluster.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Spark NLP within Oracle Cloud Infrastructure Data Flow Studio"
  },
  {
    "developed_on": "pytorch110_p38_cpu_v1",
    "filename": "train-register-deploy-pytorch.ipynb",
    "keywords": [
      "pytorch",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 708060,
    "summary": "Train, register, and deploy a PyTorch model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a PyTorch Model"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "aqua-batch-inferencing.ipynb",
    "keywords": [
      "quick action",
      "batch",
      "inferencing",
      "llm"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19594,
    "summary": "Perform batch inferencing on LLMs using AI Quick Actions.",
    "time_created": "2024-09-19T14:31:00",
    "title": "AI Quick Action - Batch inferencing"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "train-register-deploy-sklearn.ipynb",
    "keywords": [
      "scikit-learn",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12972,
    "summary": "Train, register, and deploy an scikit-learn model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, register, and deploy Sklearn Model"
  },
  {
    "developed_on": "dataexpl_p37_cpu_v3",
    "filename": "streaming-service-introduction.ipynb",
    "keywords": [
      "streaming",
      "kafka"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 97660,
    "summary": "Connect to Oracle Cloud Insfrastructure (OCI) Streaming service with kafka.",
    "time_created": "2023-03-30T10:32:35",
    "title": "Introduction to Streaming"
  },
  {
    "developed_on": "tensorflow28_p38_cpu_v1",
    "filename": "train-register-deploy-tensorflow.ipynb",
    "keywords": [
      "tensorflow",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 25991,
    "summary": "Train, register, and deploy a TensorFlow model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a TensorFlow Model"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "document-text_extraction.ipynb",
    "keywords": [
      "text extraction",
      "nlp"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 249672,
    "summary": "Extract text from common formats (e.g. PDF and Word) into plain text. Customize this process for individual use cases.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Text Extraction Using the Accelerated Data Science (ADS) SDK"
  },
  {
    "developed_on": "rapids2110_p37_gpu_v1",
    "filename": "xgboost-with-rapids.ipynb",
    "keywords": [
      "xgboost",
      "rapids",
      "gpu",
      "machine learning",
      "classification"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13296,
    "summary": "Compare training time between CPU and GPU trained models using XGBoost",
    "time_created": "2023-03-30T10:01:38",
    "title": "XGBoost with RAPIDS"
  },
  {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "train-register-deploy-xgboost.ipynb",
    "keywords": [
      "xgboost",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12075,
    "summary": "Train, register, and deploy an XGBoost model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy an XGBoost Model"
  },
    {
    "developed_on": "generalml_p311_cpu_x86_64_v1",
    "filename": "train-mysql-heatwave-deploy-xgboost.ipynb",
    "keywords": [
      "xgboost",
      "deploy model",
      "mysql heatwave",
      "linear regression",
      "random forest",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12075,
    "summary": "Train and Deploy an XGBoost Model for OCI MySQL Heatwave.",
    "time_created": "2025-02-19T22:51:01",
    "title": "Train and Deploy an XGBoost Model for OCI MySQL Heatwave."
  }
]
