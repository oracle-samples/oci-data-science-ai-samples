[
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "genome_visualization-oracle_open_data.ipynb",
        "keywords": [
            "object annotation",
            "genome visualization",
            "oracle open data"
        ],
        "license": "Universal Permissive License v 1.0 (https://oss.oracle.com/licenses/upl/)",
        "summary": "Load visual data, define regions, and visualize objects using metadata to connect structured images to language.",
        "title": "Visual Genome Repository"
    },
    {
        "developed_on": "nlp_p37_cpu_v2",
        "filename": "natural_language_processing.ipynb",
        "keywords": [
            "language services",
            "string manipulation",
            "regex",
            "regular expression",
            "natural language processing",
            "NLP",
            "part-of-speech tagging",
            "named entity recognition",
            "sentiment analysis",
            "custom plugins"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Use the ADS SDK to process and manipulate strings. This notebook includes regular expression matching and natural language (NLP) parsing, including part-of-speech tagging, named entity recognition, and sentiment analysis. It also shows how to create and use custom plugins specific to your specific needs.",
        "title": "Natural Language Processing"
    },
    {
        "developed_on": "rapids2110_p37_gpu_v1",
        "filename": "xgboost-with-rapids.ipynb",
        "keywords": [
            "xgboost",
            "rapids",
            "gpu",
            "machine learning",
            "classification"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Compare training time between CPU and GPU trained models using XGBoost.",
        "title": "XGBoost with RAPIDS"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "visualizing_data-exploring_data.ipynb",
        "keywords": [
            "data visualization",
            "seaborn plot",
            "charts"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Perform common data visualization tasks and explore data with the ADS SDK. Plotting approaches include 3D plots, pie chart, GIS plots, and Seaborn pairplot graphs.",
        "title": "Visualizing Data"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "sql_magic-commands-with-autonomous_database.ipynb",
        "keywords": [
            "sql magic",
            "autonomous database"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Use SQL Magic commands to work with a database within a Jupytyer notebook. This notebook shows how to to use both line and cell magics.",
        "title": "Introduction to SQL Magic"
    },
    {
        "developed_on": "pyspark30_p37_cpu_v5",
        "filename": "read-write-big_data_service-(BDS).ipynb",
        "keywords": [
            "bds",
            "fsspec"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Manage data using fsspec file system. Read and save data using pandas and pyarrow through fsspec file system.",
        "title": "How to Read Data with fsspec from Oracle Big Data Service (BDS)"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "train-register-deploy-sklearn.ipynb",
        "keywords": [
            "scikit-learn",
            "deploy model",
            "register model",
            "train model"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train, register, and deploy an scikit-learn model.",
        "title": "Train, register, and deploy Sklearn Model"
    },
    {
        "developed_on": "pyspark24_p37_cpu_v3",
        "filename": "pyspark-data_flow-application.ipynb",
        "keywords": [
            "pyspark",
            "data flow"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Develop local PySpark applications and work with remote clusters using Data Flow.",
        "title": "PySpark"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "train-register-deploy-xgboost.ipynb",
        "keywords": [
            "xgboost",
            "deploy model",
            "register model",
            "train model"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train, register, and deploy an XGBoost model.",
        "title": "Train, Register, and Deploy an XGBoost Model"
    },
    {
        "developed_on": "pyspark30_p37_cpu_v5",
        "filename": "pyspark-data_catalog-hive_metastore-data_flow.ipynb",
        "keywords": [
            "data catalog metastore",
            "data flow"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Write and test a Data Flow batch application using the Oracle Cloud Infrastructure (OCI) Data Catalog Metastore. Configure the job, run the application and clean up resources.",
        "title": "Using Data Catalog Metastore with DataFlow"
    },
    {
        "developed_on": "dataexpl_p37_cpu_v3",
        "filename": "streaming-service-introduction.ipynb",
        "keywords": [
            "streaming",
            "kafka"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Connect to Oracle Cloud Insfrastructure (OCI) Streaming service with kafka.",
        "title": "Introduction to Streaming"
    },
    {
        "developed_on": "dbexp_p38_cpu_v1",
        "filename": "model_version_set.ipynb",
        "keywords": [
            "model",
            "model experiments",
            "model version set"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "A model version set is a way to track the relationships between models. As a container, the model version set takes a collection of models. Those models are assigned a sequential version number based on the order they are entered into the model version set.",
        "title": "Introduction to Model Version Set"
    },
    {
        "developed_on": "tensorflow27_p37_cpu_v1",
        "filename": "train-register-deploy-tensorflow.ipynb",
        "keywords": [
            "tensorflow",
            "deploy model",
            "register model",
            "train model"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train, register, and deploy a TensorFlow model.",
        "title": "Train, Register, and Deploy a TensorFlow Model"
    },
    {
        "developed_on": "nlp_p37_cpu_v2",
        "filename": "data_labeling-text_classification.ipynb",
        "keywords": [
            "data labeling",
            "text classification"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Use the Oracle Cloud Infrastructure (OCI) Data Labeling service to efficiently build enriched, labeled datasets for the purpose of accurately training AI/ML models. This notebook demonstrates operations that can be performed using the Advanced Data Science (ADS) Data Labeling module.",
        "title": "Text Classification with Data Labeling Service Integration"
    },
    {
        "developed_on": "pyspark30_p37_cpu_v5",
        "filename": "big_data_service-(BDS)-livy.ipynb",
        "keywords": [
            "bds",
            "big data service",
            "livy"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Work interactively with a BDS cluster using Livy and two different connection techniques, SparkMagic (for a notebook environment) and with REST.",
        "title": "Using Livy on the Big Data Service"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "model_evaluation-with-ADSEvaluator.ipynb",
        "keywords": [
            "model evaluation",
            "binary classification",
            "regression",
            "multi-class classification",
            "imbalanced dataset",
            "synthetic dataset"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train and evaluate different types of models: binary classification using an imbalanced dataset, multi-class classification using a synthetically generated dataset consisting of three equally distributed classes, and a regression using a synthetically generated dataset with positive targets.",
        "title": "Model Evaluation with ADSEvaluator"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "api_keys-authentication.ipynb",
        "keywords": [
            "authentication",
            "api keys",
            "iam",
            "access management"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Configure and test API key authentication, attach keys to user account through Oracle's identity service, and test access to the API.",
        "title": "API Keys"
    },
    {
        "developed_on": "pyspark32_p38_cpu_v1",
        "filename": "pyspark-data_flow_studio-spark_nlp.ipynb",
        "keywords": [
            "pyspark",
            "data flow"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Demonstrates how to use Spark NLP within a long lasting Oracle Cloud Infrastructure Data Flow cluster.",
        "title": "Spark NLP within Oracle Cloud Infrastructure Data Flow Studio"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "train-register-deploy-lightgbm.ipynb",
        "keywords": [
            "lightgbm",
            "deploy model",
            "register model",
            "train model"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train, register, and deploy a LightGBM model.",
        "title": "Train, Register, and Deploy a LightGBM Model"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "caltech-pedestrian_detection-oracle_open_data.ipynb",
        "keywords": [
            "caltech",
            "pedestrian detection",
            "oracle open data"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Download and process annotated video data of vehicles and pedestrians.",
        "title": "Caltech Pedestrian Detection Benchmark Repository"
    },
    {
        "developed_on": "pyspark30_p37_cpu_v5",
        "filename": "pyspark-data_catalog-hive_metastore.ipynb",
        "keywords": [
            "dcat",
            "data catalog metastore",
            "pyspark"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Configure and use PySpark to process data in the Oracle Cloud Infrastructure (OCI) Data Catalog metastore, including common operations like creating and loading data from the metastore.",
        "title": "Using Data Catalog Metastore with PySpark"
    },
    {
        "developed_on": "pytorch110_p37_cpu_v1",
        "filename": "train-register-deploy-pytorch.ipynb",
        "keywords": [
            "pytorch",
            "deploy model",
            "register model",
            "train model"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train, register, and deploy a PyTorch model.",
        "title": "Train, Register, and Deploy a PyTorch Model"
    },
    {
        "developed_on": "nlp_p37_cpu_v2",
        "filename": "text_classification-model_explanation-lime.ipynb",
        "keywords": [
            "nlp",
            "lime",
            "model_explanation",
            "text_classification",
            "text_explanation"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Perform model explanations on an NLP classifier using the locally interpretable model explanations technique (LIME).",
        "title": "Text Classification and Model Explanations using LIME"
    },
    {
        "developed_on": "pyspark32_p38_cpu_v1",
        "filename": "pyspark-data_flow_studio-introduction.ipynb",
        "keywords": [
            "pyspark",
            "data flow"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Run interactive Spark workloads on a long lasting Oracle Cloud Infrastructure Data Flow Spark cluster through Apache Livy integration. Data Flow Spark Magic is used for interactively working with remote Spark clusters through Livy, a Spark REST server, in Jupyter notebooks. It includes a set of magic commands for interactively running Spark code.",
        "title": "Introduction to the Oracle Cloud Infrastructure Data Flow Studio"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "load_data-object_storage-hive-autonomous-database.ipynb",
        "keywords": [
            "loading data"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Load data from a variety of sources and in different formats. Sources include local storage, OCI storage, and different databases. Formats include Pandas DataFrames, parquet, excel, csv, and Python primitives.",
        "title": "Loading Data with DatasetFactory"
    },
    {
        "developed_on": "sklearnex202130_p37_cpu_v1",
        "filename": "accelerate-scikit_learn-with-intel_extension.ipynb",
        "keywords": [
            "intel",
            "intel extension",
            "scikit-learn",
            "scikit learn"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Enhance performance of scikit-learn models using the Intel(R) oneAPI Data Analytics Library. Train a k-means model using both sklearn and the accelerated Intel library and compare performance.",
        "title": "Intel Extension for Scikit-Learn"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "pipelines-ml_lifecycle.ipynb",
        "keywords": [
            "pipelines",
            "pipeline step",
            "jobs pipeline"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Create and use ML pipelines through the entire machine learning lifecycle",
        "title": "Working with Pipelines [Limited Availability]"
    },
    {
        "developed_on": "nlp_p37_cpu_v2",
        "filename": "document-text_extraction.ipynb",
        "keywords": [
            "text extraction",
            "nlp"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Extract text from common formats (e.g. PDF and Word) into plain text. Customize this process for individual use cases.",
        "title": "Text Extraction Using the Accelerated Data Science (ADS) SDK"
    },
    {
        "developed_on": "computervision_p37_cpu_v1",
        "filename": "audi-autonomous_driving-oracle_open_data.ipynb",
        "keywords": [
            "autonomous driving",
            "oracle open data"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Download, process and display autonomous driving data, and map LiDAR data onto images.",
        "title": "Audi Autonomous Driving Dataset Repository"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "hyperparameter_tuning.ipynb",
        "keywords": [
            "hyperparameter tuning"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Use ADSTuner to optimize an estimator using the scikit-learn API",
        "title": "Introduction to ADSTuner"
    },
    {
        "developed_on": "generalml_p37_cpu_v1",
        "filename": "train-register-deploy-other-frameworks.ipynb",
        "keywords": [
            "generic model",
            "deploy model",
            "register model",
            "train model"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Train, register, and deploy a generic model",
        "title": "Train, Register, and Deploy a Generic Model"
    },
    {
        "developed_on": "pyspark30_p37_cpu_v5",
        "filename": "big_data_service-(BDS)-kerberos.ipynb",
        "keywords": [
            "kerberos",
            "big data service",
            "bds"
        ],
        "license": "Universal Permissive License v 1.0",
        "summary": "Connect to Oracle Big Data services using Kerberos.",
        "title": "Connect to Oracle Big Data Service"
    }
]