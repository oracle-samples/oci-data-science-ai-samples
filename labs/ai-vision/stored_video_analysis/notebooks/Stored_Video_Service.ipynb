{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222552d2",
   "metadata": {},
   "source": [
    "\n",
    "# <b>Stored Video Service Demo</b>\n",
    "\n",
    "\n",
    "The Vision Service now offers Stored Video Processing. This notebook aims to provide overall clarity about the Stored Video features to the user in terms of requirements and usage.\n",
    "<ul>\n",
    "    <li><font size=\"2\">The output response file is stored at the object storage location specified in the below cells.</font></li>\n",
    "    <li><font size=\"2\">At the end of the notebook the response is downloaded and saved as <code>video_response.json</code> in the current directory. </font></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c0dd4",
   "metadata": {},
   "source": [
    "### Steps to run the notebook:\n",
    "- Notebook session setup\n",
    "    - Installing the OCI Python SDK.\n",
    "    - Setup sample input video.\n",
    "    - Setup helper functions.\n",
    "- Importing the required modules\n",
    "- Setting the input variables\n",
    "    - The user can give input variables of their choice.\n",
    "- Running the main pipeline\n",
    "    - Run all cells to get the output in the current directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba246b2",
   "metadata": {},
   "source": [
    "### Notebook session setup\n",
    "<details>\n",
    "    <summary>Instructions</summary>\n",
    "    <ul>\n",
    "        <li><font size=\"2\">The user needs to setup only once.</font></li>\n",
    "        <li><font size=\"2\">Uncomment the commented cells and run once to setup.</font></li>\n",
    "        <li><font size=\"2\">Comment back the same cells to avoid running again.</font></li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f89d12",
   "metadata": {},
   "source": [
    "#### Installing the OCI Python SDK\n",
    "Make sure to finish lab prerequisites and have access to SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use pip/pip3 as per availability\n",
    "# !pip3 install --trusted-host=artifactory.oci.oraclecorp.com -i https://artifactory.oci.oraclecorp.com/api/pypi/global-dev-pypi/simple -U oci==2.115.2+preview.1.1678"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca395d",
   "metadata": {},
   "source": [
    "#### Setup sample input\n",
    "\n",
    "* Uncomment and run the cell below.\n",
    "* User can create a bucket in their tenancy (user may skip this step if they have an existing bucket).\n",
    "* Upload the video `demo.mp4` to the bucket (user can also upload and use the video of their choice).\n",
    "* Input video limits and requirements\n",
    "    - Input video can be of format \".mov\", \".mp4\", \".h264\", \".mkv\", or \".webm\"\n",
    "    - Maximum length of the input video is 1hr\n",
    "    - Maximum size of the input video is 20 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a94b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://raw.githubusercontent.com/oracle-samples/oci-data-science-ai-samples/main/labs/ai-vision/analyze_video_workshop/data/demo.mp4\"\n",
    "# !mkdir data\n",
    "# !mv demo.mp4 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4277c4",
   "metadata": {},
   "source": [
    "#### Setup helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://raw.githubusercontent.com/oracle-samples/oci-data-science-ai-samples/main/labs/ai-vision/analyze_video_workshop/helper/analyze_video_utils.py\"\n",
    "# !mkdir helper\n",
    "# !mv analyze_video_utils.py helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a46d5e",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12753a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import oci\n",
    "import json\n",
    "from oci.ai_vision.models import *\n",
    "from helper.analyze_video_utils import display_formatted_response\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4dd46",
   "metadata": {},
   "source": [
    "#### Authorize OCI config\n",
    "Set up authentication for OCI by reading configuration from a file. The default configuration file location is ```~/.oci/config``` and ```DEFAULT``` profile is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = oci.config.from_file('~/.oci/config', profile_name='DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f561b1",
   "metadata": {},
   "source": [
    "#### Set required input variables\n",
    "- **input_location_path:**\n",
    "    The user needs to provide the following details:\n",
    "    - <code>namespace</code> : specify the namespace where the input video is uploaded.\n",
    "    - <code>bucket</code> : specify the bucket name where the input video is uploaded.\n",
    "    - <code>filename</code> : specify the filename of the input video (e.g: we have uploaded <code>demo.mp4</code> in <code>Setup sample input</code> step).\n",
    "- **output_location_path:**\n",
    "    The user needs to provide the following details to store the output:\n",
    "    - <code>namespace</code> : specify the namespace where the output has to be stored.\n",
    "    - <code>bucket</code> : specify the bucket name where the output has to be stored.\n",
    "    - <code>prefix</code> : specify the prefix where the output has to be stored.\n",
    "- **compartment_id:**\n",
    "    The user should provide the compartment OCID to call the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_namespace = \"<INPUT_NAMESPACE>\"\n",
    "input_bucket = \"<INPUT_BUCKET>\"\n",
    "input_filename = \"<INPUT_FILENAME>\"\n",
    "\n",
    "output_namespace = \"<OUTPUT_NAMESPACE>\"\n",
    "output_bucket = \"<OUTPUT_BUCKET>\"\n",
    "output_prefix = \"<OUTPUT_PREFIX>\"\n",
    "\n",
    "compartment_id = \"<COMPARTMENT_ID>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce24213",
   "metadata": {},
   "source": [
    "#### Set optional input variables\n",
    "- **max_results:**\n",
    "    Provide the maximum results needed for Object, Label and Face Detection. This is an upper limit over the output classes, the API may detect lesser classes according to the input video. Default value is 20.\n",
    "- **min_confidence:**\n",
    "    Provide the minimum confidence needed for the feature, between 0 and 1. This is an lower limit over the output, the API may detect objects and classes above the specified confidence. Default value is 0.35f. \n",
    "- **is_landmark_required:**\n",
    "    Provide whether the landmark details for the face is required or not. Landmarks are the key points representing regions on the face. Default value is False.\n",
    "- **model_id:**\n",
    "    In case of custom models uncomment the line and provide the model OCID needed for Custom Label Detection and Object Detection features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2325fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results = 5\n",
    "\n",
    "min_confidence = 0\n",
    "\n",
    "is_landmark_required = False\n",
    "\n",
    "# od_model_id = \"<Object Detection MODEL_ID>\"\n",
    "# ld_model_id = \"<Label Detection MODEL_ID>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4c1dd",
   "metadata": {},
   "source": [
    "#### Setup input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf14ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_location_1 = ObjectLocation()\n",
    "object_location_1.namespace_name = input_namespace\n",
    "object_location_1.bucket_name = input_bucket\n",
    "object_location_1.object_name = input_filename\n",
    "object_locations = [object_location_1]\n",
    "input_location = ObjectListInlineInputLocation()\n",
    "input_location.object_locations = object_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcec9f",
   "metadata": {},
   "source": [
    "#### Setup output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = OutputLocation()\n",
    "output_location.namespace_name = output_namespace\n",
    "output_location.bucket_name = output_bucket\n",
    "output_location.prefix = output_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca5761",
   "metadata": {},
   "source": [
    "### Create AIServiceVisionClient and Setup input features for Stored Video Processing\n",
    "User can specify the features they want to call. In the below code all supported pretrained models are called. To call custom models uncomment commented lines and replace corresponding model id for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_service_vision_client = oci.ai_vision.AIServiceVisionClient(config=config)\n",
    "\n",
    "video_label_detection_feature = VideoLabelDetectionFeature()\n",
    "video_label_detection_feature.max_results = max_results\n",
    "video_label_detection_feature.min_confidence = min_confidence\n",
    "# video_label_detection_feature.model_id = ld_model_id\n",
    "\n",
    "video_object_detection_feature = VideoObjectDetectionFeature()\n",
    "video_object_detection_feature.max_results = max_results\n",
    "video_object_detection_feature.min_confidence = min_confidence\n",
    "# video_object_detection_feature.model_id = od_model_id\n",
    "\n",
    "video_text_detection_feature = VideoTextDetectionFeature()\n",
    "video_text_detection_feature.min_confidence = min_confidence\n",
    "\n",
    "video_face_detection_feature = VideoFaceDetectionFeature()\n",
    "video_face_detection_feature.max_results = max_results\n",
    "video_face_detection_feature.min_confidence = min_confidence\n",
    "video_face_detection_feature.is_landmark_required = is_landmark_required\n",
    "\n",
    "features = [video_label_detection_feature, \n",
    "            video_object_detection_feature, \n",
    "            video_text_detection_feature, \n",
    "            video_face_detection_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59ec19",
   "metadata": {},
   "source": [
    "### Create video job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video_job_details = CreateVideoJobDetails()\n",
    "create_video_job_details.features = features\n",
    "create_video_job_details.compartment_id = compartment_id\n",
    "create_video_job_details.output_location = output_location\n",
    "create_video_job_details.input_location = input_location\n",
    "\n",
    "res = ai_service_vision_client.create_video_job(create_video_job_details=create_video_job_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb3c3e",
   "metadata": {},
   "source": [
    "### Job submitted\n",
    "The job is created and should be in <code>ACCEPTED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1423b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(display_formatted_response(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f153e0",
   "metadata": {},
   "source": [
    "#### Job IN_PROGRESS\n",
    "The job progress is tracked till completion with a polling interval of 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a695df",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = res.data.id\n",
    "polling_interval = 5\n",
    "print(\"Job ID :\", job_id, '\\n')\n",
    "seconds = 0\n",
    "while res.data.lifecycle_state == \"IN_PROGRESS\" or res.data.lifecycle_state == \"ACCEPTED\":\n",
    "    print(f\"Job {job_id} is IN_PROGRESS for {str(seconds)} seconds, progress: {res.data.percent_complete}\")\n",
    "    time.sleep(polling_interval)\n",
    "    seconds += polling_interval\n",
    "    res = ai_service_vision_client.get_video_job(video_job_id=job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db11dc",
   "metadata": {},
   "source": [
    "### Job completed\n",
    "The job is completed and should be in <code>SUCCEEDED</code> state. In case the job is not in <code>SUCCEEDED</code> state refer to the displayed response below to know the state and reason. Possible job states are <code>PARTIALLY SUCCEEDED</code> and <code>FAILED</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec073627",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(display_formatted_response(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba42d96",
   "metadata": {},
   "source": [
    "#### Get response json from object storage\n",
    "The output can be found in the output location specified or it can be saved in ```video_response.json``` file by running the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "output_object_name = f\"{output_location.prefix}/{job_id}/{input_location.object_locations[0].object_name}.json\"\n",
    "\n",
    "video_response = object_storage_client.get_object(output_location.namespace_name, output_location.bucket_name, output_object_name)\n",
    "\n",
    "response = json.dumps(video_response.data.text, indent=4)\n",
    "file = open('video_response.json', 'w')\n",
    "file.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
