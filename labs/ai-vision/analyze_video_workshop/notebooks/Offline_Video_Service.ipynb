{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222552d2",
   "metadata": {},
   "source": [
    "\n",
    "# <b>Offline Video Service Demo</b>\n",
    "\n",
    "\n",
    "The AIServiceVisionClient offers the video features. This notebook aims to provide overall clarity about the features to the user in terms of requirements, usage.\n",
    "<ul>\n",
    "    <li><font size=\"2\">The output response file is stored at the object storage location specified in the below cells.</font></li>\n",
    "    <li><font size=\"2\">At the end of the notebook the response is downloaded and saved as <code>video_response.json</code> in the output directory. </font></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbd40c",
   "metadata": {},
   "source": [
    "### Steps to run the notebook:\n",
    "<details>\n",
    "    <summary>Notebook session setup</summary>\n",
    "    <ol>\n",
    "        <li><font size=\"2\">Installing the OCI SDK</font></li>\n",
    "        <li><font size=\"2\">Installing other dependencies</font></li>\n",
    "        <li><font size=\"2\">Setup sample input images</font></li>\n",
    "        <li><font size=\"2\">Create output folder</font></li>\n",
    "        <li><font size=\"2\">Setup helper .py files</font></li>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Importing the required modules</summary>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Setting the input variables</summary>\n",
    "     <font size=\"2\">The user can give input variables of their choice.</font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Running the main pipeline</summary>\n",
    "    <font size=\"2\">Run all cells to get the output in the <code>output</code> directory. </font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba246b2",
   "metadata": {},
   "source": [
    "### Notebook session setup\n",
    "<details>\n",
    "    <summary>Instructions</summary>\n",
    "    <ul>\n",
    "        <li><font size=\"2\">The user needs to setup only once.</font></li>\n",
    "        <li><font size=\"2\">Uncomment the commented cells and run once to setup.</font></li>\n",
    "        <li><font size=\"2\">Comment back the same cells to avoid running again.</font></li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f89d12",
   "metadata": {},
   "source": [
    "#### Installing the OCI Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use pip/pip3 as per availability\n",
    "# !pip3 install --trusted-host=artifactory.oci.oraclecorp.com -i https://artifactory.oci.oraclecorp.com/api/pypi/global-dev-pypi/simple -U oci==2.115.2+preview.1.1678"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca395d",
   "metadata": {},
   "source": [
    "#### Setup sample input\n",
    "\n",
    "* Uncomment and run the cell below.\n",
    "* Create a bucket in your tenancy (you may skip this step if you have an existing bucket)\n",
    "* Upload the video `demo.mp4` to the bucket. (you can also upload and use the video of your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a94b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/labs/ai-vision/analyze_video_workshop/data/demo.mp4\"\n",
    "# !mkdir data\n",
    "# !mv demo.mp4 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4277c4",
   "metadata": {},
   "source": [
    "#### Setup helper.py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/labs/ai-vision/analyze_video_workshop/helper/analyze_video_utils.py\"\n",
    "# !mkdir helper\n",
    "# !mv analyze_video_utils.py helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a46d5e",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12753a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import oci\n",
    "from helper.analyze_video_utils import clean_output\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4dd46",
   "metadata": {},
   "source": [
    "#### Authorize OCI config\n",
    "Set up authentication for OCI by reading configuration from a file. The default configuration file location is ```~/.oci/config```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = oci.config.from_file('~/.oci/config')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f561b1",
   "metadata": {},
   "source": [
    "#### Set input variables\n",
    "<details>\n",
    "    <summary><font size=\"3\">input_location_variables</font></summary>\n",
    "    <font size=\"2\">The user needs to provide the following details:\n",
    "        <ul>\n",
    "            <li><code>namespace</code> : specify the namespace where the input video is uploaded</li>\n",
    "            <li><code>bucket</code> : specify the bucket name where the input video is uploaded</li>\n",
    "            <li><code>filename</code> : specify the filename of the input video(e.g: we have uploaded <code>demo.mp4</code> in <code>Setup sample input</code> step )</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\">output_location_path</font></summary>\n",
    "    <font size=\"2\">The user needs to provide the following details to store the output:\n",
    "        <ul>\n",
    "            <li><code>namespace</code> : specify the namespace where the output has to be stored</li>\n",
    "            <li><code>bucket</code> : specify the bucket name where the output has to be stored</li>\n",
    "            <li><code>prefix</code> : specify the prefix where the output has to be stored</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">compartment_id</font></summary>\n",
    "    <font size=\"2\">The user should provide the compartment OCID to call the API.</font><br>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">max_results</font></summary>\n",
    "    <font size=\"2\">Provide the maximum number of results needed for image classification. This is an upper limit over the output classes, the API may detect lesser classes according to the image.</font><br>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">min_confindence</font></summary>\n",
    "    <font size=\"2\">Provide the minimum confidence needed for the feature. This is an lower limit over the output, the API may detect objects and classes above the specified confidence.</font><br>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">model_id</font></summary>\n",
    "    <font size=\"2\">In case of custom models uncomment the line and provide the model_id needed for the feature.</font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_namespace = \"<INPUT_NAMESPACE>\"\n",
    "input_bucket = \"<INPUT_BUCKET>\"\n",
    "input_filename = \"<INPUT_FILENAME>\"\n",
    "\n",
    "output_namespace = \"<OUTPUT_NAMESPACE>\"\n",
    "output_bucket = \"<OUTPUT_BUCKET>\"\n",
    "output_prefix = \"<OUTPUT_PREFIX>\"\n",
    "\n",
    "compartment_id = \"<COMPARTMENT_ID>\"\n",
    "\n",
    "max_results = 5\n",
    "\n",
    "min_confidence = 0 \n",
    "\n",
    "# model_id = \"<MODEL_ID>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4c1dd",
   "metadata": {},
   "source": [
    "#### Setup input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf14ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_location_1 = ObjectLocation()\n",
    "object_location_1.namespace_name = input_namespace\n",
    "object_location_1.bucket_name = input_bucket\n",
    "object_location_1.object_name = input_filename\n",
    "object_locations = [object_location_1]\n",
    "input_location = ObjectListInlineInputLocation()\n",
    "input_location.object_locations = object_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcec9f",
   "metadata": {},
   "source": [
    "#### Setup output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = OutputLocation()\n",
    "output_location.namespace_name = output_namespace\n",
    "output_location.bucket_name = output_bucket\n",
    "output_location.prefix = output_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca5761",
   "metadata": {},
   "source": [
    "### Create AI service vision client and Setup input feature for Offline video features\n",
    "You can specify the features you want to call. In the below code we are calling all the features. Uncomment commented lines in case of custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_service_vision_client = oci.ai_vision.AIServiceVisionClient(config=config)\n",
    "\n",
    "video_label_detection_feature = VideoLabelDetectionFeature()\n",
    "video_label_detection_feature.max_results = max_results\n",
    "video_label_detection_feature.min_confidence = min_confidence\n",
    "# video_label_detection_feature.model_id = model_id\n",
    "\n",
    "video_object_detection_feature = VideoObjectDetectionFeature()\n",
    "video_object_detection_feature.max_results = max_results\n",
    "video_object_detection_feature.min_confidence = min_confidence\n",
    "# video_object_detection_feature.model_id = model_id\n",
    "\n",
    "video_text_detection_feature = VideoTextDetectionFeature()\n",
    "video_text_detection_feature.max_results = max_results\n",
    "video_text_detection_feature.min_confidence = min_confidence\n",
    "\n",
    "video_face_detection_feature = VideoFaceDetectionFeature()\n",
    "video_face_detection_feature.max_results = max_results\n",
    "video_face_detection_feature.min_confidence = min_confidence\n",
    "\n",
    "features = [video_label_detection_feature, \n",
    "            video_object_detection_feature, \n",
    "            video_text_detection_feature, \n",
    "            video_face_detection_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59ec19",
   "metadata": {},
   "source": [
    "### Create video job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video_job_details = CreateVideoJobDetails()\n",
    "create_video_job_details.features = features\n",
    "create_video_job_details.compartment_id = compartment_id\n",
    "create_video_job_details.output_location = output_location\n",
    "create_video_job_details.input_location = input_location\n",
    "\n",
    "res = ai_service_vision_client.create_video_job(create_video_job_details=create_video_job_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb3c3e",
   "metadata": {},
   "source": [
    "### Job submitted\n",
    "The job is created and is in <code>ACCEPTED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1423b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_json = json.loads(repr(res.data))\n",
    "clean_res = clean_output(res_json)\n",
    "JSON(clean_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f153e0",
   "metadata": {},
   "source": [
    "#### Job in progress\n",
    "The job progress is tracked till completion with an interval of 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a695df",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = res.data.id\n",
    "print(\"Job ID :\", job_id, '\\n')\n",
    "seconds = 0\n",
    "while res.data.lifecycle_state == \"IN_PROGRESS\" or res.data.lifecycle_state == \"ACCEPTED\":\n",
    "    print(f\"Job {job_id} is IN_PROGRESS for {str(seconds)} seconds, progress: {res.data.percent_complete}\")\n",
    "    time.sleep(5)\n",
    "    seconds += 5\n",
    "    res = ai_service_vision_client.get_video_job(video_job_id=job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db11dc",
   "metadata": {},
   "source": [
    "### Job completed\n",
    "The job is completed and is in <code>SUCCEEDED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec073627",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_json = json.loads(repr(res.data))\n",
    "clean_res = clean_output(res_json)\n",
    "JSON(clean_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba42d96",
   "metadata": {},
   "source": [
    "#### Get response json from object storage\n",
    "The output can be found in the output location specified or it can be saved in ```video_response.json``` file by running the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "output_object_name = f\"{output_location.prefix}/{job_id}/{input_location.object_name}.json\"\n",
    "\n",
    "video_response = object_storage_client.get_object(output_location.namespace_name, output_location.bucket_name, output_object_name)\n",
    "\n",
    "file = open('video_response.json', 'w')\n",
    "file.write(video_response.data.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
