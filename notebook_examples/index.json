[
  {
    "developed_on": "computervision_p37_cpu_v1",
    "filename": "audi-autonomous_driving-oracle_open_data.ipynb",
    "keywords": [
      "autonomous driving",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19670,
    "summary": "Download, process and display autonomous driving data, and map LiDAR data onto images.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Audi Autonomous Driving Dataset Repository"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "read-write-big_data_service-(BDS).ipynb",
    "keywords": [
      "bds",
      "fsspec"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 21291,
    "summary": "Manage data using fsspec file system. Read and save data using pandas and pyarrow through fsspec file system.",
    "time_created": "2022-12-22T14:27:22",
    "title": "How to Read Data with fsspec from Oracle Big Data Service (BDS)"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "big_data_service-(BDS)-livy.ipynb",
    "keywords": [
      "bds",
      "big data service",
      "livy"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 46207,
    "summary": "Work interactively with a BDS cluster using Livy and two different connection techniques, SparkMagic (for a notebook environment) and with REST.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Using Livy on the Big Data Service"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "caltech-pedestrian_detection-oracle_open_data.ipynb",
    "keywords": [
      "caltech",
      "pedestrian detection",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 15206,
    "summary": "Download and process annotated video data of vehicles and pedestrians.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Caltech Pedestrian Detection Benchmark Repository"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "pyspark-data_catalog-hive_metastore-data_flow.ipynb",
    "keywords": [
      "data catalog metastore",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19211,
    "summary": "Write and test a Data Flow batch application using the Oracle Cloud Infrastructure (OCI) Data Catalog Metastore. Configure the job, run the application and clean up resources.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Using Data Catalog Metastore with DataFlow"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "data_labeling-text_classification.ipynb",
    "keywords": [
      "data labeling",
      "text classification"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 22463,
    "summary": "Use the Oracle Cloud Infrastructure (OCI) Data Labeling service to efficiently build enriched, labeled datasets for the purpose of accurately training AI/ML models. This notebook demonstrates operations that can be performed using the Advanced Data Science (ADS) Data Labeling module.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Text Classification with Data Labeling Service Integration"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "visualizing_data-exploring_data.ipynb",
    "keywords": [
      "data visualization",
      "seaborn plot",
      "charts"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 20724,
    "summary": "Perform common data visualization tasks and explore data with the ADS SDK. Plotting approaches include 3D plots, pie chart, GIS plots, and Seaborn pairplot graphs.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Visualizing Data"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "pyspark-data_catalog-hive_metastore.ipynb",
    "keywords": [
      "dcat",
      "data catalog metastore",
      "pyspark"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 17260,
    "summary": "Configure and use PySpark to process data in the Oracle Cloud Infrastructure (OCI) Data Catalog metastore, including common operations like creating and loading data from the metastore.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Using Data Catalog Metastore with PySpark"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-other-frameworks.ipynb",
    "keywords": [
      "generic model",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 44631,
    "summary": "Train, register, and deploy a generic model",
    "time_created": "2022-12-22T14:27:22",
    "title": "Train, Register, and Deploy a Generic Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "hyperparameter_tuning.ipynb",
    "keywords": [
      "hyperparameter tuning"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 24714,
    "summary": "Use ADSTuner to optimize an estimator using the scikit-learn API",
    "time_created": "2022-12-22T14:27:22",
    "title": "Introduction to ADSTuner"
  },
  {
    "developed_on": "sklearnex202130_p37_cpu_v1",
    "filename": "accelerate-scikit_learn-with-intel_extension.ipynb",
    "keywords": [
      "intel",
      "intel extension",
      "scikit-learn",
      "scikit learn"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 9596,
    "summary": "Enhance performance of scikit-learn models using the Intel(R) oneAPI Data Analytics Library. Train a k-means model using both sklearn and the accelerated Intel library and compare performance.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Intel Extension for Scikit-Learn"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "big_data_service-(BDS)-kerberos.ipynb",
    "keywords": [
      "kerberos",
      "big data service",
      "bds"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19682,
    "summary": "Connect to Oracle Big Data services using Kerberos.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Connect to Oracle Big Data Service"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "natural_language_processing.ipynb",
    "keywords": [
      "language services",
      "string manipulation",
      "regex",
      "regular expression",
      "natural language processing",
      "NLP",
      "part-of-speech tagging",
      "named entity recognition",
      "sentiment analysis",
      "custom plugins"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 36063,
    "summary": "Use the ADS SDK to process and manipulate strings. This notebook includes regular expression matching and natural language (NLP) parsing, including part-of-speech tagging, named entity recognition, and sentiment analysis. It also shows how to create and use custom plugins specific to your specific needs.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Natural Language Processing"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-lightgbm.ipynb",
    "keywords": [
      "lightgbm",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12453,
    "summary": "Train, register, and deploy a LightGBM model.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Train, Register, and Deploy a LightGBM Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "load_data-object_storage-hive-autonomous-database.ipynb",
    "keywords": [
      "loading data",
      "autonomous database",
      "adw",
      "hive",
      "pandas",
      "dask",
      "object storage"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 10007,
    "summary": "Load data from sources including ADW, Object Storage, and Hive in formats like parquet, csv etc",
    "time_created": "2023-01-09T10:44:59",
    "title": "Loading Data With Pandas & Dask"
  },
  {
    "developed_on": "dbexp_p38_cpu_v1",
    "filename": "model_version_set.ipynb",
    "keywords": [
      "model",
      "model experiments",
      "model version set"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 20067,
    "summary": "A model version set is a way to track the relationships between models. As a container, the model version set takes a collection of models. Those models are assigned a sequential version number based on the order they are entered into the model version set.",
    "time_created": "2023-02-03T15:20:55",
    "title": "Introduction to Model Version Set"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "model_evaluation-with-ADSEvaluator.ipynb",
    "keywords": [
      "model evaluation",
      "binary classification",
      "regression",
      "multi-class classification",
      "imbalanced dataset",
      "synthetic dataset"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 35858,
    "summary": "Train and evaluate different types of models: binary classification using an imbalanced dataset, multi-class classification using a synthetically generated dataset consisting of three equally distributed classes, and a regression using a synthetically generated dataset with positive targets.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Model Evaluation with ADSEvaluator"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "text_classification-model_explanation-lime.ipynb",
    "keywords": [
      "nlp",
      "lime",
      "model_explanation",
      "text_classification",
      "text_explanation"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 16346,
    "summary": "Perform model explanations on an NLP classifier using the locally interpretable model explanations technique (LIME).",
    "time_created": "2022-12-22T14:27:22",
    "title": "Text Classification and Model Explanations using LIME"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "genome_visualization-oracle_open_data.ipynb",
    "keywords": [
      "object annotation",
      "genome visualization",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0 (https://oss.oracle.com/licenses/upl/)",
    "size": 14759,
    "summary": "Load visual data, define regions, and visualize objects using metadata to connect structured images to language.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Visual Genome Repository"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "pipelines-ml_lifecycle.ipynb",
    "keywords": [
      "pipelines",
      "pipeline step",
      "jobs pipeline"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 36342,
    "summary": "Create and use ML pipelines through the entire machine learning lifecycle",
    "time_created": "2023-02-03T15:20:55",
    "title": "Working with Pipelines"
  },
  {
    "developed_on": "pyspark32_p38_cpu_v1",
    "filename": "pyspark-data_flow_studio-spark_nlp.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 17270,
    "summary": "Demonstrates how to use Spark NLP within a long lasting Oracle Cloud Infrastructure Data Flow cluster.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Spark NLP within Oracle Cloud Infrastructure Data Flow Studio"
  },
  {
    "developed_on": "pyspark32_p38_cpu_v2",
    "filename": "pyspark-data_flow_studio-introduction.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 144930,
    "summary": "Run interactive Spark workloads on a long lasting Oracle Cloud Infrastructure Data Flow Spark cluster through Apache Livy integration. Data Flow Spark Magic is used for interactively working with remote Spark clusters through Livy, a Spark REST server, in Jupyter notebooks. It includes a set of magic commands for interactively running Spark code.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Introduction to the Oracle Cloud Infrastructure Data Flow Studio"
  },
  {
    "developed_on": "pyspark24_p37_cpu_v3",
    "filename": "pyspark-data_flow-application.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13104,
    "summary": "Develop local PySpark applications and work with remote clusters using Data Flow.",
    "time_created": "2022-12-22T14:27:22",
    "title": "PySpark"
  },
  {
    "developed_on": "pytorch110_p38_cpu_v1",
    "filename": "train-register-deploy-pytorch.ipynb",
    "keywords": [
      "pytorch",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 708226,
    "summary": "Train, register, and deploy a PyTorch model.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Train, Register, and Deploy a PyTorch Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-sklearn.ipynb",
    "keywords": [
      "scikit-learn",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13067,
    "summary": "Train, register, and deploy an scikit-learn model.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Train, register, and deploy Sklearn Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "sql_magic-commands-with-autonomous_database.ipynb",
    "keywords": [
      "sql magic",
      "autonomous database"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13065,
    "summary": "Use SQL Magic commands to work with a database within a Jupyter notebook. This notebook shows how to to use both line and cell magics.",
    "time_created": "2023-02-02T01:32:19",
    "title": "Introduction to SQL Magic"
  },
  {
    "developed_on": "dataexpl_p37_cpu_v3",
    "filename": "streaming-service-introduction.ipynb",
    "keywords": [
      "streaming",
      "kafka"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 97679,
    "summary": "Connect to Oracle Cloud Insfrastructure (OCI) Streaming service with kafka.",
    "time_created": "2023-01-02T01:25:36",
    "title": "Introduction to Streaming"
  },
  {
    "developed_on": "tensorflow28_p38_cpu_v1",
    "filename": "train-register-deploy-tensorflow.ipynb",
    "keywords": [
      "tensorflow",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 26241,
    "summary": "Train, register, and deploy a TensorFlow model.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Train, Register, and Deploy a TensorFlow Model"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "document-text_extraction.ipynb",
    "keywords": [
      "text extraction",
      "nlp"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 249672,
    "summary": "Extract text from common formats (e.g. PDF and Word) into plain text. Customize this process for individual use cases.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Text Extraction Using the Accelerated Data Science (ADS) SDK"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-xgboost.ipynb",
    "keywords": [
      "xgboost",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12159,
    "summary": "Train, register, and deploy an XGBoost model.",
    "time_created": "2022-12-22T14:27:22",
    "title": "Train, Register, and Deploy an XGBoost Model"
  },
  {
    "developed_on": "rapids2110_p37_gpu_v1",
    "filename": "xgboost-with-rapids.ipynb",
    "keywords": [
      "xgboost",
      "rapids",
      "gpu",
      "machine learning",
      "classification"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13315,
    "summary": "Compare training time between CPU and GPU trained models using XGBoost",
    "time_created": "2022-12-22T14:27:22",
    "title": "XGBoost with RAPIDS"
  }
]