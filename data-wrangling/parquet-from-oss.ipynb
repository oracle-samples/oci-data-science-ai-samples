{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da99b91",
   "metadata": {},
   "source": [
    "## Reading/Writing Parquet Files From/to OCI Object Storage with Pandas\n",
    "\n",
    "The setup for this notebook is simple. I used the `generalml_p37_cpu_v1` conda environment. This environment has ADS,pyarrow, pandas, snappy, and fastparquet pre-installed. \n",
    "\n",
    "I also upgraded the version of ADS. In this notebook ADS version 2.5.8 was used. \n",
    "\n",
    "To read/write files to Object Storage, use `ocifs` : \n",
    "* github.com/oracle/ocifs\n",
    "* docs: https://docs.oracle.com/en-us/iaas/tools/ocifs-sdk/latest/unix-operations.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install oracle-ads --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads \n",
    "from ads.common.auth import default_signer\n",
    "import pandas as pd \n",
    "import fsspec\n",
    "from ocifs import OCIFileSystem\n",
    "\n",
    "# Using resource principal auth method: \n",
    "print(ads.__version__)\n",
    "ads.set_auth(auth=\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object storage bucket + data \n",
    "# this bucket is publicly available \n",
    "bucket = \"hosted-ds-datasets\"\n",
    "namespace = \"bigdatadatasciencelarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68024c",
   "metadata": {},
   "source": [
    "# Single Large File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 440 MB, 14M rows. \n",
    "large_files = [\"nyc_tlc/2009/01/data.parquet\"] # NYC Taxi dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the `pyarrow` engine. You can also use `fastparquet`. \n",
    "for f in large_files: \n",
    "    df = pd.read_parquet(f\"oci://{bucket}@{namespace}/{f}\", \n",
    "                     storage_options=default_signer(),\n",
    "                     engine=\"pyarrow\")\n",
    "    print(f\"file {f}\")\n",
    "    print(df.head())\n",
    "    print(f\"size {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06706b05",
   "metadata": {},
   "source": [
    "# Multiple Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d202b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oci.auth.signers import get_resource_principals_signer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using resource principal for authn. \n",
    "fs = OCIFileSystem(signer=get_resource_principals_signer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e146024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a small sample of the overall NYC Taxi dataset. There are 4 files in total, each of size ~ 450MB. \n",
    "relevant_files = fs.ls(f\"{bucket}@{namespace}/nyc_tlc/2009/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22421b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# this operation takes about 50 secs: \n",
    "df = pd.concat((pd.read_parquet(f\"oci://{f}/data.parquet\", storage_options=default_signer(), engine=\"pyarrow\") for f in relevant_files), \n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 56M rows \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52a973",
   "metadata": {},
   "source": [
    "## Write Parquet Files to Object Storage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4923c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Writing the dataframe as a parquet file to Object Storage. \n",
    "# Insert the name of your bucket and namespace you want to write parquet. \n",
    "# this operation takes about 2 mins\n",
    "your_bucket = \"\"\n",
    "your_namespace = \"\"\n",
    "\n",
    "df.to_parquet(f\"oci://{your_bucket}@{your_namespace}/taxi-data.parquet\", \n",
    "                     storage_options=default_signer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
