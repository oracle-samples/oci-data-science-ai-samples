{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ab6c39f3",
   "metadata": {},
   "source": [
    "@notebook{natural_language_processing.ipynb,\n",
    "    title: Natural Language Processing,\n",
    "    summary: Use the ADS SDK to process and manipulate strings. This notebook includes regular expression matching and natural language (NLP) parsing, including part-of-speech tagging, named entity recognition, and sentiment analysis. It also shows how to create and use custom plugins specific to your specific needs.,\n",
    "    developed_on: nlp_p37_cpu_v2,\n",
    "    keywords: language services, string manipulation, regex, regular expression, natural language processing, NLP, part-of-speech tagging, named entity recognition, sentiment analysis, custom plugins,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6627d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f5e3c",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2021, 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "***\n",
    "\n",
    "# <font color=\"red\">Natural Language Processing</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\"> Oracle Cloud Infrastructure Data Science Service</font></p>\n",
    "\n",
    "---\n",
    "\n",
    "# Overview:\n",
    "\n",
    "Data scientists need to be able to quickly and easily manipulate strings. The Accelerated Data Science (ADS) SDK provides an enhanced string class, called `ADSString`. It adds functionalty like regular expression (RegEx) matching and natural language processing (NLP) parsing. The class can be expanded by registering custom plugins so that you can process a string in a way that it fits your specific needs. For example, you can register the OCI AI Language service plugin to bind functionalities from the Language service to `ADSString`.\n",
    "\n",
    "Compatible conda pack: [Natural Language Processing](https://docs.oracle.com/iaas/data-science/using/conda-nlp-fam.htm) for CPU on Python 3.7 (version 2.0)\n",
    "\n",
    "---\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href='#intro'>Introduction</a>\n",
    "- <a href=\"#regex-match\">Regular Expression Matching</a>\n",
    "- <a href=\"#nlp\">NLP Parsing</a>\n",
    "    - <a href=\"#nlp_nltk\">Natural Language Toolkit Backend</a>\n",
    "        - <a href=\"#nlp_nltk_pos\">Part-of-Speech Tags</a> \n",
    "    - <a href=\"#nlp_spacy\">spaCy</a>\n",
    "        - <a href=\"#nlp_spacy_pos\">Part-of-Speech Tag</a>\n",
    "- <a href=\"#plugin\">Plugin</a> \n",
    "    - <a href=\"#plugin_oci-lang\">OCI Language Services</a>\n",
    "        - <a href=\"#plugin_oci-lang_absa\">Aspect-Based Sentiment Analysis</a> \n",
    "        - <a href=\"#plugin_oci-lang_ner\">Named Entity Recognition</a>\n",
    "        - <a href=\"#plugin_oci-lang_key-phrase\">Key Phrase Extraction</a>\n",
    "        - <a href=\"#plugin_oci-lang_language\">Language Detection</a>\n",
    "        - <a href=\"#plugin_oci-lang_classification\">Text Classification</a>\n",
    "    - <a href=\"#plugin_custom\">Custom Plugin</a> \n",
    "- <a href='#str'>`ADSString` is Still a `str`</a>\n",
    "- <a href=\"#reference\">References</a>\n",
    "\n",
    "*** \n",
    "\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials \n",
    "under your agreement with Oracle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7528879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "import spacy\n",
    "\n",
    "from ads.feature_engineering.adsstring.oci_language import OCILanguage\n",
    "from ads.feature_engineering.adsstring.string import ADSString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46cf2d",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "Text analytics uses a set of powerful tools to understand the content of unstructured data such as text. It is becoming an increasingly more important tool in feature engineering as product reviews, media content, research papers, and more are being mined for their content. In many data science areas, such as marketing analytics, the use of unstructured text is becoming as popular as structured data. This is largely due to the relatively low cost of collection of the data. However, the downside is the complexity of working with the data. To work with unstructured that you need to clean, summarize, and create features out of it before you create a model. The `ADSString` class provides tools that allow you to quickly do this work. More importantly, you can expand the tool to meet your specific needs.\n",
    "\n",
    "<a id=\"regex-match\"></a>\n",
    "# Regular Expression Matching\n",
    "\n",
    "Text documents are often parsed looking for specific patterns to extract information like emails, dates, times, web links, and so on. This pattern matching is often done with (RegEx), which is hard to write, modify, understand, and custom-written RegEx often misses the edge cases. `ADSString` has a number of common RegEx patterns built-in so that your work is simplified. The following patterns have been defined:\n",
    "\n",
    "* `credit_card`: Credit card number.\n",
    "* `dates`: Dates in a variety of standard formats.\n",
    "* `email`: Email address.\n",
    "* `ip`: IP addresses, versions IPV4 and IPV6.\n",
    "* `link`: Text that appears to be a link to a website.\n",
    "* `phone_number_US`: USA phone numbers including those with extensions.\n",
    "* `price`: Text that appears to be a price.\n",
    "* `ssn`: USA social security number.\n",
    "* `street_address`: Street address.\n",
    "* `times`: Text that appears to be a time and less than 24 hours.\n",
    "* `zip_code`: USA zip code.\n",
    "\n",
    "The above `ADSString` properties return an array with each pattern that in matches. The following cells demonstrate how to extract Email addresses, dates and links from the text. It should be noted that the text is extracted as-is. For example, the dates are not converted to a standard format. The returned value is the text as it is represented in the input text. Use the `datetime.strptime()` method to convert the date to a date time stamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fe292",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ADSString(\n",
    "    \"Get in touch with my associates john.smith@example.com and jane.johnson@example.com to schedule\"\n",
    ")\n",
    "s.email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc191438",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ADSString(\"She is born on Jan. 19th, 2014 and died 2021-09-10\")\n",
    "s.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae37b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ADSString(\"Follow the link www.oracle.com to Oracle's homepage.\")\n",
    "s.link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994bf3b1",
   "metadata": {},
   "source": [
    "<a id=\"nlp\"></a>\n",
    "# NLP Parsing\n",
    "\n",
    "`ADSString` also supports NLP parsing and is backed by [NLTK](https://www.nltk.org/) or [spaCy](https://spacy.io/). Unless otherwise specified, NLTK is used by default. You can extract properties, such as nouns, adjectives, word counts, parts-of-speech tags, and so on, from text with NLP support.\n",
    "\n",
    "The `ADSString` class can have one backend enabled at a time. What properties are available depends on the backend, as do the results of calling the property. The following section provides an overview of the available parsers, and how to use them. Generally, the parses support the `adjective`, `adverb`, `bigram`, `noun`, `pos`, `sentence`, `trigram`, `verb`, `word`, and `word_count` base properties. Parsers can support additional parsers.\n",
    "\n",
    "\n",
    "<a id=\"nlp_nltk\"></a>\n",
    "## Natural Language Toolkit Backend\n",
    "\n",
    "The Natural Language Toolkit (NLTK) is a powerful platform for processing human language data. It supports all the base properties and in addition `stem` and `token`. The `stem` property  returns a list of all the stemmed tokens. It reduces a token to its word stem that affixes to suffixes and prefixes, or to the roots of words that is the lemma. The `token` property is similar to the `word` property, except it returns non-alphanumeric tokens and doesn't force tokens to be lowercase.\n",
    "\n",
    "The following cells use a sample of text about Larry Ellison to demonstrate the use of the NLTK properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75664cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "            Lawrence Joseph Ellison (born August 17, 1944) is an American business magnate,\n",
    "            investor, and philanthropist who is a co-founder, the executive chairman and\n",
    "            chief technology officer (CTO) of Oracle Corporation. As of October 2019, he was\n",
    "            listed by Forbes magazine as the fourth-wealthiest person in the United States\n",
    "            and as the sixth-wealthiest in the world, with a fortune of $69.1 billion,\n",
    "            increased from $54.5 billion in 2018.[4] He is also the owner of the 41st\n",
    "            largest island in the United States, Lanai in the Hawaiian Islands with a\n",
    "            population of just over 3000.\n",
    "        \"\"\".strip()\n",
    "ADSString.nlp_backend(\"nltk\")\n",
    "s = ADSString(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.noun[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.word[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb346a7",
   "metadata": {},
   "source": [
    "By taking the difference between `token` and `word`, you can see that the token set contains non-alphanumeric tokes, and also the uppercase version of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7393443",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(s.token) - set(s.word))[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c2dad",
   "metadata": {},
   "source": [
    "The `stem` property takes the list of words and stems them. It produces morphological variations of a word‚Äôs root form. The following cell stems some words, and shows some of the stemmed words that were changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(s.stem) - set(s.word))[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176801f",
   "metadata": {},
   "source": [
    "<a id=\"nlp_nltk_pos\"></a>\n",
    "### Part-of-Speech Tags\n",
    "\n",
    "The part-of-speech (POS) is a category in which a word is assigned based on its syntactic function. The POS depends on the language. For English, the most common POS are adjective, adverb, conjunction, determiner, interjection, noun, preposition, pronoun, and verb. However, each POS system has its own set of POS tags that vary based on their respective training set. The NLTK parsers produce the following list of POS tags:\n",
    "\n",
    "* `CC`: coordinating conjunction\n",
    "* `CD`: cardinal digit\n",
    "* `DT`: determiner\n",
    "* `EX`: existential there; like: \"there is\" ... think of it like \"there exists\"\n",
    "* `FW`: foreign word\n",
    "* `IN`: preposition/subordinating conjunction\n",
    "* `JJ`: adjective; \"big\"\n",
    "* `JJR`: adjective, comparative; \"bigger\"\n",
    "* `JJS`: adjective, superlative; \"biggest\"\n",
    "* `LS`: list marker 1)\n",
    "* `MD`: modal could, will\n",
    "* `NN`: noun, singular; \"desk\"\n",
    "* `NNS`: noun plural; \"desks\"\n",
    "* `NNP`: proper noun, singular; \"Harrison\"\n",
    "* `NNPS`: proper noun, plural; \"Americans\"\n",
    "* `PDT`: predeterminer; \"all the kids\"\n",
    "* `POS`: possessive ending; \"parent's\"\n",
    "* `PRP`: personal pronoun; I, he, she\n",
    "* `PRP$`: possessive pronoun; my, his, hers\n",
    "* `RB`: adverb; very, silently\n",
    "* `RBR`: adverb; comparative better\n",
    "* `RBS`: adverb; superlative best\n",
    "* `RP`: particle; give up\n",
    "* `TO`: to go; \"to\" the store.\n",
    "* `UH`: interjection; errrrrrrrm\n",
    "* `VB`: verb, base form; take\n",
    "* `VBD`: verb, past tense; took\n",
    "* `VBG`: verb, gerund/present participle; taking\n",
    "* `VBN`: verb, past participle; taken\n",
    "* `VBP`: verb, singular present; non-3d take\n",
    "* `VBZ`: verb, 3rd person singular present; takes\n",
    "* `WDT`: wh-determiner; which\n",
    "* `WP`: wh-pronoun; who, what\n",
    "* `WP$`: possessive wh-pronoun; whose\n",
    "* `WRB`: wh-adverb; where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffe09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.pos[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098dd03",
   "metadata": {},
   "source": [
    "<a id=\"nlp_spacy\"></a>\n",
    "## spaCy\n",
    "\n",
    "spaCy is in an advanced NLP toolkit. It helps you understand what the words mean in context, and who is doing what to whom. It helps you determine what companies and products are mentioned in a document. The spaCy backend is used to parses the `adjective`, `adverb`, `bigram`, `noun`, `pos`, `sentence`, `trigram`, `verb`, `word`, and `word_count` base properties. It also supports the following additional properties:\n",
    "\n",
    "* `entity`: All entities in the text.\n",
    "* `entity_artwork`: The titles of books, songs, and so on.\n",
    "* `entity_location`: Locations, facilities, and geopolitical entities such as countries, cities, and states.\n",
    "* `entity_organization`: Companies, agencies, and institutions.\n",
    "* `entity_person`: Fictional and real people.\n",
    "* `entity_product`: Product names and so on.\n",
    "* `lemmas`: A rule-based estimation of the roots of a word.\n",
    "* `tokens`: The base tokens of the tokenization process. This is similar to `word`, but it includes non-alphanumeric values and the word case is preserved.\n",
    "\n",
    "If the `spacy` is installed module is installed ,you can change the NLP backend using the command `ADSString.nlp_backend('spacy')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADSString.nlp_backend(\"spacy\")\n",
    "s = ADSString(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54885699",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.noun[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb74bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.word[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017fe58",
   "metadata": {},
   "source": [
    "You can identify all the locations that are mentioned in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bf69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.entity_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5efe6",
   "metadata": {},
   "source": [
    "And what organizations were mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbaece",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.entity_organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54afbe92",
   "metadata": {},
   "source": [
    "<a id=\"nlp_spacy_pos\"></a>\n",
    "### Part-of-Speech Tags\n",
    "\n",
    "The POS tagger in spaCy uses a smaller number of categories. For example, spaCy has the `ADJ` POS for all adjectives, while NLTK has `JJ` to mean an adjective, `JJR` refers to a compartive adjective, and `JJS` refers to a superlative adjective. For fine grain analysis of different parts of speech, NLTK is the preferred backend. However, spaCy's reduced category set tends to produce fewer errors,at the cost of not being as specific.\n",
    "\n",
    "The spaCy parsers produce the following list of POS tags:\n",
    "\n",
    "*  `ADJ`: adjective; big, old, green, incomprehensible, first\n",
    "*  `ADP`: adposition; in, to, during\n",
    "*  `ADV`: adverb; very, tomorrow, down, where, there\n",
    "*  `AUX`: auxiliary; is, has (done), will (do), should (do)\n",
    "*  `CONJ`: conjunction; and, or, but\n",
    "*  `CCONJ`: coordinating conjunction; and, or, but\n",
    "*  `DET`: determiner; a, an, the\n",
    "*  `INTJ`: interjection; psst, ouch, bravo, hello\n",
    "*  `NOUN`: noun; girl, cat, tree, air, beauty\n",
    "*  `NUM`: numeral; 1, 2017, one, seventy-seven, IV, MMXIV\n",
    "*  `PART`: particle; ‚Äôs, not,\n",
    "*  `PRON`: pronoun; I, you, he, she, myself, themselves, somebody\n",
    "*  `PROPN`: proper noun; Mary, John, London, NATO, HBO\n",
    "*  `PUNCT`: punctuation; ., (, ), ?\n",
    "*  `SCONJ`: subordinating conjunction; if, while, that\n",
    "*  `SYM`: symbol; $, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù\n",
    "*  `VERB`: verb; run, runs, running, eat, ate, eating\n",
    "*  `X`: other; sfpksdpsxmsa\n",
    "*  `SPACE`: space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62873566",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.pos[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bec151",
   "metadata": {},
   "source": [
    "<a id=\"plugin\"></a>\n",
    "# Plugin\n",
    "\n",
    "One of the most powerful features of `ADSString` is that it can be expanded and customized. The `.plugin_register()` method allows you to add properites to the `ADSString` class. These plugins can be provided by third-party providers or developed in house. This section denonstrates how to connect the to the Language service, and how to create a custom plugin.\n",
    "\n",
    "<a id=\"plugin_oci-lang\"></a>\n",
    "## OCI Language Services\n",
    "\n",
    "The [Language service](https://docs.oracle.com/en-us/iaas/language/using/overview.htm) provides pretrained models that provide sophisticated text analysis at scale.\n",
    "\n",
    "The Language service contains these pretrained language processing capabilities:\n",
    "\n",
    "* `Aspect-Based Sentiment Analysis`: Identifies aspects from the given text and classifies each into positive, negative, or neutral polarity.\n",
    "* `Key Phrase Extraction`: Extracts an important set of phrases from a block of text.\n",
    "* `Language Detection`: Detects languages based on the given text, and includes a confidence score.\n",
    "* `Named Entity Recognition`: Identifies common entities, people, places, locations, email, and so on.\n",
    "* `Text Classification`: Identifies the document category and subcategory that the text belongs to.\n",
    "\n",
    "\n",
    "Those are accessible in ADS via `OCILanguage` plugin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b59389",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADSString.plugin_register(OCILanguage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6632e3",
   "metadata": {},
   "source": [
    "<a id=\"plugin_oci-lang_absa\"></a>\n",
    "### Aspect-Based Sentiment Analysis\n",
    "\n",
    "Aspect-based sentiment analysis can be used to gauge the mood or the tone of the text.\n",
    "\n",
    "The aspect-based sentiment analysis (ABSA) supports fine-grained sentiment analysis by extracting the individual aspects in the input document. For example, a restaurant review \"The driver was really friendly, but the taxi was falling apart.\" contains positive sentiment toward the taxi driver aspect. Also, it has a strong negative sentiment toward the service mechanical aspect of the taxi. Classifying the overall sentiment as negative would neglect the fact that the taxi driver was nice.\n",
    "\n",
    "ABSA classifies each of the aspects into one of the three polarity classes, positive, negative, mixed, and neutral. With the predicted sentiment for each aspect. It also provides a confidence score for each of the classes and their corresponding offsets in the input. The range of the confidence score for each class is between 0‚Äì1, and the cumulative scores of all the three classes sum to 1.\n",
    "\n",
    "In the next cell, the example sentence is analyzed. The two aspects, taxi cab and driver, have their sentiments determined. It defines the location of the aspect by giving its offset position in the text, and the length of the aspect in characters. It also gives the text that defines the aspect along with the sentiment scores and which sentiment is dominant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ADSString(\"The driver was really friendly, but the taxi was falling apart.\")\n",
    "t.absa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c93a27",
   "metadata": {},
   "source": [
    "<a id=\"plugin_oci-lang_ner\"></a>\n",
    "### Named Entity Recognition\n",
    "\n",
    "Named entity recognition (NER) detects named entities in text. The NER tool uses NLP, which uses machine learning to find predefined named entities. This tool also provides a confidence score for each entity and is a value from 0-1. The returned data is the text of the entity, its position in the document, and its length. It also identifies the type of entity, a probability score that it is an entity of the stated type. \n",
    "\n",
    "The following are the supported entity types:\n",
    "\n",
    "* `DATE`: Absolute or relative dates, periods, and date range.\n",
    "* `EMAIL`: Email address.\n",
    "* `EVENT`: Named hurricanes, sports events, and so on.\n",
    "* `FAC`: Facilities; Buildings, airports, highways, bridges, and so on.\n",
    "* `GPE`: Geopolitical entity; Countries, cities, and states.\n",
    "* `IPADDRESS`: IP address according to IPv4 and IPv6 standards.\n",
    "* `LANGUAGE`: Any named language.\n",
    "* `LOCATION`: Non-GPE locations, mountain ranges, and bodies of water.\n",
    "* `MONEY`: Monetary values, including the unit.\n",
    "* `NORP`: Nationalities, religious, and political groups.\n",
    "* `ORG`: Organization; Companies, agencies, institutions, and so on.\n",
    "* `PERCENT`: Percentage.\n",
    "* `PERSON`: People, including fictional characters.\n",
    "* `PHONE_NUMBER`: Supported phone numbers.\n",
    "    * (\"GB\") - United Kingdom\n",
    "    * (\"AU\") - Australia\n",
    "    * (\"NZ\") - New Zealand\n",
    "    * (\"SG\") - Singapore\n",
    "    * (\"IN\") - India\n",
    "    * (\"US\") - United States\n",
    "* `PRODUCT`: Vehicles, tools, foods, and so on (not services).\n",
    "* `QUANTITY`: Measurements, as weight or distance.\n",
    "* `TIME`: Anything less than 24 hours (time, duration, and so on).\n",
    "* `URL`: URL\n",
    "\n",
    "The following cell lists the named entities in the \"Lawrence Joseph Ellison...\" `test_text`. The output gives the named entity, its location, and offset position in the text. It gives a probability and score that this text is actually a named entity along with the type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ADSString(test_text)\n",
    "s.ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f304e",
   "metadata": {},
   "source": [
    "<a id=\"plugin_oci-lang_key-phrase\"></a>\n",
    "### Key Phrase Extraction\n",
    "\n",
    "Key phrase (KP) extraction is the process of extracting the words with the most relevance, and expressions from the input text. It helps summarize the content and recognizes the main topics. The KP extraction finds insights related to the main points of the text. It understands the unstructured input text, and returns keywords and KPs. The KPs consist of subjects and objects that are being talked about in the document. Any modifiers, like adjectives associated with these subjects and objects, are also included in the output. Confidence scores for each key phrase that signify how confident the algorithm is that the identified phrase is a KP. Confidence scores are a value from 0-1.\n",
    "\n",
    "The following cell determines the key phrases and the importance of these phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.key_phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c3dd7",
   "metadata": {},
   "source": [
    "<a id=\"plugin_oci-lang_language\"></a>\n",
    "### Language Detection\n",
    "\n",
    "The language detection tool identifies which natural language the input text is in. If the document contains more than one language, the results may not be what you expect. Language detection can help make customer support interactions more personable and quicker. Customer service chatbots can interact with customers based on the language of their input text and respond accordingly. If a customer needs help with a product, the chatbot server can field the corresponding language product manual, or transfer it to a call center for the specific language.\n",
    "\n",
    "The following is a list of some of the supported languages:\n",
    "\n",
    "* Afrikaans\n",
    "* Albanian\n",
    "* Arabic\n",
    "* Armenian\n",
    "* Azerbaijani\n",
    "* Basque\n",
    "* Belarusian\n",
    "* Bengali\n",
    "* Bosnian\n",
    "* Bulgarian\n",
    "* Burmese\n",
    "* Cantonese\n",
    "* Catalan\n",
    "* Cebuano\n",
    "* Chinese\n",
    "* Croatian\n",
    "* Czech\n",
    "* Danish\n",
    "* Dutch\n",
    "* Eastern Punjabi\n",
    "* Egyptian Arabic\n",
    "* English\n",
    "* Esperanto\n",
    "* Estonian\n",
    "* Finnish\n",
    "* French\n",
    "* Georgian\n",
    "* German\n",
    "* Greek\n",
    "* Hebrew\n",
    "* Hindi\n",
    "* Hungarian\n",
    "* Icelandic\n",
    "* Indonesian\n",
    "* Irish\n",
    "* Italian\n",
    "* Japanese\n",
    "* Javanese\n",
    "* Kannada\n",
    "* Kazakh\n",
    "* Korean\n",
    "* Kurdish (Sorani)\n",
    "* Latin\n",
    "* Latvian\n",
    "* Lithuanian\n",
    "* Macedonian\n",
    "* Malay\n",
    "* Malayalam\n",
    "* Marathi\n",
    "* Minangkabau\n",
    "* Nepali\n",
    "* Norwegian (Bokmal)\n",
    "* Norwegian (Nynorsk)\n",
    "* Persian\n",
    "* Polish\n",
    "* Portuguese\n",
    "* Romanian\n",
    "* Russian\n",
    "* Serbian\n",
    "* Serbo-Croatian\n",
    "* Slovak\n",
    "* Slovene\n",
    "* Spanish\n",
    "* Swahili\n",
    "* Swedish\n",
    "* Tagalog\n",
    "* Tamil\n",
    "* Telugu\n",
    "* Thai\n",
    "* Turkish\n",
    "* Ukrainian\n",
    "* Urdu\n",
    "* Uzbek\n",
    "* Vietnamese\n",
    "* Welsh\n",
    "\n",
    "The next cell determines the language of the text, the [ISO 639-1](https://en.wikipedia.org/wiki/ISO_639-1) language code, and a probability score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.language_dominant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ba201",
   "metadata": {},
   "source": [
    "<a id=\"plugin_oci-lang_classification\"></a>\n",
    "### Text Classification\n",
    "\n",
    "Text classification analyses the text and identifies categories for the content with a confidence score. Text classification uses NLP techniques to find insights from textual data. It returns a category from a set of predefined categories. This text classification uses NLP and relies on the main objective lies on zero-shot learning. It classifies text with no or minimal data to train. The content of a collection of documents is analyzed to determine common themes.\n",
    "\n",
    "The next cell classifies the text and gives a probability score that the text is in that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c04be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.text_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb6831f",
   "metadata": {},
   "source": [
    "<a id=\"plugin_custom\"></a>\n",
    "## Custom Plugin\n",
    "\n",
    "You can bind additional properties to `ADSString` using custom plugins. This allows you to create custom text processing extensions. A plugin has access to the `self.string` property in `ADSString` class. You can define functions that perform a transformation on the text in the object. All functions defined in a plugin are bound to `ADSString` and accessible across all objects of that class.\n",
    "\n",
    "Assume that your text is `\"I purchased the gift on this card 4532640527811543 and the dinner on 340984902710890\"` and you want to know what credit cards were used. The `.credit_card` property returns the entire credit card number. However, for privacy reasons you don't what the entire credit card number, but the last four digits.\n",
    "\n",
    "To solve this problem, you can create the class `CreditCardLast4` and use the `self.string` property in `ADSString` to access the text associated with the object. It then calls the `.credit_card` method to get the credit card numbers. It then parses this to return the last four characters in each credit card.\n",
    "\n",
    "The first step is to define the class that you want to bind to `ADSString`. Use the `@property` decorator and define a property function. This function only takes `self`. The `self.string` is accessible with the text that is defined for a given object. The property returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fbf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditCardLast4:\n",
    "    @property\n",
    "    def credit_card_last_4(self):\n",
    "        return [x[len(x) - 4 : len(x)] for x in ADSString(self.string).credit_card]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55b77b",
   "metadata": {},
   "source": [
    "After the class is defined, it must be registered with `ADSString` using the `.register_plugin()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eaa5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADSString.plugin_register(CreditCardLast4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f91ea",
   "metadata": {},
   "source": [
    "Take the text and make it an `ADSString` object and call the `.credit_card_last_4` property to obtain the last four digits of the credit cards that were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef73509",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_numbers = \"I purchased the gift on this card 4532640527811543 and the dinner on 340984902710890\"\n",
    "s = ADSString(creditcard_numbers)\n",
    "s.credit_card_last_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90a84a",
   "metadata": {},
   "source": [
    "<a id='str'></a>\n",
    "# `ADSString` is Still a `str`\n",
    "\n",
    "While `ADSString` expands your feature engineering capabilities, it can still be treated as a `str` object. Any standard operation on `str` is preserved in `ADSString`. For instance, you can convert it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d684c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_world = \"HELLO WORLD\"\n",
    "s = ADSString(hello_world)\n",
    "s.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf8f45",
   "metadata": {},
   "source": [
    "You can split a text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa9d03",
   "metadata": {},
   "source": [
    "You can use all the `str` methods, such as the `.replace()` method, to replace text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.replace(\"L\", \"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e07e9",
   "metadata": {},
   "source": [
    "You can perform a number of `str` manipulation operations, such as `.lower()` and `.upper()`, to get an `ADSString` object back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ad698",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(s.lower().upper(), ADSString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cca216",
   "metadata": {},
   "source": [
    "While a new `ADSString` object is created with `str` manipulation operations, the equality operation holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.lower().upper() == s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebba7f",
   "metadata": {},
   "source": [
    "The equality operation even holds between `ADSString` objects (`s`) and `str` objects (`hello_world`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9fe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "s == hello_world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452b40b",
   "metadata": {},
   "source": [
    "<a id=\"reference\"></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [OCI Language service](https://docs.oracle.com/en-us/iaas/language/using/overview.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
