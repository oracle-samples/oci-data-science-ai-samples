{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a204cdc2",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43929671",
   "metadata": {},
   "source": [
    "# <font color=red>Using Data Science Jobs to create design time entities of OCI feature store</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle Cloud Infrastructure Data Science Team </font></p>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26506eac",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "Data Science Jobs allow you to run customized tasks outside of a notebook session. You can have Compute on demand and only pay for the Compute that you need. With jobs, you can run applications that perform tasks such as data preparation, model training, hyperparameter tuning, and batch inference. When the task is complete, the compute automatically terminates. You can use the Logging service to capture output messages. In this notebook, we will use the Accelerated Data Science SDK (ADS) to help us define a Data Science Job to create design time entities of OCI feature store which can later be used to ingest feature data.\n",
    "\n",
    "For more information on using ADS for jobs, you can go to our [documentation](https://docs.oracle.com/en-us/iaas/tools/ads-sdk/latest/user_guide/jobs/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.jobs import Job\n",
    "from ads.jobs import DataScienceJob, ScriptRuntime\n",
    "import ads \n",
    "client_kwargs = dict(\n",
    "    fs_service_endpoint=\"<api_gateway>\",\n",
    ")\n",
    "\n",
    "ads.set_auth('resource_principal',client_kwargs=client_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a0dcb",
   "metadata": {},
   "source": [
    "## Infrastructure\n",
    "\n",
    "Data Science Job infrastructure is defined by a `DataScienceJob` instance.  \n",
    "<span style=\"color:red\">Important:  </span>If you want to use logging for the job, fill in the `log_group_id` and `log_id` in the cell below.  You need to have set up the policies for the logging service.  For more information about setting up logs for a job, you can go to our [documentation](https://docs.oracle.com/en-us/iaas/data-science/using/log-about.htm#jobs_about__job-logs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "infrastructure = (\n",
    "    DataScienceJob()\n",
    "    .with_shape_name(\"VM.Standard2.24\")\n",
    "    .with_block_storage_size(50)\n",
    "    .with_log_group_id(\"<log_group_id>\")\n",
    "    .with_log_id(\"<log_id>\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880938cb",
   "metadata": {},
   "source": [
    "## Job Runtime\n",
    "\n",
    "`ScriptRuntime` allows you to run Python, Bash, and Java scripts from a single source file (.zip or .tar.gz) or code directory. You can configure a Data Science Conda Environment for running your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = (\n",
    "    ScriptRuntime()\n",
    "    .with_source(\"./feature_store_creation_example.py\")\n",
    "    .with_service_conda(\"fspyspark32_p38_cpu_v3\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebaed82",
   "metadata": {},
   "source": [
    "## Define Job\n",
    "\n",
    "With runtime and infrastructure, you can define a job and give it a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6049898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time    \n",
    "epoch_time = int(time.time())\n",
    "print(f'fs_dt_creation_{epoch_time}')\n",
    "job = Job(name= f'fs_dt_creation_{epoch_time}').with_infrastructure(infrastructure).with_runtime(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a5a95",
   "metadata": {},
   "source": [
    "## Create and Run Job\n",
    "\n",
    "You can call the `create()` method of a job instance to create a job. After the job is created, you can call the `run()` method to create and start a job run. The `run()` method returns a `DataScienceJobRun`. You can monitor the job run output by calling the `watch()` method of the `DataScienceJobRun` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8382b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11330367",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run.watch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69266ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
