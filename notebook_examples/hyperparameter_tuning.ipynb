{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@notebook{hyperparameter_tuning.ipynb,\n",
    "    title: Introduction to ADSTuner,\n",
    "    summary: Use ADSTuner to optimize an estimator using the scikit-learn API,\n",
    "    developed on: generalml_p37_cpu_v1,\n",
    "    keywords: hyperparameter tuning,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6627d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2020, 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "***\n",
    "\n",
    "# <font color=\"red\">Introduction to ADSTuner</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "***\n",
    "\n",
    "# Overview:\n",
    "\n",
    "A hyperparameter is a parameter that is used to control a learning process. This is in contrast to other parameters that are learned in the training process. The process of hyperparameter optimization is to search for hyperparameter values by building many models and assessing their quality. This notebook provides an overview of the `ADSTuner` hyperparameter optimization engine. `ADSTuner` can optimize any estimator object that follows the [scikit-learn API](https://scikit-learn.org/stable/modules/classes.html).\n",
    "\n",
    "Developed on [General Machine Learning](https://docs.oracle.com/en-us/iaas/data-science/using/conda-gml-fam.htm) for CPU on Python 3.7 (version 1.0)\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href='#intro'>Introduction</a>\n",
    "    - <a href='#ntrials'>Synchronous Tuning with Exit Criterion Based on Number of Trials</a>\n",
    "    - <a href='#resume'>Asynchronously Tuning with Exit Criterion Based on Time Budget</a>\n",
    "    - <a href='#inspect'>Inspecting the Tuning Trials</a>\n",
    "- <a href='#custom'>Defining a Custom Search Space and Score</a>  \n",
    "    - <a href='#search-space'>Changing the Search Space Strategy</a>\n",
    "- <a href='#pipeline'>Optimizing a scikit-learn `Pipeline()`</a> \n",
    "- <a href=\"#reference\">References</a>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials \n",
    "under your agreement with Oracle. \n",
    "\n",
    "You can access the `iris` dataset license [here](https://github.com/scikit-learn/scikit-learn/blob/master/COPYING).  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from ads.hpo.stopping_criterion import *\n",
    "from ads.hpo.distributions import *\n",
    "from ads.hpo.search_cv import ADSTuner, State\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "Hyperparameter optimization requires a model, dataset, and an `ADSTuner` object to perform the search.\n",
    "\n",
    "`ADSTuner()` Performs a hyperparameter search using [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). You can specify the number of folds you want to use with the `cv` parameter.\n",
    "\n",
    "The `ADSTuner()` needs a search space to tune the hyperparameters in so you use the `strategy` parameter. This parameter can be set in two ways. You can specify detailed search criteria or you can use the built-in defaults. For the supported model classes, `ADSTuner` provides `perfunctory`and `detailed` search spaces that are optimized for the class of model that is being used. The `perfunctory` option is optimized for a small search space so that the most important hyperparameters are tuned. Generally, this option is used early in your search as it reduces the computational cost and allows you to assess the quality of the model class that you are using. The `detailed` search space instructs `ADSTuner` to cover a broad search space by tuning more hyperparameters. Typically, you would use it when you have determined what class of model is best suited for the dataset and type of problem you are working on. If you have experience with the dataset and have a good idea of what the best hyperparameter values are, you can explicitly specify the search space. You pass a dictionary that defines the search space into the `strategy`.\n",
    "\n",
    "The parameter `storage` takes a database URL. For example, `sqlite:////home/datascience/example.db`. When `storage` is set to the default value `None`, a new sqlite database file is created internally in the `tmp` folder with a unique name. The name format is `sqlite:////tmp/hpo_*.db`. `study_name` is the name of this study for this `ADSTuner` object. One `ADSTuner` object only has one `study_name`. However, one database file can be shared among different `ADSTuner` objects. `load_if_exists` controls whether to load an existing study from an existing database file. If `False`, it raises a `DuplicatedStudyError` when the `study_name` exists.\n",
    "\n",
    "The `loglevel` parameter controls the amount of logging information displayed in the notebook.\n",
    "\n",
    "This notebook uses the scikit-learn `SGDClassifer()` model and the iris dataset. This model object is a regularized linear model with [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) (SGD) used to optimize the model parameters.\n",
    "\n",
    "The next cell creates the `SGDClassifer()` model, initialize san `ADSTuner` object, and loads the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = ADSTuner(SGDClassifier(), cv=3, loglevel=logging.WARNING)\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model class has a set of hyperparameters that yoi need to optimized. The `strategy` attribute returns what strategy is being used. This can be `perfunctory`, `detailed`, or a dictionary that defines the strategy. The method `search_space()` always returns a dictionary of hyperparameters that are to be searched. Any hyperparameter that is required by the model, but is not listed, uses the default value that is defined by the model class. To see what search space is being used for your model class when `strategy` is `perfunctory` or `detailed` use the `search_space()` method to see the details.\n",
    "\n",
    "The `adstuner_search_space_update.ipynb` notebook has detailed examples about how to work with and update the search space.\n",
    "\n",
    "The next cell displaces the search strategy and the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Search Space for strategy \"{tuner.strategy}\" is: \\n {tuner.search_space()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tune()` method starts a tuning process. It has a synchronous and asynchronous mode for tuning. The mode is set with the `synchronous` parameter. When it is set to `False`, the tuning process runs asynchronously so it runs in the background and allows you to continue your work in the notebook. When `synchronous` is set to `True`, the notebook is blocked until `tune()` finishes running. The `adntuner_sync_and_async.ipynb` notebook illustrates this feature in a more detailed way.\n",
    "\n",
    "The `ADSTuner` object needs to know when to stop tuning. The `exit_criterion` parameter accepts a list of criteria that cause the tuning to finish. If any of the criteria are met, then the tuning process stops. Valid exit criteria are:\n",
    "\n",
    "* `NTrials(n)`: Run for `n` number of trials.\n",
    "* `TimeBudget(t)`: Run for `t` seconds.\n",
    "* `ScoreValue(s)`: Run until the score value exceeds `s`.\n",
    "\n",
    "The default behavior is to run for 50 trials (`NTrials(50)`).\n",
    "\n",
    "The stopping criteria are listed in the [`ads.hpo.stopping_criterion`](https://docs.oracle.com/en-us/iaas/tools/ads-sdk/latest/ads.hpo.html#module-ads.hpo.stopping_criterion) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ntrials'></a>\n",
    "## Synchronous Tuning with Exit Criterion Based on Number of Trials\n",
    "\n",
    "This section demonstrates how to perform a synchronous tuning process with the exit criteria based on the number of trials. In the next cell, the `synchronous` parameter is set to `True` and the `exit_criterion` is set to `[NTrials(5)]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.tune(X, y, exit_criterion=[NTrials(5)], synchronous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access a summary of the trials by looking at the various attributes of the `tuner` object. The `scoring_name` attribute is a string that defines the name of the scoring metric. The `best_score` attribute gives the best score of all the completed trials. The `best_params` parameter defines the values of the hyperparameters that have to lead to the best score. Hyperparameters that are not in the search criteria are not reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"So far the best {tuner.scoring_name} score is {tuner.best_score} and the best hyperparameters are {tuner.best_params}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also look at the detailed table of all the trials attempted: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.trials.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='resume'></a>\n",
    "## Asynchronously Tuning with Exit Criterion Based on Time Budget\n",
    "\n",
    "`ADSTuner()` tuner can be run in an asynchronous mode by setting `synchronous=False` in the `tune()` method. This allows you to run other Python commands while the tuning process is executing in the background. This section demonstrates how to run an asynchronous search for the optimal hyperparameters. It uses a stopping criteria of five seconds. This is controlled by the parameter `exit_criterion=[TimeBudget(5)]`.\n",
    "\n",
    "The next cell starts an asynchronous tuning process. A loop is created that prints the best search results that have been detected so far by using the `best_score` attribute. It also displays the remaining time in the time budget by using the `time_remaining` attribute. The attribute `status` is used to exit the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will return right away since it's running asynchronous.\n",
    "tuner.tune(exit_criterion=[TimeBudget(5)])\n",
    "while tuner.status == State.RUNNING:\n",
    "    print(\n",
    "        f\"So far the best score is {tuner.best_score} and the time left is {tuner.time_remaining}\"\n",
    "    )\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `best_index` givse you the index in the `trials` data frame where the best model is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.trials.loc[tuner.best_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `n_trials` reports the number of successfully complete trials that were conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The total of trials was: {tuner.n_trials}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspect'></a>\n",
    "## Inspecting the Tuning Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the tuning trials performance using several built in plots.\n",
    "\n",
    "**Note**: If the tuning process is still running in the background, the plot runs in real time to update the new changes until the tuning process completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.tune(exit_criterion=[NTrials(5)], loglevel=logging.WARNING) # uncomment this line to see the real-time plot.\n",
    "tuner.plot_best_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.plot_intermediate_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.plot_contour_scores(params=[\"penalty\", \"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.plot_parallel_coordinate_scores(params=[\"penalty\", \"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.plot_edf_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.plot_param_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='custom'></a>\n",
    "# Defining a Custom Search Space and Score\n",
    "\n",
    "Instead of using a `perfunctory` or `detailed` strategy, define a custom search space strategy. \n",
    "\n",
    "The next cell, creates a `LogisticRegression()` model instance then defines a custom search space strategy for the three `LogisticRegression()` hyperparameters, `C`, `solver`, and `max_iter` parameters. \n",
    "\n",
    "You can define a custom `scoring` parameter, see <a id='pipeline'>Optimizing a scikit-learn `Pipeline()`</a> though this example uses the standard weighted average $F_1$, `f1_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = ADSTuner(\n",
    "    LogisticRegression(),\n",
    "    strategy={\n",
    "        \"C\": LogUniformDistribution(low=1e-05, high=1),\n",
    "        \"solver\": CategoricalDistribution([\"saga\"]),\n",
    "        \"max_iter\": IntUniformDistribution(500, 2000, 50),\n",
    "    },\n",
    "    scoring=make_scorer(f1_score, average=\"weighted\"),\n",
    "    cv=3,\n",
    ")\n",
    "tuner.tune(\n",
    "    X, y, exit_criterion=[NTrials(5)], synchronous=True, loglevel=logging.WARNING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='search-space'></a>\n",
    "## Changing the Search Space Strategy\n",
    "\n",
    "You can change the search space in the following three ways:\n",
    "\n",
    "- add new hyperparameters\n",
    "- remove existing hyperparameters\n",
    "- modify the range of existing non-categorical hyperparameters\n",
    "\n",
    "**Note**: You can't change the distribution of an existing hyperparameter or make any changes to a hyperparameter that is based on a categorical distribution. You need to initiate a new `ADSTuner` object for those cases. For more detailed information, review the `adstuner_search_space_update.ipynb` notebook.\n",
    "\n",
    "The next cell switches to a `detailed` strategy. All previous values set for `C`, `solver`, and `max_iter` are kept, and `ADSTuner` infers distributions for the remaining hyperparameters. You can force an overwrite by setting `overwrite=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space(strategy=\"detailed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can edit a subset of the search space by changing the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space(strategy={\"C\": LogUniformDistribution(low=1e-05, high=1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of using `overwrite=True` to reset to the default values for `detailed`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space(strategy=\"detailed\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.tune(\n",
    "    X, y, exit_criterion=[NTrials(5)], synchronous=True, loglevel=logging.WARNING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pipeline'></a>\n",
    "# Optimizing a scikit-learn `Pipeline()` \n",
    "\n",
    "The following example demonstrates how the `ADSTuner` hyperparameter optimization engine can optimize the **sklearn** `Pipeline()` objects. \n",
    "\n",
    "You create a scikit-learn `Pipeline()` model object and use `ADSTuner` to optimize its performance on the iris dataset from sklearn.\n",
    "\n",
    "The dataset is then split into X and y, which refers to the training features and the target feature respectively. Again, applying a `train_test_split()` call splits the data into training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X = pd.DataFrame(\n",
    "    data=X, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    ")\n",
    "y = pd.DataFrame(data=y)\n",
    "\n",
    "numeric_features = X.select_dtypes(\n",
    "    include=[\"int64\", \"float64\", \"int32\", \"float32\"]\n",
    ").columns\n",
    "categorical_features = y.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
    "\n",
    "y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "\n",
    "num_features = len(numeric_features) + len(categorical_features)\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"num_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"cat_encoder\", ce.woe.WOEEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"feature_selection\", SelectKBest(f_classif, k=int(0.9 * num_features))),\n",
    "        (\"classifier\", LogisticRegression()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define a custom score function. In this example, it is directly measuring how close the predicted y-values are to the true y-values by taking the weighted average of the number of direct matches between the y-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred, sample_weight=None):\n",
    "    score = y_true == y_pred\n",
    "    return np.average(score, weights=sample_weight)\n",
    "\n",
    "\n",
    "score = make_scorer(custom_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you instantiate the `ADSTuner()` object and use it to tune the iri` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search = ADSTuner(pipe, scoring=score, strategy=\"detailed\", cv=2, random_state=42)\n",
    "\n",
    "ads_search.tune(\n",
    "    X=X, y=y, exit_criterion=[NTrials(20)], synchronous=True, loglevel=logging.WARNING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ads_search` tuner can provide useful information about the tuning process, like the best parameter that was optimized, the best score achieved, the number of trials, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search.sklearn_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search.best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search.trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_search.n_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reference\"></a>\n",
    "# References\n",
    "\n",
    "- [`ads.hpo.stopping_criterion`](https://docs.oracle.com/en-us/iaas/tools/ads-sdk/latest/ads.hpo.html#module-ads.hpo.stopping_criterion)\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Cross-Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
