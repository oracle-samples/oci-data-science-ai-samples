{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ML Insights : Post Processor Component Example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case\n",
    "\n",
    "This Notebook shows example of different Post Processor options for writing metric result to storage, calling any external service, integration with other tools etc \n",
    "\n",
    "### About Dataset\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set . The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "Dataset source : https://archive.ics.uci.edu/dataset/53/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ML Observability Insights Library SDK\n",
    "\n",
    "- Prerequisites\n",
    "    - Linux/Mac (Intel CPU)\n",
    "    - Python 3.8 and 3.9 only\n",
    "\n",
    "\n",
    "- Installation\n",
    "    - MLM Insights is made available as a Python package (via Artifactory) which can be installed using pip install as shown below. Depending on the execution engine on which to do the run, one can use scoped package. For eg: if we want to run on dask, use mlm-insights[dask], for spark use mlm-insights[spark], for native use mlm-insights. One can install all the dependencies as use mlm-insights[all]\n",
    "\n",
    "      !pip install oracle-ml-insights\n",
    "\n",
    "Refer : [Installation and Setup](https://docs.oracle.com/en-us/iaas/tools/ml-insights-docs/latest/ml-insights-documentation/html/user_guide/tutorials/install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install oracle-ml-insights"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 ML Insights Imports "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-25T16:41:00.360558Z",
     "end_time": "2024-04-25T16:41:23.091951Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Import metrics\n",
    "from mlm_insights.core.features.feature import FeatureMetadata\n",
    "from mlm_insights.core.metrics.max import Max\n",
    "from mlm_insights.core.metrics.min import Min\n",
    "from mlm_insights.core.metrics.sum import Sum\n",
    "\n",
    "# Import dataset metrics\n",
    "from mlm_insights.core.metrics.rows_count import RowCount\n",
    "\n",
    "from mlm_insights.builder.builder_component import MetricDetail, EngineDetail\n",
    "from mlm_insights.constants.types import FeatureType, DataType, VariableType\n",
    "from mlm_insights.core.metrics.metric_metadata import MetricMetadata\n",
    "\n",
    "# import data reader\n",
    "from mlm_insights.core.data_sources import LocalDatePrefixDataSource\n",
    "from mlm_insights.mlm_native.readers import CSVNativeDataReader\n",
    "from mlm_insights.core.data_sources import OCIDatePrefixDataSource\n",
    "\n",
    "# import post processor \n",
    "from mlm_insights.core.post_processors.local_writer_post_processor import LocalWriterPostProcessor\n",
    "from mlm_insights.core.post_processors.object_storage_writer_post_processor import ObjectStorageWriterPostProcessor\n",
    "from mlm_insights.builder.insights_builder import InsightsBuilder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Configure Feature schema\n",
    "\n",
    "Feature Schema defines the structure and metadata of the input data, which includes data type, column type, column mapping . The framework, uses this information as the ground truth and any deviation in the actual data is taken as an anomaly and the framework usually will ignore such all such anomaly in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_schema():\n",
    "    return {\n",
    "        \"sepal length (cm)\": FeatureType(data_type=DataType.FLOAT, variable_type=VariableType.CONTINUOUS),\n",
    "        \"sepal width (cm)\": FeatureType(data_type=DataType.FLOAT, variable_type=VariableType.CONTINUOUS),\n",
    "        \"petal length (cm)\": FeatureType(data_type=DataType.FLOAT, variable_type=VariableType.CONTINUOUS),\n",
    "        \"petal width (cm)\": FeatureType(data_type=DataType.FLOAT, variable_type=VariableType.CONTINUOUS)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Configure Metrics\n",
    "\n",
    "Metrics are the core construct for the framework. This component is responsible for calculating all statistical metrics and algorithms. Metric components work based on the type of features (eg. input feature, output feature etc.) available, their data type (eg. int, float, string etc.) as well as additional context (e.g. if any previous computation is available to compare against). ML Insights provides commonly used metrics out of the box for different ML observability use cases.\n",
    "\n",
    "Refer : [Metrics Component Documentation](https://docs.oracle.com/en-us/iaas/tools/ml-insights-docs/latest/ml-insights-documentation/html/user_guide/getting_started/metrics_component.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    metrics = [\n",
    "               MetricMetadata(klass=Sum),\n",
    "               MetricMetadata(klass=Max),\n",
    "               MetricMetadata(klass=Min)\n",
    "              ]\n",
    "    uni_variate_metrics = {\n",
    "        \"sepal length (cm)\": metrics,\n",
    "        \"sepal width (cm)\": metrics,\n",
    "        \"petal length (cm)\": metrics,\n",
    "        \"petal width (cm)\": metrics\n",
    "    }\n",
    "    dataset_metrics = [MetricMetadata(klass=RowCount)]\n",
    "    metric_details = MetricDetail(univariate_metric=uni_variate_metrics,\n",
    "                                  dataset_metrics=dataset_metrics)\n",
    "    return metric_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Configure Data Reader\n",
    "\n",
    "Data Reader allows for ingestion of raw data into the framework. This component is primarily responsible for understanding different formats of data (e.g. jsonl, csv) etc. and how to properly read them. At its essence, the primary responsibility of this component is that given a set of valid file locations which represents file of a specific type, reader can properly decode the content and load them in memory.\n",
    "\n",
    "Additionally, Data Source component is an optional subcomponent, which is usually used along side the Reader. The primary responsibility of the data source component is to embed logic on filtering and partitioning of files to be read by the framework.\n",
    "\n",
    "Refer : [Data Reader Documentation](https://docs.oracle.com/en-us/iaas/tools/ml-insights-docs/latest/ml-insights-documentation/html/user_guide/getting_started/data_reader_component.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader():\n",
    "    data = {\n",
    "        \"file_type\": \"csv\",\n",
    "        \"date_range\": {\"start\": \"2023-06-24\", \"end\": \"2023-06-27\"}\n",
    "    }\n",
    "    base_location =\"input_data/iris_dataset\"\n",
    "    ds = LocalDatePrefixDataSource(base_location, **data)\n",
    "    print(ds.get_data_location())\n",
    "    csv_reader = CSVNativeDataReader(data_source=ds)\n",
    "    return csv_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Compute Metrics and Configure Post Processor Component\n",
    "\n",
    " ## Compute the Profile \n",
    "\n",
    "    - Create the builder object which provides core set of api, using which user can set the behavior of their monitoring. By selecting what components and variants to run all aspects of the monitoring task can be customised and configured. \n",
    "\n",
    "    - The run() method is responsible to run the internal workflow. It also handles the life cycle of each component passed, which includes creation (if required), invoking interface functions, destroying etc . Additionally, runner also handles some more advanced operations like thread pooling, compute engine abstraction etc.\n",
    "\n",
    "    Refer : [Builder Object Documentation](https://docs.oracle.com/en-us/iaas/tools/ml-insights-docs/latest/ml-insights-documentation/html/user_guide/getting_started/builder_object.html)\n",
    "    \n",
    " ## Post Processor Component\n",
    "\n",
    "    - Post processor components are responsible for running any action after the entire data is processed and all the metrics are calculated. They can be used for different purposes, like writing metric result to storage, calling any external service, integration with other tools etc. The interface of post processor is intentionally kept quite open ended for the same reason.\n",
    "\n",
    "    - Post processor components only have access to the final output of the framework (namely profile etc.) and do not have access to any of the input data. User can add multiple post processor component for their monitoring runs to the builder and they will all be executed.\n",
    "\n",
    "    - is_critical flag can be passed to a post processor. When set to true, Insights run is marked as failed when the post processor execution fails. By default the flag is set to False.\n",
    "\n",
    "    Refer : [Post Processor Component Documentation](https://docs.oracle.com/en-us/iaas/tools/ml-insights-docs/latest/ml-insights-documentation/html/user_guide/getting_started/getting_started.html#post-processor-component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Compute Metrics and Store the Profile in local Folder using LocalWriterPostProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    # Set up the insights builder by passing: input schema, metric, reader and engine details\n",
    "    runner = InsightsBuilder(). \\\n",
    "        with_input_schema(get_input_schema()). \\\n",
    "        with_metrics(metrics=get_metrics()). \\\n",
    "        with_reader(reader=get_reader()). \\\n",
    "        with_post_processors(post_processors=[LocalWriterPostProcessor(file_location=\"output_data/profiles\", file_name=\"profile_local_1.bin\", is_critical=False)]). \\\n",
    "        build()\n",
    "\n",
    "    # Run the evaluation\n",
    "    run_result = runner.run()\n",
    "    return run_result.profile\n",
    "    \n",
    "profile = main()\n",
    "profile.to_pandas()\n",
    "\n",
    "profile_json = profile.to_json()\n",
    "dataset_metrics = profile_json\n",
    "print(json.dumps(dataset_metrics,sort_keys=True, indent=4))\n",
    "pd.json_normalize(dataset_metrics).T.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Compute Metrics and Store the Profile in Object Storage using ObjectStorageWriterPostProcessor\n",
    "\n",
    "Need to enable OCI_RESOURCE_PRINCIPAL authentication for target object storage bucket to run the following in local system or in customer tenancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():    \n",
    "    # Set up the insights builder by passing: input schema, metric, data frame and engine details\n",
    "    runner = InsightsBuilder(). \\\n",
    "        with_input_schema(get_input_schema()). \\\n",
    "        with_metrics(metrics=get_metrics()). \\\n",
    "        with_reader(reader=get_reader()). \\\n",
    "        with_post_processors(post_processors=[ObjectStorageWriterPostProcessor(bucket_name=\"mlm-insights\", namespace=\"bigdatadatasciencelarge\", prefix=\"output/profiles\", object_name=\"profile_1.bin\", is_critical=False)]). \\\n",
    "        build()\n",
    "    # Other Insights components that can be configured are:\n",
    "    # - Custom Transformers (ability to transform incoming data frame to add/update/merge/delete/normalize etc features)\n",
    "    # - Conditional Features (ability to create new features from existing features using python expressions)\n",
    "    # - Tags (ability to provide custom metadata to be added as key-value pairs to a Profile)\n",
    "\n",
    "    # Run the evaluation\n",
    "    run_result = runner.run()\n",
    "    return run_result.profile\n",
    "    \n",
    "profile = main()\n",
    "profile.to_pandas()\n",
    "\n",
    "profile_json = profile.to_json()\n",
    "dataset_metrics = profile_json\n",
    "print(json.dumps(dataset_metrics,sort_keys=True, indent=4))\n",
    "pd.json_normalize(dataset_metrics).T.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Compute Metrics and Store the Profile in both Local folder and Object Storage \n",
    "\n",
    "Need to enable OCI_RESOURCE_PRINCIPAL authentication for target object storage bucket to run the following in local system or in customer tenancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    # Set up the insights builder by passing: input schema, metric, data frame and engine details\n",
    "    runner = InsightsBuilder(). \\\n",
    "        with_input_schema(get_input_schema()). \\\n",
    "        with_metrics(metrics=get_metrics()). \\\n",
    "        with_reader(reader=get_reader()). \\\n",
    "        with_post_processors(post_processors=[LocalWriterPostProcessor(file_location=\"output_data/profiles\", file_name=\"profile_local_2.bin\"),ObjectStorageWriterPostProcessor(bucket_name=\"mlm-insights\", prefix=\"output/profiles\", object_name=\"profile_2.bin\")]). \\\n",
    "        build()\n",
    "    # Other Insights components that can be configured are:\n",
    "    # - Custom Transformers (ability to transform incoming data frame to add/update/merge/delete/normalize etc features)\n",
    "    # - Conditional Features (ability to create new features from existing features using python expressions)\n",
    "    # - Tags (ability to provide custom metadata to be added as key-value pairs to a Profile)\n",
    "\n",
    "    # Run the evaluation\n",
    "    run_result = runner.run()\n",
    "    return run_result.profile\n",
    "    \n",
    "profile = main()\n",
    "profile.to_pandas()\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "profile_json = profile.to_json()\n",
    "dataset_metrics = profile_json\n",
    "print(json.dumps(dataset_metrics,sort_keys=True, indent=4))\n",
    "pd.json_normalize(dataset_metrics).T.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "06b89612a5e9c675d881f7c391886fce9eabd2126328a7f9c136f634c360fd8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}