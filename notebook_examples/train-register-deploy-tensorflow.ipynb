{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a613b4aa",
   "metadata": {},
   "source": [
    "@notebook{train-register-deploy-tensorflow.ipynb,\n",
    "    title: Train, Register, and Deploy a TensorFlow Model,\n",
    "    summary: Train, register, and deploy a TensorFlow model.,\n",
    "    developed_on: tensorflow28_p38_cpu_v1,\n",
    "    keywords: tensorflow, deploy model, register model, train model,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9674c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c86ea",
   "metadata": {},
   "source": [
    "<font color=gray>Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2022 Oracle, Inc.  All rights reserved.\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "</font>\n",
    "\n",
    "***\n",
    "# <font color=red>Train, Register, and Deploy a TensorFlow Model</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle Cloud Infrastructure Data Science Service Team </font></p>\n",
    "\n",
    "***\n",
    "\n",
    "## Overview:\n",
    "\n",
    "The `TensorFlowModel` class in Accelerated Data Science (ADS) is designed to allow you to rapidly get a model into production. The `.prepare()` method creates the model artifacts that are needed to deploy a functioning model without you having to configure it or write code. However, it does allow you to customize the `score.py` file as needed. Simulate a call to a deployed model with the `.verify()` method. This method calls the `load_model()` and `predict()` functions in the `score.py` file. Using `.verify()` allows you to debug your `score.py` file without having to deploy a model. The `.save()` method pushes your `TensorFlowModel` and the model artifacts to the model catalog. The `.deploy()` method deploys the model to a REST endpoint for you. Finally, the `.predict()` method allows you to call the endpoint to perform model inference.\n",
    "\n",
    "These simples steps take your trained TensorFlow model and pushes it to production with just a few lines of code.\n",
    "\n",
    "Compatible conda pack: [TensorFlow 2.8](https://docs.oracle.com/en-us/iaas/data-science/using/conda-tensor-fam.htm) for CPU on Python 3.8 (version 1.0)\n",
    "\n",
    "---\n",
    "\n",
    "## Contents:\n",
    "\n",
    "* <a href='#intro'>Introduction</a>\n",
    "    * <a href=\"#intro_dataset\">Dataset</a>\n",
    "* <a href='#create'>Create a TensorFlow Model</a>\n",
    "* <a href='#serialize'>TensorFlow Framework Serialization</a>\n",
    "    * <a href='#serialize_tensorflowmodel'>Create a TensorFlowModel</a>\n",
    "    * <a href='#serialize_prepare'>Prepare</a>\n",
    "    * <a href='#serialize_verify'>Verify</a>\n",
    "    * <a href='#serialize_save'>Save</a>\n",
    "    * <a href='#serialize_deploy'>Deploy</a>\n",
    "    * <a href='#serialize_predict'>Predict</a>\n",
    "* <a href='#clean_up'>Clean Up</a>\n",
    "* <a href='#ref'>References</a>    \n",
    "\n",
    "---\n",
    "\n",
    "Developed on [TensorFlow 2.7](https://docs.oracle.com/en-us/iaas/data-science/using/conda-tensor-fam.htm) for CPU on Python 3.7 (version 1.0)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* This notebook requires internet egress to download the sample dataset\n",
    "* This notebook requires authorization to work with the OCI Data Science Service. Details can be found [here](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html#). For the purposes of this notebook what is important to to know is that resource principals will be used absent api_key authentication.\n",
    "\n",
    "Datasets are provided as a convenience. Datasets are considered third-party content and are not considered materials under your agreement with Oracle.\n",
    "      \n",
    "The [`MNIST`](https://creativecommons.org/licenses/by/4.0/) dataset is used in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model.framework.tensorflow_model import TensorFlowModel\n",
    "from shutil import rmtree\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s:%(message)s\", level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962d183",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "\n",
    "Authentication to the OCI Data Science service is required. Here we default to resource principals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0dbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.set_auth(auth=\"resource_principal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1996e6",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "<a id=\"intro_dataset\"></a>\n",
    "## Dataset\n",
    "\n",
    "The [MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist) dataset is a collection of handwritten digits images that are centered and in a 20x20 area within a 28x28 pixel image. There are 60,000 training samples and 10,000 testing samples.\n",
    "\n",
    "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "Data in the MNIST come from two different databases where each database contributed equally to the training and test datasets. One dataset contains digits that are clear and relatively easy to recognize. In one of the datasets, there were 500 different writers and the writer's data was split such that a writer in the test set didn't have digits in the training set and the reverse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b72094",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "# Create a TensorFlow Model\n",
    "\n",
    "The next cell creates a `TFModel` class that loads in the MNIST data using a public internet connection. The data is then scaled to be between zero and one. To reduce the computational time needed to generate the model, only the first 10,000 training samples are used.\n",
    "\n",
    "The TensorFlow model has an input layer of 784 nodes (28x28), a single dense, hidden layer of 128 nodes with a RELU activation function. The output layer consists of 10 dense nodes, one for each of the ten possible digits. A 20% drop-out is used to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0fff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFModel:\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()  # Load data\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0  # Scale between 0 and 1\n",
    "    x_train, y_train = x_train[:10000], y_train[:10000]  # Reduce training data size\n",
    "\n",
    "    def training(self):\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Dense(10),\n",
    "            ]\n",
    "        )\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "        model.fit(self.x_train, self.y_train, epochs=1)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510e283",
   "metadata": {},
   "source": [
    "The next cell builds and trains the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFModel().training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774ca02",
   "metadata": {},
   "source": [
    "Once the model has been trained, you use the `.predict()` method to make predictions on a subset of the test dataset. Each prediction outputs ten values because there are ten nodes on the output layer. The node with the highest value is the digit that the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(TFModel().x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e404fd59",
   "metadata": {},
   "source": [
    "<a id='serialize'></a>\n",
    "# TensorFlow Framework Serialization\n",
    "\n",
    "The TensorFlow framework makes it easy to deploy a TensorFlow model into production. The `TensorFlowModel()` constructor takes a TensorFlow model and converts it into a `TensorFlowModel` object. To deploy the model into production, you must prepare the model artifact, verify that the artifact works, save the model to the model catalog, and then deploy it.\n",
    "\n",
    "ADS provides a number of methods that greatly simplify the model deployment process. It also provides the `.summary_status()` method that provides a dataframe that defines the steps, status, and detailed information about each step.Â \n",
    "\n",
    "<a id='serialize_tensorflowmodel'></a>\n",
    "## Create a TensorFlowModel\n",
    "\n",
    "In this notebook, a `keras.engine.sequential.Sequential` object is created. The `TensorFlowModel()` constructor takes the `keras.engine.sequential.Sequential` object along with the path that you want to use to store the model artifacts. A `TensorFlowModel` object is returned, and it's used to manage the deployment.\n",
    "\n",
    "The next cell creates a model artifact directory. This directory is used to store the artifacts that are needed to deploy the model. It also creates the `TensorFlowModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e676ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir = tempfile.mkdtemp()\n",
    "print(f\"Model artifact director: {artifact_dir}\")\n",
    "tf_model = TensorFlowModel(estimator=model, artifact_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f657958",
   "metadata": {},
   "source": [
    "The `.summary_status()` method of the `TensorFlowModel` class is a handy method to keep track of the progress that you are making in deploying the model. It creates a dataframe that lists the deployment steps, their status, and details about them. The next cell returns the summary status dataframe. It shows that the initiate step has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5245ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291bbae",
   "metadata": {},
   "source": [
    "<a id='serialize_prepare'></a>\n",
    "## Prepare\n",
    "\n",
    "The prepare step is performed by the `.prepare()` method of the `TensorFlowModel` class. It creates a number of customized files that are used to run the model once it is deployed. These include:\n",
    "\n",
    "* `input_schema.json`: A JSON file that defines the nature of the features of the `X_sample` data. It includes metadata such as the data type, name, constraints, summary statistics, feature type, and more.\n",
    "* `model.h5`: This is the default filename of the serialized model. You can change it with the `model_file_name` attribute. By default, the model is stored in an h5 file. You can use the `as_onnx` parameter to save the model in the ONNX format.\n",
    "* `output_schema.json`: A JSON file that defines the nature of the dependent variable in the `y_sample` data. It includes metadata such as the data type, name, constraints, summary statistics, feature type, and more.\n",
    "* `runtime.yaml`: This file contains information that is needed to set up the runtime environment on the deployment server. It has information about which conda environment was used to train the model, and what environment should be used to deploy the model. The file also specifies what version of Python should be used.\n",
    "* `score.py`: This script contains the `load_model()` and `predict()` functions. The `load_model()` function understands the format the model file was saved in, and loads it into memory. The `.predict()` method is used to make inferences in a deployed model. There are also hooks that allow you to perform operations before and after inference. You are able to modify this script to fit your specific needs.\n",
    "\n",
    "To create the model artifacts, you use the `.prepare()` method. There are a number of parameters that allow you to store model provenance information. In the next cell, the `conda_env` variable defines the slug of the conda environment that was used to train the model, and the conda environment to use for deployment. Note that you can only pass in slugs to `inference_conda_env` or `training_conda_env` if it's a service environment. Otherwise, you must pass in the full path of the conda environment along with the python version through `inference_python_version` and `training_python_version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_env = \"tensorflow28_p38_cpu_v1\"\n",
    "\n",
    "tf_model.prepare(\n",
    "    inference_conda_env=conda_env,\n",
    "    training_conda_env=conda_env,\n",
    "    use_case_type=UseCaseType.MULTINOMIAL_CLASSIFICATION,\n",
    "    X_sample=TFModel().x_test,\n",
    "    y_sample=TFModel().y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a9a7a",
   "metadata": {},
   "source": [
    "The next cell uses the `.summary_status()` method to show you that the prepare step finished, and what tasks were completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032b075",
   "metadata": {},
   "source": [
    "The `.prepare()` method has created the following fully functional files. However, you can modify them to fit your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaded56",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd7c30",
   "metadata": {},
   "source": [
    "Once the artifacts have been created, there are a number of attributes in the `TensorFlowModel` object that provide metadata about the model. The `.runtime` attribute details the model deployment settings and model provenance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1fc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.runtime_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efe27d",
   "metadata": {},
   "source": [
    "The `.schema_input` attribute provides metadata on the features that were used to train the model. You can use this information to determine what data must be provided to make model inferences. Each feature in the model has a section that defines the dtype, feature type, name, and if it is required. The metadata also includes the summary statistics associated with the feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.schema_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef1fa9",
   "metadata": {},
   "source": [
    "The `.metadata_custom` attribute provides custom metadata that contains information on the category of the metadata, description, key, and value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.metadata_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd9f7c",
   "metadata": {},
   "source": [
    "The `.metadata_provenance` contains information about the code and training data that was used to create the model. This information is most useful when a Git repository is being used to manage the code for training the model. This is considered a best practice because it allows you to do things like reproduce a model, perform forensic on the model, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42cfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.metadata_provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98d703",
   "metadata": {},
   "source": [
    "The `.metadata_taxonomy` is a key-value store that has information about the classification or taxonomy of the model. This can include information such as the model framework, use case type, hyperparameters, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.metadata_taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986c010",
   "metadata": {},
   "source": [
    "<a id='serialize_verify'></a>\n",
    "## Verify\n",
    "\n",
    "If you modify the `score.py` file that is part of the model artifacts, then you should verify it. The verify step allows you to test those changes without having to deploy the model. This allows you to debug your code without having to save the model to the model catalog, and then deploy it. The `.verify()` method takes a set of test parameters and performs the prediction by calling the `predict` function in `score.py`. It also runs the `load_model` function.\n",
    "\n",
    "The next cell simulates a call to a deployed model without having to actually deploy the model. It passes in test values and returns the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.verify(TFModel().x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3a8b8",
   "metadata": {},
   "source": [
    "Update the `.summary_status()` method to show that the verify step has been completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff7a78",
   "metadata": {},
   "source": [
    "<a id='serialize_save'></a>\n",
    "## Save\n",
    "\n",
    "Once you are satisfied with the performance of the model and have verified that the `score.py` file is working, you save the model to the model catalog. You do this with the `.save()` method on a `TensorFlowModel` object. This bundles up the model artifact that you have created, and deploys it to the model catalog. It returns the model OCID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d656dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = tf_model.save(display_name=\"Demo TensorFlowModel model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d293d",
   "metadata": {},
   "source": [
    "<a id='serialize_deploy'></a>\n",
    "## Deploy\n",
    "\n",
    "When the model is in the model catalog, you can use the `.deploy()` method of a `TensorFlowModel` object to deploy the model. This method allows you to specify the attributes of the deployment such as the display name, description, instance type and count, the maximum bandwidth, and logging groups. The next cell deploys the model with the default settings, except for the custom display name. The `.deploy()` method returns a `ModelDeployment` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy = tf_model.deploy(display_name=\"Demo TensorFlowModel deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b18b85",
   "metadata": {},
   "source": [
    "After deployment, the `.summary_status()` method shows that the model is `ACTIVE` and the `predict()` method is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc59f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9d077",
   "metadata": {},
   "source": [
    "<a id='serialize_predict'></a>\n",
    "## Predict\n",
    "\n",
    "In the <a href='#create'>Create a TensorFlow Model</a> section, you used the `model.predict()` method where `model` is an `ADSModel` object. This did the inference using the local model. Now that the `TensorFlowModel` model has been deployed, you can do the same thing using similar syntax with the `.predict()` method on a `TensorFlowModel`.\n",
    "\n",
    "After the deployment is active, you can call `predict()` on the `TensorFlowModel` object to send request to the deployed endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef240cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.predict(TFModel().x_test[0:1])[\"prediction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9964aa",
   "metadata": {},
   "source": [
    "<a id='clean_up'></a>\n",
    "# Clean Up\n",
    "\n",
    "This notebook created a model deployment and a model. This section deletes those resources. \n",
    "\n",
    "The model deployment must be deleted before the model can be deleted. You use the `.delete_deployment()` method on the `TensorFlowModel` object to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = tf_model.delete_deployment(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7698d9",
   "metadata": {},
   "source": [
    "After the model deployment has been deleted, the `.summary_status()` method shows that the model has been deleted and that the `predict()` method is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "430235b3",
   "metadata": {},
   "source": [
    "Use the `.delete()` method to delete the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60406cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a5000d",
   "metadata": {},
   "source": [
    "The next cell removes the model artifacts that were stored on your local drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d83fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd174f",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Understanding Conda Environments](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/use-notebook-sessions.htm#conda_understand_environments)\n",
    "- [Use Resource Manager to Configure Your Tenancy for Data Science](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/orm-configure-tenancy.htm)\n",
    "- [`runtime.yaml`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_runtime_yaml.htm#model_runtime_yaml)\n",
    "- [`score.py`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_score_py.htm#model_score_py)\n",
    "- [Model artifact](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/models_saving_catalog.htm#create-models)\n",
    "- [ONNX API Summary](http://onnx.ai/sklearn-onnx/api_summary.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
