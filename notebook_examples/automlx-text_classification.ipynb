{
 "cells": [
  {
   "cell_type": "raw",
   "id": "589d405a",
   "metadata": {},
   "source": [
    "@notebook{automlx-text_classification.ipynb,\n",
    "    title: Building and Explaining a Text Classifier using AutoMLx,\n",
    "    summary: build a classifier using the Oracle AutoMLx tool for the public 20newsgroup dataset,\n",
    "    developed_on: automlx234_p310_cpu_x86_64_v1,\n",
    "    keywords: automlx, text classification, text classifier,\n",
    "    license: Universal Permissive License v 1.0.,\n",
    "    original source: http://automl.oraclecorp.com/multiversion/v23.4.0/_static/notebooks/OracleAutoMLx_Classification_Text.ipynb\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ce5e0",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=red>Building and Explaining a Text Classifier using AutoMLx</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle AutoMLx Team </font></p>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b87c3",
   "metadata": {},
   "source": [
    "AutoMLx Fairness Demo version 23.4.1.\n",
    "\n",
    "Copyright © 2023, Oracle and/or its affiliates.\n",
    "\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e94d73",
   "metadata": {},
   "source": [
    "## Overview of this Notebook\n",
    "\n",
    "In this notebook we will build a classifier using the Oracle AutoMLx tool for the public 20newsgroup dataset. The dataset is a binary classification dataset, and more details about the dataset can be found at http://qwone.com/~jason/20Newsgroups/.\n",
    "We explore the various options provided by the Oracle AutoMLx tool, allowing the user to exercise control over the AutoMLx training process. We then evaluate the different models trained by AutoMLx. Finally we provide an overview of the possibilites that Oracle AutoMLx offers for explaining the predictions of the tuned model.\n",
    "\n",
    "---\n",
    "## Prerequisites\n",
    "\n",
    "  - Experience level: Novice (Python and Machine Learning)\n",
    "  - Professional experience: Some industry experience\n",
    "  \n",
    "Compatible conda pack: [Oracle AutoMLx v23.4 for CPU on Python 3.10 (version 1.0)](oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/Oracle_AutoMLx_v23.4_for_CPU_on_Python_3.10/1.0/automlx234_p310_cpu_x86_64_v1)\n",
    "\n",
    "---\n",
    "\n",
    "## Business Use\n",
    "\n",
    "Data analytics and modeling problems using Machine Learning (ML) are becoming popular and often rely on data science expertise to build accurate ML models. Such modeling tasks primarily involve the following steps:\n",
    "- Preprocess dataset (clean, impute, engineer features, normalize).\n",
    "- Pick an appropriate model for the given dataset and prediction task at hand.\n",
    "- Tune the chosen model’s hyperparameters for the given dataset.\n",
    "\n",
    "All of these steps are significantly time consuming and heavily rely on data scientist expertise. Unfortunately, to make this problem harder, the best feature subset, model, and hyperparameter choice widely varies with the dataset and the prediction task. Hence, there is no one-size-fits-all solution to achieve reasonably good model performance. Using a simple Python API, AutoMLx can quickly (faster) jump-start the datascience process with an accurately-tuned model and appropriate features for a given prediction task.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- <a href='#setup'>0. Setup</a>\n",
    "- <a href='#load-data'>1. Load the 20newsgroup Income dataset</a>\n",
    "- <a href='#AutoMLx'>2. AutoMLx</a>\n",
    "  - <a href='#Engine'>2.0. Set the engine and deprecation warnings</a>\n",
    "  - <a href='#provider'>2.1. Create an Instance of Oracle AutoMLx</a>\n",
    "  - <a href='#default'>2.2. Train a Model using AutoMLx</a>\n",
    "  - <a href='#analyze'>2.3. Analyze the AutoMLx optimization process </a>\n",
    "      - <a href='#algorithm-selection'>2.3.1. Algorithm Selection</a>\n",
    "      - <a href='#adaptive-sampling'>2.3.2. Adaptive Sampling</a>\n",
    "      - <a href='#feature-selection'>2.3.3. Feature Selection</a>\n",
    "      - <a href='#hyperparameter-tuning'>2.3.4. Hyperparameter Tuning</a>\n",
    "  - <a href='#timebudget'>2.4. Specify a time budget to AutoMLx</a>\n",
    "  - <a href='#scoringfn'>2.5. Specify a different scoring metric to AutoMLx</a>\n",
    "- <a href='#MLX'>3. Machine Learning Explainability (MLX)</a>\n",
    "  - <a href='#MLX-initialization'> 3.1. Initialize an MLExplainer</a>\n",
    "  - <a href='#MLX-global'> 3.2. Global Token Importance</a>\n",
    "  - <a href='#MLX-local'> 3.3. Local Token Importance</a>\n",
    "- <a href='#ref'>References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9d19b",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Setup\n",
    "\n",
    "Basic setup for the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476ece5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn==0.12.1 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from seaborn==0.12.1) (1.22.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from seaborn==0.12.1) (1.4.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from seaborn==0.12.1) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from pandas>=0.25->seaborn==0.12.1) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /home/datascience/conda/automlx234_p310_cpu_x86_64_v1/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn==0.12.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn==0.12.1\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889131f6",
   "metadata": {},
   "source": [
    "Load the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b71caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Settings for plots\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 7]\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "sns.set(color_codes=True)\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_palette(\"bright\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Deprecated automl check\n",
    "try:\n",
    "    import automl\n",
    "\n",
    "    print(\n",
    "        \"⚠️  The 'automl' module is no longer supported. Please update your conda environment to use latest supported version of AutoMLx to run this notebook.\"\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Recommended AutoMLx\n",
    "import automlx\n",
    "from automlx import init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81393c",
   "metadata": {},
   "source": [
    "<a id='load-data'></a>\n",
    "## Load the 20 News Group dataset\n",
    "We start by reading in the dataset from sklearn. The dataset has already been pre-split into training and test sets. The training set will be used to create a Machine Learning model using AutoMLx, and the test set will be used to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca77e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset=\"train\")\n",
    "test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "target_names = train.target_names\n",
    "\n",
    "X_train, y_train = pd.DataFrame(train.data), pd.DataFrame(train.target)\n",
    "X_test, y_test = pd.DataFrame(test.data), pd.DataFrame(test.target)\n",
    "\n",
    "column_names = [\"Message\"]\n",
    "X_train.columns = column_names\n",
    "X_test.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26832bc",
   "metadata": {},
   "source": [
    "Lets look at a few of the values in the data. 20 NewsGroup is a classification dataset made of text samples. Each sample has an associated class (also called topic), which can be one of the followings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a7462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82be92c",
   "metadata": {},
   "source": [
    "We display some examples of data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3aff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1c2459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba7355",
   "metadata": {},
   "source": [
    "We further downsample the train set to have a reasonable training time for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba51a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = train_test_split(\n",
    "    X_train, y_train, test_size=0.7, stratify=y_train, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67b1d0",
   "metadata": {},
   "source": [
    "Finally we generate a validation set and only use that for internal pipeline validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae06b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522d687",
   "metadata": {},
   "source": [
    "<a id='AutoMLx'></a>\n",
    "## AutoMLx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6403b7c",
   "metadata": {},
   "source": [
    "<a id='Engine'></a>\n",
    "### Setting the engine and deprecation warnings\n",
    "The AutoMLx pipeline offers the function `init`, which allows to initialize the parallelization engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-12 16:02:53,168] [automlx.backend] Overwriting ray session directory to /tmp/me6jse5t/ray, which will be deleted at engine shutdown. If you wish to retain ray logs, provide _temp_dir in ray_setup dict of engine_opts when initializing the AutoMLx engine.\n"
     ]
    }
   ],
   "source": [
    "init(engine=\"ray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1472e86",
   "metadata": {},
   "source": [
    "<a id='provider'></a>\n",
    "### Create an instance of Oracle AutoMLx\n",
    "\n",
    "The Oracle AutoMLx solution provides a pipeline that automatically finds a tuned model given a prediction task and a training dataset. In particular it allows to find a tuned model for any supervised prediction task, e.g. classification or regression where the target can be binary, categorical or real-valued.\n",
    "\n",
    "AutoMLx consists of five main modules:\n",
    "- **Preprocessing** (Feature extraction and selection) : The pipeline extracts tabular features using [TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) that it then selects between.\n",
    "- **Algorithm Selection** : Identify the right classification algorithm -in this notebook- for a given dataset, choosing from amongst:\n",
    "    - AdaBoostClassifier\n",
    "    - DecisionTreeClassifier\n",
    "    - ExtraTreesClassifier\n",
    "    - TorchMLPClassifier\n",
    "    - KNeighborsClassifier\n",
    "    - LGBMClassifier\n",
    "    - LinearSVC\n",
    "    - LogisticRegression\n",
    "    - RandomForestClassifier\n",
    "    - SVC\n",
    "    - XGBClassifier\n",
    "    - GaussianNB\n",
    "- **Adaptive Sampling** : Select a subset of the data samples for the model to be trained on.\n",
    "- **Feature Selection** : Select a subset of the features (extracted with TFIDF), based on the previously selected model. In the rest of this notebook, we will implicitly refer to the extracted features as data features.\n",
    "- **Hyperparameter Tuning** : Find the right model parameters that maximize score for the given dataset.\n",
    "\n",
    "All these pieces are readily combined into a simple AutoMLx pipeline which automates the entire Machine Learning process with minimal user input/interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c08f1",
   "metadata": {},
   "source": [
    "<a id='default'></a>\n",
    "### Train a model using AutoMLx\n",
    "\n",
    "The AutoMLx API is quite simple to work with. We create an instance of the pipeline. Next, the training data is passed to the `fit()` function which executes the three previously mentioned steps.\n",
    "\n",
    "A model is then generated and can be used for prediction tasks. We use the roc_auc scoring metric to evaluate the performance of this model on unseen data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b2b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-12 16:02:56,503] [automlx.interface] Dataset shape: (3394,1)\n",
      "[2024-01-12 16:02:56,670] [automlx.data_transform] Running preprocessing. Number of features: 2\n",
      "[2024-01-12 16:03:12,195] [automlx.data_transform] Preprocessing completed. Took 15.524 secs\n",
      "[2024-01-12 16:03:44,144] [automlx.process] Running Model Generation\n",
      "[2024-01-12 16:03:44,645] [automlx.process] CatBoostClassifier is disabled. The CatBoostClassifier model is only recommended for datasets with less than 10000 features.\n",
      "[2024-01-12 16:03:44,652] [automlx.process] ExtraTreesClassifier is disabled. The ExtraTreesClassifier model is only recommended for datasets with less than 10000 features.\n",
      "[2024-01-12 16:03:44,658] [automlx.process] KNeighborsClassifier is disabled. The KNeighborsClassifier model is only recommended for datasets with less than 10000 samples and 1000 features.\n",
      "[2024-01-12 16:03:44,665] [automlx.process] RandomForestClassifier is disabled. The RandomForestClassifier model is only recommended for datasets with less than 10000 features.\n",
      "[2024-01-12 16:03:44,668] [automlx.process] SVC is disabled. The SVC model is only recommended for datasets with less than 10000 samples and 1000 features.\n",
      "[2024-01-12 16:03:44,674] [automlx.process] XGBClassifier is disabled. The XGBClassifier model is only recommended for datasets with less than 5000 features.\n",
      "[2024-01-12 16:03:44,678] [automlx.process] LogisticRegressionClassifier is disabled. The LogisticRegressionClassifier model is only recommended for datasets with less than 5000 features.\n",
      "[2024-01-12 16:03:44,679] [automlx.process] Package torch is not installed. Removing models [<automlx._model.pytorch.mlp.TorchMLPClassifier object at 0x7f492edf7460>] from generated model list.\n",
      "[2024-01-12 16:03:44,680] [automlx.process] Model Generation completed.\n",
      "[2024-01-12 16:03:44,700] [automlx.model_selection] Running Model Selection\n",
      "[2024-01-12 16:04:24,958] [automlx.model_selection] Model Selection completed - Took 40.258 sec - Selected models: ['GaussianNB']\n",
      "[2024-01-12 16:04:25,006] [automlx.adaptive_sampling] Running Adaptive Sampling. Dataset shape: (3394,25239).\n",
      "[2024-01-12 16:04:26,951] [automlx.adaptive_sampling] Adaptive Sampling: top_limit: 144 < bottom_limit: 1000,\n",
      "sampling process will be skipped\n",
      "[2024-01-12 16:04:26,960] [automlx.adaptive_sampling] Adaptive Sampling: top_limit: 36 < bottom_limit: 1000,\n",
      "sampling process will be skipped\n",
      "[2024-01-12 16:04:27,041] [automlx.feature_selection] Starting feature ranking for Pipeline GaussianNB\n"
     ]
    }
   ],
   "source": [
    "est1 = automlx.Pipeline(task=\"classification\")\n",
    "est1.fit(X_train, y_train, X_valid, y_valid, col_types=[\"text\"])\n",
    "\n",
    "y_predict = est1.predict(X_test)\n",
    "score_default = f1_score(y_test, y_predict, average=\"micro\")\n",
    "\n",
    "print(\"F1 Micro Score on test data: {:3.3f}\".format(score_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633bd07",
   "metadata": {},
   "source": [
    "<a id='analyze'></a>\n",
    "### Analyze the AutoMLx optimization process\n",
    "\n",
    "During the AutoMLx process, a summary of the optimization process is logged. It consists of:\n",
    "- Information about the training data\n",
    "- Information about the AutoMLx Pipeline, such as:\n",
    "    - selected features that AutoMLx found to be most predictive in the training data;\n",
    "    - selected algorithm that was the best choice for this data;\n",
    "    - hyperparameters for the selected algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869de0e",
   "metadata": {},
   "source": [
    "AutoMLx provides a print_summary API to output all the different trials performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ed07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "est1.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988323f",
   "metadata": {},
   "source": [
    "We also provide the capability to visualize the results of each stage of the AutoMLx pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e3eb6",
   "metadata": {},
   "source": [
    "<a id='algorithm-selection'></a>\n",
    "#### Algorithm Selection\n",
    "\n",
    "The plot below shows the scores predicted by Algorithm Selection for each algorithm. The horizontal line shows the average score across all algorithms. Algorithms below the line are colored turquoise, whereas those with a score higher than the mean are colored teal. Here we can see that the `TorchMLPClassifier` achieved the highest predicted score (orange bar), and is chosen for subsequent stages of the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090690cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[\n",
    "    est1.completed_trials_summary_[\"Step\"].str.contains(\"Model Selection\")\n",
    "]\n",
    "name_of_score_column = f\"Score ({est1._inferred_score_metric[0].name})\"\n",
    "trials.dropna(subset=[name_of_score_column], inplace=True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "models = trials[\"Algorithm\"].tolist()\n",
    "colors = []\n",
    "\n",
    "y_margin = 0.10 * (max(scores) - min(scores))\n",
    "s = pd.Series(scores, index=models).sort_values(ascending=False)\n",
    "s = s.dropna()\n",
    "for f in s.keys():\n",
    "    if f.strip() == est1.selected_model_.strip():\n",
    "        colors.append(\"orange\")\n",
    "    elif s[f] >= s.mean():\n",
    "        colors.append(\"teal\")\n",
    "    else:\n",
    "        colors.append(\"turquoise\")\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Algorithm Selection Trials\")\n",
    "ax.set_ylim(min(scores) - y_margin, max(scores) + y_margin)\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "s.plot.bar(ax=ax, color=colors, edgecolor=\"black\")\n",
    "ax.axhline(y=s.mean(), color=\"black\", linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6138fa60",
   "metadata": {},
   "source": [
    "<a id='adaptive-sampling'></a>\n",
    "#### Adaptive Sampling\n",
    "\n",
    "Following Algorithm Selection, Adaptive Sampling aims to find the smallest dataset sample that can be created without compromising validation set score for the chosen model. Given the small size of the training data (948 samples), Adaptive Sampling is not relevant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a tuple of\n",
    "# (algorithm, no. samples, no. features, mean CV score, hyperparameters,\n",
    "# all CV scores, total CV time (s), memory usage (Gb))\n",
    "trials = est1.adaptive_sampling_trials_\n",
    "scores = [x[3] for x in trials]\n",
    "n_samples = [x[1] for x in trials]\n",
    "y_margin = 0.10 * (max(scores) - min(scores))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Adaptive Sampling ({})\".format(trials[0][0]))\n",
    "ax.set_xlabel(\"Dataset sample size\")\n",
    "ax.set_ylabel(est1.inferred_score_metric[0])\n",
    "ax.grid(color=\"g\", linestyle=\"-\", linewidth=0.1)\n",
    "ax.set_ylim(min(scores) - y_margin, max(scores) + y_margin)\n",
    "ax.plot(n_samples, scores, \"k:\", marker=\"s\", color=\"teal\", markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a65109",
   "metadata": {},
   "source": [
    "<a id='feature-selection'></a>\n",
    "#### Feature Selection\n",
    "After finding a sample subset, the next step is to find a relevant feature subset to maximize score for the chosen algorithm. The Feature Selection step identifies the smallest feature subset that does not compromise on the score of the chosen algorithm. The orange line shows the optimal number of features chosen by Feature Selection (in this case, retaining only about 4 000 of the more than 11 000 available words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[\n",
    "    est1.completed_trials_summary_[\"Step\"].str.contains(\"Feature Selection\")\n",
    "]\n",
    "trials.dropna(subset=[name_of_score_column], inplace=True)\n",
    "trials.sort_values(by=[\"# Features\"], ascending=True, inplace=True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "n_features = trials[\"# Features\"].tolist()\n",
    "\n",
    "y_margin = 0.10 * (max(scores) - min(scores))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Feature Selection Trials\")\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "ax.grid(color=\"g\", linestyle=\"-\", linewidth=0.1)\n",
    "ax.set_ylim(min(scores) - y_margin, max(scores) + y_margin)\n",
    "ax.plot(n_features, scores, \"k:\", marker=\"s\", color=\"teal\", markersize=3)\n",
    "ax.axvline(x=len(est1.selected_features_names_), color=\"orange\", linewidth=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab15ec8",
   "metadata": {},
   "source": [
    "<a id='hyperparameter-tuning'></a>\n",
    "#### Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter Tuning is the last stage of the AutoMLx pipeline, and focuses on improving the chosen algorithm's score on the reduced dataset (after Adaptive Sampling and Feature Selection). We use a novel algorithm to search across many hyperparameters dimensions, and converge automatically when optimal hyperparameters are identified. Each trial in the graph below represents a particular hyperparameters configuration for the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ad5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[\n",
    "    est1.completed_trials_summary_[\"Step\"].str.contains(\"Model Tuning\")\n",
    "]\n",
    "trials.dropna(subset=[name_of_score_column], inplace=True)\n",
    "trials.drop(trials[trials[\"Finished\"] == -1].index, inplace=True)\n",
    "trials[\"Finished\"] = trials[\"Finished\"].apply(\n",
    "    lambda x: time.mktime(\n",
    "        datetime.datetime.strptime(x, \"%a %b %d %H:%M:%S %Y\").timetuple()\n",
    "    )\n",
    ")\n",
    "trials.sort_values(by=[\"Finished\"], ascending=True, inplace=True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "score = []\n",
    "score.append(scores[0])\n",
    "for i in range(1, len(scores)):\n",
    "    if scores[i] >= score[i - 1]:\n",
    "        score.append(scores[i])\n",
    "    else:\n",
    "        score.append(score[i - 1])\n",
    "y_margin = 0.10 * (max(score) - min(score))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Hyperparameter Tuning Trials\")\n",
    "ax.set_xlabel(\"Iteration $n$\")\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "ax.grid(color=\"g\", linestyle=\"-\", linewidth=0.1)\n",
    "ax.set_ylim(min(score) - y_margin, max(score) + y_margin)\n",
    "ax.plot(range(1, len(trials) + 1), score, \"k:\", marker=\"s\", color=\"teal\", markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8e36d",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "### Advanced AutoMLx Configuration\n",
    "\n",
    "You can also configure the pipeline with suitable parameters according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4582f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline = automlx.Pipeline(\n",
    "    task=\"classification\",\n",
    "    model_list=[  # Specify the models you want the AutoMLx to consider\n",
    "        \"GaussianNB\",\n",
    "        \"LGBMClassifier\",\n",
    "    ],\n",
    "    min_features=1.0,  # Specify minimum features to force the model to use. It can take 3 possible types of values:\n",
    "    # If int, 0 < min_features <= n_features,\n",
    "    # If float, 0 < min_features <= 1.0, 1.0 means disabling feature selection\n",
    "    # If list, names of features to keep, for example ['a', 'b'] means keep features 'a' and 'b'\n",
    "    n_algos_tuned=2,  # Choose how many models to tune\n",
    "    adaptive_sampling=False,  # Disable or enable Adaptive Sampling step. Default to `True`\n",
    "    preprocessing=True,  # Disable or enable Preprocessing step. Default to `True`\n",
    "    search_space={},  # You can specify the hyper-parameters and ranges AutoMLx searches\n",
    "    max_tuning_trials=2,  # The maximum number of tuning trials. Can be integer or Dict (max number for each model)\n",
    "    score_metric=\"f1_macro\",  # Any scikit-learn metric or a custom function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9e0af",
   "metadata": {},
   "source": [
    "A few of the advanced settings can be passed directly to the pipeline's fit method, instead of its constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dfb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    col_types=[\"text\"],\n",
    "    time_budget=50,  # Specify time budget in seconds\n",
    "    cv=\"auto\",  # Automatically pick a good cross-validation (cv) strategy for the user's dataset.\n",
    "    # Ignored if X_valid and y_valid are provided.\n",
    "    # Can also be:\n",
    "    #   - An integer (for example, to use 5-fold cross validation)\n",
    "    #   - A list of data indices to use as splits (for advanced, such as time-based splitting)\n",
    ")\n",
    "y_proba = custom_pipeline.predict_proba(X_test)\n",
    "score_default = f1_score(y_test, y_predict, average=\"micro\")\n",
    "\n",
    "print(f\"Score on test data : {score_default}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c1302",
   "metadata": {},
   "source": [
    "<a id='MLX'></a>\n",
    "## Machine Learning Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b550e5",
   "metadata": {},
   "source": [
    "For a variety of decision-making tasks, getting only a prediction as model output is not sufficient. A user may wish to know why the model outputs that prediction, or which data features are relevant for that prediction. For that purpose the Oracle AutoMLx solution defines the MLExplainer object, which allows to compute a variety of model explanations\n",
    "\n",
    "<a id='MLX-initializing'></a>\n",
    "### Initializing an MLExplainer\n",
    "\n",
    "The MLExplainer object takes as argument the trained model, the training data and labels, as well as the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = automlx.MLExplainer(\n",
    "    est1,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    target_names=target_names,\n",
    "    task=\"classification\",\n",
    "    col_types=[\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f08536a",
   "metadata": {},
   "source": [
    "<a id='MLX-global'></a>\n",
    "### Model Explanations (Global Token Importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781e717",
   "metadata": {},
   "source": [
    "For text classification tasks, since we first extract tokens (features), the Oracle AutoMLx solution offers a single way to compute a notion of token importance: Global Token Importance. The notion of Global Token Importance intuitively measures how much a token impacts the model's predictions (relative to the provided train labels). This notion of token importance considers each token independently from all other tokens. Tokens are the most fine-grained building blocks of the NLP model, such as sentences, words, or characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdff106",
   "metadata": {},
   "source": [
    "#### Computing the importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5515bf",
   "metadata": {},
   "source": [
    "We use a permutation-based method to successively measure the importance of each token (feature). Such a method therefore runs in linear time with respect to the\n",
    "number of features (tokens) in the dataset. \n",
    "\n",
    "The method `explain_model()` allows to compute such feature importances. It also provides 95% confidence intervals for each token importance attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_model_default = explainer.explain_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48267a53",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44c732",
   "metadata": {},
   "source": [
    "There are two options to show the explanation's results:\n",
    "- `to_dataframe()` will return a dataframe of the results.\n",
    "- `show_in_notebook()` will show the results as a bar plot.\n",
    "\n",
    "The features are returned in decreasing order of importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cffbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_model_default.to_dataframe(n_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f304dc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "result_explain_model_default.show_in_notebook(n_tokens=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403d8ad",
   "metadata": {},
   "source": [
    "<a id='MLX-local'></a>\n",
    "## Local Token importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7f874",
   "metadata": {},
   "source": [
    "For text classification tasks, since we first extract tokens (features), the Oracle AutoMLx solution offers a single way to compute a notion of token importance: Local Token Importance. The notion of Local Token Importance intuitively measures how much a token impacts an instance's predictions (relative to the provided train labels). This notion of token importance considers each token independently from all other tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5512a",
   "metadata": {},
   "source": [
    "#### Compute the importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4dd541",
   "metadata": {},
   "source": [
    "By default we use a surrogate method to successively measure the importance of each token in a given instance. Such a method therefore runs in linear time with respect to the number of features in the dataset.\n",
    "\n",
    "The method `explain_prediction()` allows to compute such feature importances. It also provides 95% confidence intervals for each feature importance attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "result_explain_prediction_default = explainer.explain_prediction(\n",
    "    X_train.iloc[index : index + 1, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe982a8",
   "metadata": {},
   "source": [
    "There are two options to show the explanation's results:\n",
    " - `to_dataframe()` will return a dataframe of the results.\n",
    " - `show_in_notebook()` will show the results as a bar plot.\n",
    "\n",
    "The features are returned in decreasing order of importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3e4dc",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_prediction_default[0].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2162b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_prediction_default[0].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362cef69",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## References\n",
    "* More examples and details: http://automl.oraclecorp.com/\n",
    "* Oracle AutoMLx http://www.vldb.org/pvldb/vol13/p3166-yakovlev.pdf\n",
    "* scikit-learn https://scikit-learn.org/stable/\n",
    "* Interpretable Machine Learning https://christophm.github.io/interpretable-ml-book/\n",
    "* LIME https://arxiv.org/pdf/1602.04938\n",
    "* 20newsgroup http://qwone.com/~jason/20Newsgroups/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python [conda env:automlx234_p310_cpu_x86_64_v1]",
   "language": "python",
   "name": "conda-env-automlx234_p310_cpu_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
