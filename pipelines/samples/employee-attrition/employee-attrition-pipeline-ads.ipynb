{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8a4f0d9",
   "metadata": {},
   "source": [
    "# Employee attrition sample using ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10f732",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "import ads\n",
    "import os\n",
    "from os import environ\n",
    "from ads.catalog.project import ProjectCatalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d481be5",
   "metadata": {},
   "source": [
    "#### Make sure you are using ADS version 2.9.0 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e21ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'NB_SESSION_COMPARTMENT_OCID' in os.environ:\n",
    "    # using the notebook's compartment if running on OCI Data Science Notebook Session\n",
    "    compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "else:\n",
    "    # set the compartment OCID if you are working locally\n",
    "    compartment_id = '<YOUR_COMPARTMENT_OCID>'\n",
    "print('compartment OCID = ', compartment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will work whether working on a local machine (using API key) or in OCI Notebook Session (using Resource Principal)\n",
    "if \"OCI_RESOURCE_PRINCIPAL_VERSION\" in os.environ:\n",
    "    # Use resource principal\n",
    "    print(\"using Resource Principal for auth\")\n",
    "    ads.set_auth(auth=\"resource_principal\")\n",
    "else:\n",
    "    # Use api_key with config file\n",
    "    print(\"using API key for auth\")\n",
    "    ads.set_auth(auth=\"api_key\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there is access to the project and compartment\n",
    "pc = ProjectCatalog(compartment_id=compartment_id)\n",
    "pc.list_projects()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc038dc6",
   "metadata": {},
   "source": [
    "Fill in your resources details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464525b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = '<YOUR_PROJECT_ID>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_group_id = \"<YOUR_LOG_GROUP_ID>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32519399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "pipeline_name = f\"pipeline_sample_employee-attrition-{randrange(1000,9999)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.pipeline.ads_pipeline_step import PipelineStep\n",
    "from ads.pipeline.ads_pipeline import Pipeline\n",
    "from ads.pipeline import CustomScriptStep\n",
    "from ads.jobs import ScriptRuntime\n",
    "\n",
    "infrastructure = (\n",
    "    CustomScriptStep()\n",
    "    .with_block_storage_size(50)\n",
    "    .with_shape_name(\"VM.Standard2.4\")\n",
    ")\n",
    "\n",
    "step_data_processing = (\n",
    "    PipelineStep(\"data_processing\")\n",
    "    .with_description(\"Import data, feature engineering, train-test split\")\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_maximum_runtime_in_minutes(30)\n",
    "    .with_runtime(\n",
    "        ScriptRuntime()\n",
    "        .with_source(\"employee-attr-dataproc.zip\")\n",
    "        .with_service_conda(\"pypgx2340_p38_cpu_v1\")\n",
    "        .with_environment_variable(PIPELINE_STEP_RUN_ENTRYPOINT=\"employee-attr-dataproc.py\")\n",
    "    )\n",
    ")\n",
    "\n",
    "step_train_logistic_regression = (\n",
    "    PipelineStep(\"train_logistic_regression\")\n",
    "    .with_description(\"Train a Logistic Regression model and save to the model catalog with its AUC score\")\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_maximum_runtime_in_minutes(120)\n",
    "    .with_runtime(\n",
    "        ScriptRuntime()\n",
    "        .with_source(\"employee-attr-train-lr.zip\")\n",
    "        .with_service_conda(\"pypgx2340_p38_cpu_v1\")\n",
    "        .with_environment_variable(PIPELINE_STEP_RUN_ENTRYPOINT=\"employee-attr-train-lr.py\")\n",
    "    )\n",
    ")\n",
    "\n",
    "step_train_random_forest = (\n",
    "    PipelineStep(\"train_random_forest\")\n",
    "    .with_description(\"Train a Random Forest model and save to the model catalog with its AUC score\")\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_maximum_runtime_in_minutes(120)\n",
    "    .with_runtime(\n",
    "        ScriptRuntime()\n",
    "        .with_source(\"employee-attr-train-rf.zip\")\n",
    "        .with_service_conda(\"pypgx2340_p38_cpu_v1\")\n",
    "        .with_environment_variable(PIPELINE_STEP_RUN_ENTRYPOINT=\"employee-attr-train-rf.py\")\n",
    "    )\n",
    ")\n",
    "\n",
    "step_train_xgboost = (\n",
    "    PipelineStep(\"train_xgboost\")\n",
    "    .with_description(\"Train a model with XGBoost and save to the model catalog with its AUC score\")\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_maximum_runtime_in_minutes(120)\n",
    "    .with_runtime(\n",
    "        ScriptRuntime()\n",
    "        .with_source(\"employee-attr-train-xgb.zip\")\n",
    "        .with_service_conda(\"pypgx2340_p38_cpu_v1\")\n",
    "        .with_environment_variable(PIPELINE_STEP_RUN_ENTRYPOINT=\"employee-attr-train-xgb.py\")\n",
    "    )\n",
    ")\n",
    "\n",
    "step_evaluate_and_deploy = (\n",
    "    PipelineStep(\"evaluate_and_deploy\")\n",
    "    .with_description(\"Find the best model by their AUC score and deploy\")\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_maximum_runtime_in_minutes(30)\n",
    "    .with_runtime(\n",
    "        ScriptRuntime()\n",
    "        .with_source(\"employee-attr-eval-deploy.zip\")\n",
    "        .with_service_conda(\"pypgx2340_p38_cpu_v1\")\n",
    "        .with_environment_variable(PIPELINE_STEP_RUN_ENTRYPOINT=\"employee-attr-eval-deploy.py\")\n",
    "    )\n",
    ")\n",
    "\n",
    "pipeline = (\n",
    "    Pipeline(pipeline_name)\n",
    "    .with_compartment_id(compartment_id)\n",
    "    .with_project_id(project_id)\n",
    "    .with_log_group_id(log_group_id)  # if you define the LogGroupID but not the LogID, logs will be created automatically in the specified LogGroup\n",
    "    .with_freeform_tags({\"pipeline-sample\":\"employee-attrition-sample\"})\n",
    "    .with_step_details([step_data_processing, step_train_logistic_regression, step_train_random_forest, step_train_xgboost, step_evaluate_and_deploy])\n",
    "    .with_dag([\"data_processing >> (train_logistic_regression, train_random_forest, train_xgboost) >> evaluate_and_deploy\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f20c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the pipeline\n",
    "pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137ee71",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab985e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the configuration and the environment variables for the run\n",
    "pipeline_run_name = f\"pipeline-run-{randrange(1000,9999)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line and set to the OCI Object storage bucket to use for transferring data between the steps. Make sure permissions are properly set.\n",
    "#data_location = \"<YOUR_OBJECT_STORAGE_BUCKET>\"  # use: 'oci://<bucket>@<workspace>/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = pipeline.run(\n",
    "    display_name=pipeline_run_name,\n",
    "    configuration_override_details={\n",
    "        \"type\": \"DEFAULT\",\n",
    "        \"environment_variables\": {\n",
    "            \"DATA_LOCATION\": data_location,     # provide the data location to the run\n",
    "            \"SKIP_MODEL_DEPLOY\": \"True\"         # change to \"False\" to deploy the best model\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e629cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch the pipeline run status visually as it progresses (interrupt the kernel to stop watching)\n",
    "pipeline_run.show(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a686dd",
   "metadata": {},
   "source": [
    "## Run the pipeline from the console UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ctrl-Click the hyperlink to open the pipeline run page in the OCI console UI\")\n",
    "print(\"https://cloud.oracle.com/data-science/pipelines/{}/pipeline-runs\".format(pipeline.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71788396",
   "metadata": {},
   "source": [
    "#### Don't forget to set the environment varaibles when running the pipeline: DATA_LOCATION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
