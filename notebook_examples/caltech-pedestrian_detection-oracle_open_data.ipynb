{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@notebook{caltech-pedestrian_detection-oracle_open_data.ipynb,\n",
    "    title: Caltech Pedestrian Detection Benchmark Repository,\n",
    "    summary: Download and process annotated video data of vehicles and pedestrians.,\n",
    "    developed_on: generalml_p38_cpu_v1,\n",
    "    keywords: caltech, pedestrian detection, oracle open data,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6627d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2022 Oracle, Inc. All rights reserved. Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "\n",
    "***\n",
    "\n",
    "# <font color=red>Caltech Pedestrian Detection Benchmark Repository</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by <font color=\"teal\">Oracle for Research</font></p>\n",
    "\n",
    "---\n",
    "\n",
    "## Overview:\n",
    "\n",
    "The Caltech Pedestrian Detection Benchmark dataset consists of approximately 10 hours of 640x480 30Hz video taken from a vehicle driving through regular traffic in an urban environment. The data consists of about 250,000 frames in 137 approximately one-minute-long segments. There are approximately 350,000 bounding boxes and 2,300 unique pedestrians have been annotated. The annotation includes temporal correspondence between bounding boxes and detailed occlusion labels.\n",
    "\n",
    "This notebook demonstrates how to download the data from Oracle Cloud Infrastructure (OCI) Object Storage. It helps you understand the data and extract images from `.seq` files to a target folder.\n",
    "\n",
    "Compatible conda pack: [General Machine Learning](https://docs.oracle.com/iaas/data-science/using/conda-gml-fam.htm) for CPU on Python 3.8 (version 1.0)\n",
    "\n",
    "---\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href=\"#intro\">Introduction</a>\n",
    "    - <a href='#data'>Dataset</a>\n",
    "    - <a href=\"#open_data\">What is Oracle Open Data?</a>\n",
    "- <a href='#download'>Downloading Dataset</a>\n",
    "- <a href='#process'>Processing Raw Data</a>\n",
    "    - <a href='#metadata'>Extract Metadata</a>\n",
    "    - <a href='#image'>Extract Image Data</a>\n",
    "- <a href=\"#cleanup\">Clean Up</a>\n",
    "- <a href='#ref'>References</a>\n",
    "\n",
    "---\n",
    "\n",
    "Datasets are provided as a convenience. Datasets are considered third-party content and are not considered materials under your agreement with Oracle.\n",
    "    \n",
    "You can access the [Caltech Pedestrian Detection Benchmark](http://www.vision.caltech.edu/archive.html) dataset license [here](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import requests\n",
    "import struct\n",
    "import tarfile\n",
    "\n",
    "from os.path import join\n",
    "from shutil import rmtree\n",
    "from tempfile import mkdtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "<a id='data'></a>\n",
    "## Dataset\n",
    "\n",
    "**Data**: The dataset consists of training and testing data. The training data are in the set00 to set05 directories. The testing data are in the set06 to set10 directories. Both of which are about 1 GB and contain 6 to 13 one-minute-long `.seq` files along with annotation. Refer to the papers [Pedestrian Detection: An Evaluation of the State of the Art](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/PAMI12pedestrians.pdf) and [Pedestrian Detection: A Benchmark](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/CVPR09pedestrians.pdf) for more details.\n",
    "\n",
    "**Download Template**: `https://objectstorage.us-ashburn-1.oraclecloud.com/n/idcxvbiyd8fn/b/caltech/o/<tar file or res directory>/<zip file>`. For example, \n",
    "* https://objectstorage.us-ashburn-1.oraclecloud.com/n/idcxvbiyd8fn/b/caltech/o/set00.tar\n",
    "* https://objectstorage.us-ashburn-1.oraclecloud.com/n/idcxvbiyd8fn/b/caltech/o/res/AFS.zip\n",
    "\n",
    "**Directory Structure**: The training data and testing data are available in `.tar` files along with the annotation in `annotations.zip`. Output files containing detection results for all evaluated algorithms are available in the `res` directory.\n",
    "\n",
    "**Data Availability**: All data is available from the [Caltech Pedestrian Detection Benchmark repository](https://opendata.oraclecloud.com/ords/r/opendata/opendata/details?data_set_id=22), which is part of [Oracle Open Data](https://opendata.oraclecloud.com/ords/r/opendata/opendata/home).\n",
    "\n",
    "<a id=\"open_data\"></a>\n",
    "## What is Oracle Open Data?\n",
    "\n",
    "Oracle Open Data is a free service that curates spatial images, protein sequences, and annotated text files from the world's leading scientific databases. The repository connects researchers, developers, students, and educators with petabytes of open data from trusted resources. You can use Oracle Open Data to view important metadata and sample code for each data set, which simplifies technical complexities and makes it easy for researchers to use.\n",
    "\n",
    "<a id='download'></a>\n",
    "# Downloading the Dataset\n",
    "\n",
    "OCI Object Storage enables you to securely store any type of data in its native format. With built-in redundancy, Object Storage is ideal for building modern applications that require scale and flexibility because you can use it to consolidate multiple data sources for analytics, backup, or archive purposes.\n",
    "\n",
    "The Caltech pedestrian detection benchmark for video data are stored in Object Storage in the SEQ format. You can run the next cell to download and extract the files to a directory. Use training set `set00` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"set00\"\n",
    "seqs_url = f\"https://objectstorage.us-ashburn-1.oraclecloud.com/n/idcxvbiyd8fn/b/caltech/o/{dataset}.tar\"\n",
    "print(\"Downloading training data {}...\".format(dataset))\n",
    "response = requests.get(seqs_url, stream=True)\n",
    "file = tarfile.open(fileobj=response.raw, mode=\"r|tar\")\n",
    "data_path = mkdtemp()\n",
    "print(f\"Extracting data to {data_path}\")\n",
    "file.extractall(path=data_path)\n",
    "print(f\"Download complete in directory {join(data_path, dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='process'></a>\n",
    "# Processing Raw Data\n",
    "\n",
    "<a id='metadata'></a>\n",
    "## Extract Metadata\n",
    "\n",
    "Each `.seq` file is a series of concatenated image frames with a fixed-size header. Effectively, the format concatenates a collection of image files into a single file with predictable locations for each image within the file.\n",
    "\n",
    "The header in a `.seq` file contains metadata like `width` and `height` of the images, `imageBitDepth` for the color information, `imageSizeInBytes`, `numFrames` that represents the total number of frames in the file, `fps` that represents the frequency at which consecutive frames are captured. In particular, each `imageFormat` is mapped to a specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [\n",
    "    \"width\",\n",
    "    \"height\",\n",
    "    \"imageBitDepth\",\n",
    "    \"imageBitDepthReal\",\n",
    "    \"imageSizeInBytes\",\n",
    "    \"imageFormatCode\",\n",
    "    \"numFrames\",\n",
    "]\n",
    "\n",
    "image_format = {\n",
    "    1: \".png\",\n",
    "    2: \".png\",\n",
    "    100: \".raw\",\n",
    "    101: \".brgb8\",\n",
    "    102: \".jpg\",\n",
    "    103: \".jbrgb\",\n",
    "    200: \".raw\",\n",
    "    201: \".jpg\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_header` is defined in the next cell. This function will read header data for a given sequence file. It hoes this by skipping the file header, which is the first 548 bytes. It then parses the header. For details on how this is done, refer to the [official Matlab code](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/code/code3.2.1.zip) for details about this position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_seq = join(data_path, dataset, \"V000.seq\")\n",
    "HEADER_DATA_INDEX = 548\n",
    "\n",
    "\n",
    "def get_header(seq):\n",
    "    with open(seq, \"rb\") as seq_file:\n",
    "        header = {}\n",
    "        seq_file.seek(HEADER_DATA_INDEX)  # skip to actual data\n",
    "        for info in metadata:\n",
    "            header[info] = struct.unpack(\"I\", seq_file.read(4))[\n",
    "                0\n",
    "            ]  # take bytes and convert to integer\n",
    "        seq_file.read(4)  # skip next 4 bytes\n",
    "        header[\"trueImageSize\"] = struct.unpack(\"I\", seq_file.read(4))[0]\n",
    "        header[\"fps\"] = struct.unpack(\"d\", seq_file.read(8))[0]\n",
    "        return header\n",
    "\n",
    "\n",
    "example_header = get_header(example_seq)\n",
    "example_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='image'></a>\n",
    "## Extract Image Data\n",
    "\n",
    "Before you extract the image data you will need a directory to store the images. The following cell does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = join(data_path, dataset, \"images\")\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "    print(f\"{image_path} created to store images\")\n",
    "else:\n",
    "    print(f\"{image_path} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image data starts at the $1024^{th}$ byte in the `.seq` file. The function `output_images` reads the image data and saves images to the `image_path` directory. The `seq` parameter is the original data `.seq` file you download, and `header` is the returned map from `get_header` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATA_INDEX = 1024\n",
    "\n",
    "\n",
    "def output_images(seq, header):\n",
    "    with open(seq, \"rb\") as seq_file:\n",
    "        seq_file.seek(IMAGE_DATA_INDEX)  # skip to actual image data\n",
    "        for img_id in range(header[\"numFrames\"]):\n",
    "            img_size = struct.unpack(\"I\", seq_file.read(4))[0]\n",
    "            img_data = seq_file.read(img_size)\n",
    "            # map to the image format from the corresponding code\n",
    "            img_name = str(img_id) + image_format[header[\"imageFormatCode\"]]\n",
    "            # write image data to a specific path\n",
    "            path = os.path.join(image_path, img_name)\n",
    "            with open(path, \"wb\") as file:\n",
    "                file.write(bytearray(img_data))\n",
    "\n",
    "            seq_file.seek(12, 1)  # skip to next image\n",
    "        print(f\"{header['numFrames']} images were extracted to {image_path}\")\n",
    "\n",
    "\n",
    "output_images(example_seq, example_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(join(image_path, \"0.jpg\")))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "# Clean Up\n",
    "\n",
    "This notebook downloaded over a gigabyte of data. This section will delete those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Understanding Conda Environments](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/use-notebook-sessions.htm#conda_understand_environments)\n",
    "- [Use Resource Manager to Configure Your Tenancy for Data Science](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/orm-configure-tenancy.htm)\n",
    "- [Pedestrian Detection: An Evaluation of the State of the Art](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/PAMI12pedestrians.pdf)\n",
    "- [Pedestrian Detection: A Benchmark](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/CVPR09pedestrians.pdf)\n",
    "- [Description of SeqIo](https://pdollar.github.io/toolbox/videos/seqIo.html)\n",
    "- [Caltech Pedestrian Detection Benchmark Python Extractor](https://github.com/martinkersner/caltech-pedestrian-detection-benchmark-python-extractor)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
