{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9213a439-8504-4bfa-88a4-93033e2a9431",
   "metadata": {},
   "source": [
    "# Multi-Model Serving using OCI Data Science Model Groups\n",
    "\n",
    "This notebook walks through:\n",
    "- building SKlearn pipelines\n",
    "- version controling model artefacts with OCI Data Science \n",
    "- deploying SKlearn models to the OCI Data Science Model Catalog\n",
    "- deploying a single model to an OCI Data Science Model Deployment for real-time inference\n",
    "- creating a homogenous OCI Data Science Model Group \n",
    "- deploying the homogenous model group to a single OCI Data Science Model Deployment\n",
    "- perform live updates to the Model Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8d097-379f-4601-8320-7ee60d020473",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2720a52-3aa5-4038-9203-db8b3c560259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ads\n",
    "from ads.model import SklearnModel, ModelVersionSet\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ads.model import ModelVersionSet\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "import requests\n",
    "from oci.signer import Signer\n",
    "import pandas as pd\n",
    "ads.set_auth('resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6004715c-e53d-44a1-abb7-9ca47c21f003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.163.0\n"
     ]
    }
   ],
   "source": [
    "# note we need the latest version of OCI\n",
    "\n",
    "import oci\n",
    "\n",
    "print(oci.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60febd-6e05-4967-84cf-0b218ec74017",
   "metadata": {},
   "source": [
    "### Set Project Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67594649-162f-4ba9-bec1-0c64191ee9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = os.environ[\"PROJECT_OCID\"]\n",
    "compartment_id = os.environ[\"NB_SESSION_COMPARTMENT_OCID\"]\n",
    "access_log_group_id = \"ocid1.loggroup...\"\n",
    "log_id='ocid1.log...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e65832-c88a-4096-8b2b-0b01aa614618",
   "metadata": {},
   "source": [
    "### Make Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7517e167-7a0c-412b-8a72-be73f4507b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X, y = make_classification(random_state=0,n_samples=5000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e96f91-e183-42a7-adb0-4a4e51c09dcf",
   "metadata": {},
   "source": [
    "### Create OCI Data Science Model Version Set\n",
    "\n",
    "NOTE: This is optional but best practice for version control of individual model artefacts. It also makes it easy to fetch Model OCIDs via ADS when connecting in a new session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bc7ac-d896-43d5-ae75-697604293acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model version set\n",
    "mvs = ModelVersionSet(\n",
    "    name = \"model-group-demo-mvs\",\n",
    "    description = \"A model version set for the models in our model group\")\n",
    "mvs.with_compartment_id(compartment_id).with_project_id(project_id).create()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877b1f1-7dcf-4c64-b0e0-934319c8199e",
   "metadata": {},
   "source": [
    "### Create Separate SKLearn Model Pipelines and Upload to OCI Data Science Model Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9860f77-9658-4e7a-bb59-11818def7d18",
   "metadata": {},
   "source": [
    "#### Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93172d76-e9ba-46e9-86db-54d6612f1e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "pipe1 = pipe.set_params(svc__C=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3feede-2320-4e6c-a91b-7706c3bc04c2",
   "metadata": {},
   "source": [
    "We now need to save this pipeline to the OCI Data Science Model Catalog. We'll use the ADS SDK and add it to our model version set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c34e2fc-b6b1-4151-9c88-24035cdd7a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n"
     ]
    }
   ],
   "source": [
    "artifact_dir1 = \"/home/datascience/svm1\"\n",
    "sklearn_model1 = SklearnModel(estimator=pipe1, artifact_dir=artifact_dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb061921-7131-4300-bd29-75c1094eaed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages/ads/model/runtime/env_info.py:92: UserWarning: slug will be deprecated. Provide conda pack path instead., ?it/s]\n",
      "  warnings.warn(\"slug will be deprecated. Provide conda pack path instead.\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: Pipeline\n",
       "artifact_dir:\n",
       "  /home/datascience/svm1:\n",
       "  - - output_schema.json\n",
       "    - runtime.yaml\n",
       "    - test_json_output.json\n",
       "    - input_schema.json\n",
       "    - .model-ignore\n",
       "    - model.joblib\n",
       "    - score.py\n",
       "framework: scikit-learn\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model1.prepare(\n",
    "    inference_conda_env=\"generalml_p311_cpu_x86_64_v1\",\n",
    "    X_sample=X_train,\n",
    "    y_sample=y_train,\n",
    "    force_overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5997d69d-cd92-42df-ad04-59d86c736d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /home/datascience/svm1 ...\n",
      "Model is successfully loaded.\n",
      "['output_schema.json', 'runtime.yaml', 'test_json_output.json', 'input_schema.json', '.model-ignore', 'model.joblib', 'score.py']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.model.datascience_model:the JSON object must be str, bytes or bytearray, not Schema\n",
      "WARNING:ads.model.datascience_model:the JSON object must be str, bytes or bytearray, not Schema\n",
      "Saved Model 1 to Model Catalog\n"
     ]
    }
   ],
   "source": [
    "model_id1 = sklearn_model1.save(\n",
    "    display_name=\"SVM Demo 1\",\n",
    "    compartment_id=compartment_id,\n",
    "    model_version_set=mvs.id,\n",
    "    project_id=project_id\n",
    ")\n",
    "print(f\"Saved Model 1 to Model Catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b5650-e5ab-43b9-9f98-0eab8fcc63a0",
   "metadata": {},
   "source": [
    "#### Pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e847c7f-bc85-4a6b-9231-64aabd767ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "pipe2 = pipe.set_params(svc__C=9).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78492965-e173-4b7e-991e-b86f9c0d5858",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n"
     ]
    }
   ],
   "source": [
    "artifact_dir2 = \"/home/datascience/svm2\"\n",
    "sklearn_model2 = SklearnModel(estimator=pipe2, artifact_dir=artifact_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162b4843-6c1f-4d28-9161-0eb146b9b5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages/ads/model/runtime/env_info.py:92: UserWarning: slug will be deprecated. Provide conda pack path instead., ?it/s]\n",
      "  warnings.warn(\"slug will be deprecated. Provide conda pack path instead.\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: Pipeline\n",
       "artifact_dir:\n",
       "  /home/datascience/svm2:\n",
       "  - - output_schema.json\n",
       "    - runtime.yaml\n",
       "    - input_schema.json\n",
       "    - .model-ignore\n",
       "    - model.joblib\n",
       "    - score.py\n",
       "framework: scikit-learn\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model2.prepare(\n",
    "    inference_conda_env=\"generalml_p311_cpu_x86_64_v1\",\n",
    "    X_sample=X_train,\n",
    "    y_sample=y_train,\n",
    "    force_overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d4b9561-4789-4e39-94df-8d93064d053c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /home/datascience/svm2 ...\n",
      "Model is successfully loaded.\n",
      "['output_schema.json', 'runtime.yaml', 'input_schema.json', '.model-ignore', 'model.joblib', 'score.py']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.model.datascience_model:the JSON object must be str, bytes or bytearray, not Schema\n",
      "WARNING:ads.model.datascience_model:the JSON object must be str, bytes or bytearray, not Schema\n",
      "Saved Model 2 to Model Catalog\n"
     ]
    }
   ],
   "source": [
    "model_id2 = sklearn_model2.save(\n",
    "    display_name=\"SVM Demo 2\",\n",
    "    compartment_id=compartment_id,\n",
    "    model_version_set=mvs.id,\n",
    "    project_id=project_id\n",
    ")\n",
    "print(f\"Saved Model 2 to Model Catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a2414-54be-4aa5-9f29-ea8f0dc4534c",
   "metadata": {},
   "source": [
    "### Deploy Single Model Deployment Endpoint\n",
    "\n",
    "Here we show how to deploy a single model to a deployment endpoint using the `ADS SDK`. The benefit here is easy of use with a higher level of abstration. The drawback is that you need at least 1 OCPU per model deployment. Using Model Groups lets us be more cost-effective in our inference deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2da52-7ee3-4a4d-9cae-482b503de274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_model1.deploy(\n",
    "        display_name=\"SVM 1 Single Deployment Example\",\n",
    "        deployment_log_group_id=access_log_group_id,\n",
    "     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90f1e933-230e-4037-b4de-4e09747aa25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "x_sample = pd.DataFrame(X_test).head().to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f6fd6d-dedc-47ba-961f-214d12aad1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [1, 1, 1, 0, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "auth = Signer(\n",
    "  tenancy=config['tenancy'],\n",
    "  user=config['user'],\n",
    "  fingerprint=config['fingerprint'],\n",
    "  private_key_file_location=config['key_file'],\n",
    "  pass_phrase=config['pass_phrase'])\n",
    "\n",
    "endpoint = 'https://modeldeployment.../predict' # note we can get this dynamically from the .deploy() method\n",
    "body = x_sample \n",
    "headers = {} \n",
    "requests.post(endpoint, json=body, auth=auth, headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e5350-6d07-48ad-9295-ab2cf8c8f6b3",
   "metadata": {},
   "source": [
    "### Prepare Model Group Artefact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d21b2a-2fe8-4e97-b0e5-f51ba41b1858",
   "metadata": {},
   "source": [
    "This is a manual task where we create a `.zip` file containing a `score.py` and `runtime.yaml` file. For the homogenous deployment this uses a common scoring file to dynamically load the model in the model group and perform inference against it.\n",
    "\n",
    "NOTE: While you can use the `score.py` generated by ADS as the base for this, there are some minor changes that need to be made for this to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1228e-c610-4a95-a562-f9417c303635",
   "metadata": {},
   "source": [
    "Working `score.py` file:\n",
    "\n",
    "```\n",
    "# score.py 1.0 generated by ADS 2.11.19 on 20251107_103309\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import logging\n",
    "from joblib import load\n",
    "\n",
    "model_name = 'model.joblib'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Inference script. This script is used for prediction by scoring server when schema is known.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=10)\n",
    "def load_model(model_folder):\n",
    "    \"\"\"\n",
    "    Loads model from the serialized format\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model:  a model instance on which predict API can be invoked\n",
    "    \"\"\"\n",
    "    model_file_name = \"model.joblib\"\n",
    "    model_path = model_folder + '/' + model_file_name\n",
    "    print(f\"Model path is: {model_path}\")\n",
    "    if not os.path.exists(model_path):\n",
    "        error = \"Model Path doesn't exist : \" + model_path\n",
    "        print(f\"Model path does not exists: {model_path}\")\n",
    "        raise Exception(error)\n",
    "\n",
    "    # TODO: Load the model from the model_dir using the appropriate loader\n",
    "    # Below is a sample code to load a model file using `cloudpickle` which was serialized using `cloudpickle`\n",
    "    # from cloudpickle import cloudpickle\n",
    "    with open(model_path, \"rb\") as file:\n",
    "        model = load(file)\n",
    "\n",
    "    print(\"Model is successfully loaded\")\n",
    "    return model\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def fetch_data_type_from_schema(input_schema_path=os.path.join(os.path.dirname(os.path.realpath(__file__)), \"input_schema.json\")):\n",
    "    \"\"\"\n",
    "    Returns data type information fetch from input_schema.json.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_schema_path: path of input schema.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_type: data type fetch from input_schema.json.\n",
    "\n",
    "    \"\"\"\n",
    "    data_type = {}\n",
    "    if os.path.exists(input_schema_path):\n",
    "        schema = json.load(open(input_schema_path))\n",
    "        for col in schema['schema']:\n",
    "            data_type[col['name']] = col['dtype']\n",
    "    else:\n",
    "        print(\"input_schema has to be passed in in order to recover the same data type. pass `X_sample` in `ads.model.framework.sklearn_model.SklearnModel.prepare` function to generate the input_schema. Otherwise, the data type might be changed after serialization/deserialization.\")\n",
    "    return data_type\n",
    "\n",
    "def deserialize(data, input_schema_path):\n",
    "    \"\"\"\n",
    "    Deserialize json serialization data to data in original type when sent to predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: serialized input data.\n",
    "    input_schema_path: path of input schema.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: deserialized input data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, bytes):\n",
    "        logging.warning(\n",
    "            \"bytes are passed directly to the model. If the model expects a specific data format, you need to write the conversion logic in `deserialize()` yourself.\"\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    data_type = data.get('data_type', '') if isinstance(data, dict) else ''\n",
    "    json_data = data.get('data', data) if isinstance(data, dict) else data\n",
    "\n",
    "    if \"numpy.ndarray\" in data_type:\n",
    "        load_bytes = BytesIO(base64.b64decode(json_data.encode('utf-8')))\n",
    "        return np.load(load_bytes, allow_pickle=True)\n",
    "    if \"pandas.core.series.Series\" in data_type:\n",
    "        return pd.Series(json_data)\n",
    "    if \"pandas.core.frame.DataFrame\" in data_type or isinstance(json_data, str):\n",
    "        return pd.read_json(json_data, dtype=fetch_data_type_from_schema(input_schema_path))\n",
    "    if isinstance(json_data, dict):\n",
    "        return pd.DataFrame.from_dict(json_data)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "\n",
    "def pre_inference(data, input_schema_path):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Data format as expected by the predict API of the core estimator.\n",
    "    input_schema_path: path of input schema.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: Data format after any processing.\n",
    "\n",
    "    \"\"\"\n",
    "    data = deserialize(data, input_schema_path)\n",
    "    return data\n",
    "\n",
    "def post_inference(yhat):\n",
    "    \"\"\"\n",
    "    Post-process the model results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yhat: Data format after calling model.predict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    yhat: Data format after any processing.\n",
    "\n",
    "    \"\"\"\n",
    "    return yhat.tolist()\n",
    "\n",
    "def predict(data, model, input_schema_path=os.path.join(os.path.dirname(os.path.realpath(__file__)), \"input_schema.json\")):\n",
    "    \"\"\"\n",
    "    Returns prediction given the model and data to predict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Model instance returned by load_model API\n",
    "    data: Data format as expected by the predict API of the core estimator. For eg. in case of sckit models it could be numpy array/List of list/Pandas DataFrame\n",
    "    input_schema_path: path of input schema.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions: Output from scoring server\n",
    "        Format: {'prediction': output from model.predict method}\n",
    "\n",
    "    \"\"\"\n",
    "    input = pre_inference(data, input_schema_path)\n",
    "    yhat = post_inference(model.predict(input))\n",
    "    return {'prediction': yhat}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cfa84-521f-4bb9-be8f-b89baab0ea4c",
   "metadata": {},
   "source": [
    "Working `runtime.yaml` file:\n",
    "\n",
    "```\n",
    "MODEL_ARTIFACT_VERSION: '3.0'\n",
    "MODEL_DEPLOYMENT:\n",
    "  INFERENCE_CONDA_ENV:\n",
    "    INFERENCE_ENV_PATH: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/General_Machine_Learning_for_CPUs_on_Python_3.11/1.0/generalml_p311_cpu_x86_64_v1\n",
    "    INFERENCE_ENV_SLUG: generalml_p311_cpu_x86_64_v1\n",
    "    INFERENCE_ENV_TYPE: data_science\n",
    "    INFERENCE_PYTHON_VERSION: '3.11'\n",
    "MODEL_PROVENANCE:\n",
    "  PROJECT_OCID: ''\n",
    "  TENANCY_OCID: ''\n",
    "  TRAINING_CODE:\n",
    "    ARTIFACT_DIRECTORY: ''\n",
    "  TRAINING_COMPARTMENT_OCID: ''\n",
    "  TRAINING_CONDA_ENV:\n",
    "    TRAINING_ENV_PATH: ''\n",
    "    TRAINING_ENV_SLUG: ''\n",
    "    TRAINING_ENV_TYPE: ''\n",
    "    TRAINING_PYTHON_VERSION: ''\n",
    "  TRAINING_REGION: ''\n",
    "  TRAINING_RESOURCE_OCID: ''\n",
    "  USER_OCID: ''\n",
    "  VM_IMAGE_INTERNAL_ID: ''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70928d6-d377-4c68-b1a2-27ff56582605",
   "metadata": {},
   "source": [
    "Our working Zip file is saved as `model_group_artefact.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83f944-63b0-43b0-a626-bdb1cc3ed183",
   "metadata": {},
   "source": [
    "### Creating the Model Group\n",
    "\n",
    "As mentioned earlier in the notebook, Model Groups are a new offering on OCI Data Science and the ADS SDK has not added all features yet to it. Given this, we'll use the OCI SDK directly to build our Model Group and Model Group Deployment. The end result is the same, it just requires slightly more boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af11a035-0f8e-466c-a5d4-7367a4b3a32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsc = oci.data_science.DataScienceClient(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c95822d1-e882-4c89-9eb1-bf2d3b7df705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_model_group_response = dsc.create_model_group(\n",
    "    create_base_model_group_details=oci.data_science.models.CreateModelGroupDetails(\n",
    "        create_type=\"CREATE\",\n",
    "        compartment_id=compartment_id,\n",
    "        project_id=project_id,\n",
    "        model_group_details=oci.data_science.models.HomogeneousModelGroupDetails(\n",
    "            type=\"HOMOGENEOUS\"),\n",
    "        member_model_entries=oci.data_science.models.MemberModelEntries(\n",
    "            member_model_details=[\n",
    "                oci.data_science.models.MemberModelDetails(\n",
    "                    model_id=model_id1,\n",
    "                    inference_key=\"svm1\"),\n",
    "                    oci.data_science.models.MemberModelDetails(\n",
    "                    model_id=model_id2,\n",
    "                    inference_key=\"svm2\")]),\n",
    "        display_name=\"SVM-Model-Group\",\n",
    "        description=\"Example of creating a Homogenous Model Group on OCI Data Science\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75a33be7-d168-45a0-a474-a3a4127d811d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING\n"
     ]
    }
   ],
   "source": [
    "# Get the data from response\n",
    "print(create_model_group_response.data.lifecycle_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91de0b29-4a0f-4e5f-b951-f356eeeecd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_group_id = create_model_group_response.data.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f686959-e514-4467-9473-41d8b87bb9c2",
   "metadata": {},
   "source": [
    "### Upload the Model Group Artefact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0626c54-be60-4538-89ba-b085b47adb61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"/home/datascience/model_group_artefact.zip\"\n",
    "content_disposition = \"attachment;filename={}\".format(os.path.basename(file_name))\n",
    "\n",
    "with open(file_name, \"rb\") as f:\n",
    "    response = dsc.create_model_group_artifact(\n",
    "        model_group_id=model_group_id,\n",
    "        model_group_artifact=f,\n",
    "        content_disposition=content_disposition\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4577371d-19fd-41c0-abe2-0510f5a70d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "print(response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3daa300-ecdc-49ca-b19b-75c417b7eaf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Mon, 10 Nov 2025 15:47:39 GMT', 'opc-request-id': '0EEBB041CDBD43A5A0E742D4DB9BB01A/D4C91FDCB21207CC1B091269465241BC/8B7FA08D2EB36775E46F93271F4B97E6', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'ETag': 'bd3e734a-0fe6-4694-9c83-b0a22119891d', 'X-Content-Type-Options': 'nosniff, nosniff', 'Vary': 'Origin', 'Content-Type': 'application/json', 'Connection': 'close'}\n"
     ]
    }
   ],
   "source": [
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b55a5d-5307-435e-a2d1-13764bd52a04",
   "metadata": {},
   "source": [
    "### Create Model Group Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f16fb3c4-b767-4be7-8569-c5fc7786472a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Compute Shape \n",
    "instance_shape_config_details = oci.data_science.models.ModelDeploymentInstanceShapeConfigDetails(\n",
    "    memory_in_gbs=16,\n",
    "    ocpus=1\n",
    ")\n",
    "\n",
    "# Set Instance Type\n",
    "instance_configuration = oci.data_science.models.InstanceConfiguration(\n",
    "    instance_shape_name=\"VM.Standard.E4.Flex\",\n",
    "    model_deployment_instance_shape_config_details=instance_shape_config_details\n",
    ")\n",
    "\n",
    "# Set Scaling Policy\n",
    "scaling_policy = oci.data_science.models.FixedSizeScalingPolicy(\n",
    "    policy_type=\"FIXED_SIZE\",\n",
    "    instance_count=1  # Adjust as needed\n",
    ")\n",
    "\n",
    "# Set Instance Config Details\n",
    "infrastructure_config_details = oci.data_science.models.InstancePoolInfrastructureConfigurationDetails(\n",
    "    infrastructure_type=\"INSTANCE_POOL\",\n",
    "    instance_configuration=instance_configuration,\n",
    "    scaling_policy=scaling_policy\n",
    ")\n",
    "\n",
    "# Set Environment Details (NOTE: Change this to use BYOC option)\n",
    "environment_config_details = oci.data_science.models.DefaultModelDeploymentEnvironmentConfigurationDetails(\n",
    "    environment_configuration_type=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "# Set Model Group Details\n",
    "model_group_config_details = oci.data_science.models.ModelGroupConfigurationDetails(\n",
    "    model_group_id=model_group_id\n",
    ")\n",
    "\n",
    "# Set Model Group Deployment Details (infrastructure + model group)\n",
    "model_group_deployment_config_details = oci.data_science.models.ModelGroupDeploymentConfigurationDetails(\n",
    "    deployment_type=\"MODEL_GROUP\",\n",
    "    model_group_configuration_details=model_group_config_details,\n",
    "    infrastructure_configuration_details=infrastructure_config_details,\n",
    "    environment_configuration_details=environment_config_details\n",
    ")\n",
    "\n",
    "# Set logging details\n",
    "category_log_details = oci.data_science.models.CategoryLogDetails(\n",
    "    access=oci.data_science.models.LogDetails(\n",
    "        log_group_id=access_log_group_id,\n",
    "        log_id=log_id\n",
    "    ),\n",
    "    predict=oci.data_science.models.LogDetails(\n",
    "        log_group_id=access_log_group_id,\n",
    "        log_id=log_id\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create Model Deployment using above\n",
    "create_model_deployment_details = oci.data_science.models.CreateModelDeploymentDetails(\n",
    "    display_name='MMS SDK',\n",
    "    description='Test',\n",
    "    compartment_id=compartment_id,\n",
    "    project_id=project_id,\n",
    "    model_deployment_configuration_details=model_group_deployment_config_details,\n",
    "    category_log_details=category_log_details  # or omit entirely if logging not required\n",
    ")\n",
    "\n",
    "response = dsc.create_model_deployment(\n",
    "    create_model_deployment_details=create_model_deployment_details\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd718498-beee-4011-8235-fb41a215ab80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING\n"
     ]
    }
   ],
   "source": [
    "print(response.data.lifecycle_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "807f1575-1c76-4524-a00f-2abb7ebc5272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_group_deployment_url = response.data.model_deployment_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c68d27-16cc-4cbb-b64a-6799eda9018e",
   "metadata": {},
   "source": [
    "### Inference against Model Group Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71626fc2-abe2-42e8-ace0-ac0cc7dcd05e",
   "metadata": {},
   "source": [
    "#### Score Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec568490-a840-4809-af18-0f35b614841d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = model_group_deployment_url+'/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cca3d8a-b559-4098-a95f-71a173564189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [1, 1, 1, 0, 1]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = x_sample # we use same dataset as before\n",
    "headers = {'Content-Type':'application/json',\n",
    "          'opc-request-id':'test-id',\n",
    "          'model-key':'svm1'} # header goes here\n",
    "requests.post(endpoint, json=body, auth=auth, headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc5d53-970b-4c1a-9412-b849a8760bf4",
   "metadata": {},
   "source": [
    "#### Score Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "469c3e3c-8738-44f9-9765-ac40bee756b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [1, 1, 1, 0, 1]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'Content-Type':'application/json',\n",
    "          'opc-request-id':'test-id',\n",
    "          'model-key':'svm2'} # all we change is the model ocid\n",
    "\n",
    "requests.post(endpoint, json=body, auth=auth, headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecd05f-a4f7-4c6e-a569-fee173333501",
   "metadata": {},
   "source": [
    "### Live Updates to Model Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6edb5-10d1-4d7d-ab8c-c06e191078ca",
   "metadata": {},
   "source": [
    "One of the benefits of using Model Groups for Deployments is that they support live updates on the compute instance. Here we have a new Model Group (we could also use a Model Group Version Set) that we'll provide to update the live deployment. This requires no downtime for the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c13da5f-b388-4bfb-b591-8ce744d29d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_model_group_id = 'ocid1.datasciencemodelgroup...' # OCID for the new Model Group ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c29cfdf3-191d-4a93-ae1b-f319cc9d12ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_model_group_configuration_details = oci.data_science.models.UpdateModelGroupConfigurationDetails( model_group_id=update_model_group_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f46cace3-e516-49ed-8128-1eadb985cc14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_deployment_configuration_details = oci.data_science.models.UpdateModelGroupDeploymentConfigurationDetails(\n",
    " deployment_type=\"MODEL_GROUP\",\n",
    " update_type=\"LIVE\",\n",
    " model_group_configuration_details=update_model_group_configuration_details\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99767400-8133-483a-8f40-fa708f502f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_model_deployment_details = oci.data_science.models.UpdateModelDeploymentDetails(\n",
    " display_name=\"MMS SDK\",\n",
    " description=\"Live model update to deployment\",\n",
    " model_deployment_configuration_details=model_deployment_configuration_details\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02b505a8-c7f5-4551-8ec8-bb3cc34cdc88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update submitted. Status: 202\n"
     ]
    }
   ],
   "source": [
    "response = dsc.update_model_deployment(\n",
    " model_deployment_id=response.data.id, # from the model deployment response object above\n",
    " update_model_deployment_details=update_model_deployment_details\n",
    " ) \n",
    "print(\"Update submitted. Status:\", response.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189ffc1-c5eb-4c39-8b89-f92fa474be2b",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook we have shown how we can create, version and upload models to the OCI Data Science Model Catalog. From there we showed how we would traditionally deploy a model to a single deployment, and then how to take a more compute efficient approach with Model Groups and Multi-Model Serving. We are also able to make live updates to Model Deployments when using the Model Group option making ModelOps seamless in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p311_cpu_x86_64_v1]",
   "language": "python",
   "name": "conda-env-generalml_p311_cpu_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
