[
  {
    "developed_on": "automlx_p38_cpu_v2",
    "filename": "automlx-anomaly_detection.ipynb",
    "keywords": [
      "automlx",
      "anomaly detection"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_AnomalyDetection.ipynb",
    "size": 1817110,
    "summary": "Build an anomaly detection model using the experimental, fully unsupervised anomaly detection pipeline in Oracle AutoMLx for the public Credit Card Fraud dataset.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining an Anomaly Detector using AutoMLx - Experimental"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-classifier.ipynb",
    "keywords": [
      "automlx",
      "classification",
      "classifier"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Classification.ipynb",
    "size": 7045225,
    "summary": "Build a classifier using the Oracle AutoMLx tool and binary data set of Census income data.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining a Classifier using AutoMLx"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-fairness.ipynb",
    "keywords": [
      "automlx",
      "fairness"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Fairness.ipynb",
    "size": 5277687,
    "summary": "Develop a model and evaluate its fairness",
    "time_created": "2023-05-29T15:52:02",
    "title": "Fairness with AutoMLx"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-regression.ipynb",
    "keywords": [
      "automlx",
      "regression"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Regression.ipynb",
    "size": 7466599,
    "summary": "Build a regressor using Oracle AutoMLx and a pricing data set. Training options will be explored and the resulting AutoMLx models will be evaluated.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining a Regressor using AutoMLx"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-text_classification.ipynb",
    "keywords": [
      "automlx",
      "text classification",
      "text classifier"
    ],
    "license": "Universal Permissive License v 1.0.",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Classification_Text.ipynb",
    "size": 4614269,
    "summary": "build a classifier using the Oracle AutoMLx tool for the public 20newsgroup dataset",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building and Explaining a Text Classifier using AutoMLx"
  },
  {
    "developed_on": "computervision_p37_cpu_v1",
    "filename": "audi-autonomous_driving-oracle_open_data.ipynb",
    "keywords": [
      "autonomous driving",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19650,
    "summary": "Download, process and display autonomous driving data, and map LiDAR data onto images.",
    "time_created": "2023-03-30T09:13:20",
    "title": "Audi Autonomous Driving Dataset Repository"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "big_data_service-(BDS)-livy.ipynb",
    "keywords": [
      "bds",
      "big data service",
      "livy"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 46207,
    "summary": "Work interactively with a BDS cluster using Livy and two different connection techniques, SparkMagic (for a notebook environment) and with REST.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Using Livy on the Big Data Service"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "read-write-big_data_service-(BDS).ipynb",
    "keywords": [
      "bds",
      "fsspec"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 21304,
    "summary": "Manage data using fsspec file system. Read and save data using pandas and pyarrow through fsspec file system.",
    "time_created": "2023-03-29T11:04:51",
    "title": "How to Read Data with fsspec from Oracle Big Data Service (BDS)"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "caltech-pedestrian_detection-oracle_open_data.ipynb",
    "keywords": [
      "caltech",
      "pedestrian detection",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 15186,
    "summary": "Download and process annotated video data of vehicles and pedestrians.",
    "time_created": "2023-03-30T10:01:38",
    "title": "Caltech Pedestrian Detection Benchmark Repository"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "pyspark-data_catalog-hive_metastore-data_flow.ipynb",
    "keywords": [
      "data catalog metastore",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19211,
    "summary": "Write and test a Data Flow batch application using the Oracle Cloud Infrastructure (OCI) Data Catalog Metastore. Configure the job, run the application and clean up resources.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Using Data Catalog Metastore with DataFlow"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "data_labeling-text_classification.ipynb",
    "keywords": [
      "data labeling",
      "text classification"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 22443,
    "summary": "Use the Oracle Cloud Infrastructure (OCI) Data Labeling service to efficiently build enriched, labeled datasets for the purpose of accurately training AI/ML models. This notebook demonstrates operations that can be performed using the Advanced Data Science (ADS) Data Labeling module.",
    "time_created": "2023-03-30T10:01:38",
    "title": "Text Classification with Data Labeling Service Integration"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "visualizing_data-exploring_data.ipynb",
    "keywords": [
      "data visualization",
      "seaborn plot",
      "charts"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 20715,
    "summary": "Perform common data visualization tasks and explore data with the ADS SDK. Plotting approaches include 3D plots, pie chart, GIS plots, and Seaborn pairplot graphs.",
    "time_created": "2023-03-30T10:32:35",
    "title": "Visualizing Data"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "pyspark-data_catalog-hive_metastore.ipynb",
    "keywords": [
      "dcat",
      "data catalog metastore",
      "pyspark"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 17252,
    "summary": "Configure and use PySpark to process data in the Oracle Cloud Infrastructure (OCI) Data Catalog metastore, including common operations like creating and loading data from the metastore.",
    "time_created": "2023-03-30T10:32:35",
    "title": "Using Data Catalog Metastore with PySpark"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-other-frameworks.ipynb",
    "keywords": [
      "generic model",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 21028,
    "summary": "Train, register, and deploy a generic model",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a Generic Model"
  },
  {
    "developed_on": "pypgx2310_p38_cpu_v1",
    "filename": "graph_insight-autonomous_database.ipynb",
    "keywords": [
      "graph_insight",
      "autonomous_database"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 121229,
    "summary": "Access",
    "time_created": "2023-06-02T08:21:55",
    "title": "Bank Graph Example Notebook"
  },
  {
    "developed_on": "pytorch110_p38_cpu_v1",
    "filename": "train-register-deploy-huggingface-pipeline.ipynb",
    "keywords": [
      "huggingface",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 15957,
    "summary": "Train, register, and deploy a huggingface pipeline.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, register, and deploy HuggingFace Pipeline"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "hyperparameter_tuning.ipynb",
    "keywords": [
      "hyperparameter tuning"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 24693,
    "summary": "Use ADSTuner to optimize an estimator using the scikit-learn API",
    "time_created": "2023-03-30T10:01:38",
    "title": "Introduction to ADSTuner"
  },
  {
    "developed_on": "sklearnex202130_p37_cpu_v1",
    "filename": "accelerate-scikit_learn-with-intel_extension.ipynb",
    "keywords": [
      "intel",
      "intel extension",
      "scikit-learn",
      "scikit learn"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 9596,
    "summary": "Enhance performance of scikit-learn models using the Intel(R) oneAPI Data Analytics Library. Train a k-means model using both sklearn and the accelerated Intel library and compare performance.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Intel Extension for Scikit-Learn"
  },
  {
    "developed_on": "pyspark30_p37_cpu_v5",
    "filename": "big_data_service-(BDS)-kerberos.ipynb",
    "keywords": [
      "kerberos",
      "big data service",
      "bds"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 19691,
    "summary": "Connect to Oracle Big Data services using Kerberos.",
    "time_created": "2023-03-27T11:14:06",
    "title": "Connect to Oracle Big Data Service"
  },
  {
    "developed_on": "automlx_p38_cpu_v3",
    "filename": "automlx-forecasting.ipynb",
    "keywords": [
      "language services",
      "string manipulation",
      "regex",
      "regular expression",
      "natural language processing",
      "NLP",
      "part-of-speech tagging",
      "named entity recognition",
      "sentiment analysis",
      "custom plugins"
    ],
    "license": "Universal Permissive License v 1.0",
    "original_source": "https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Forecasting.ipynb",
    "size": 5638148,
    "summary": "Use Oracle AutoMLx to build a forecast model with real-world data sets.",
    "time_created": "2023-05-29T15:52:02",
    "title": "Building a Forecaster using AutoMLx"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "natural_language_processing.ipynb",
    "keywords": [
      "language services",
      "string manipulation",
      "regex",
      "regular expression",
      "natural language processing",
      "NLP",
      "part-of-speech tagging",
      "named entity recognition",
      "sentiment analysis",
      "custom plugins"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 36063,
    "summary": "Use the ADS SDK to process and manipulate strings. This notebook includes regular expression matching and natural language (NLP) parsing, including part-of-speech tagging, named entity recognition, and sentiment analysis. It also shows how to create and use custom plugins specific to your specific needs.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Natural Language Processing"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-lightgbm.ipynb",
    "keywords": [
      "lightgbm",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12216,
    "summary": "Train, register, and deploy a LightGBM model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a LightGBM Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "load_data-object_storage-hive-autonomous-database.ipynb",
    "keywords": [
      "loading data",
      "autonomous database",
      "adw",
      "hive",
      "pandas",
      "dask",
      "object storage"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 10007,
    "summary": "Load data from sources including ADW, Object Storage, and Hive in formats like parquet, csv etc",
    "time_created": "2023-03-26T22:51:01",
    "title": "Loading Data With Pandas & Dask"
  },
  {
    "developed_on": "dbexp_p38_cpu_v1",
    "filename": "model_version_set.ipynb",
    "keywords": [
      "model",
      "model experiments",
      "model version set"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 20067,
    "summary": "A model version set is a way to track the relationships between models. As a container, the model version set takes a collection of models. Those models are assigned a sequential version number based on the order they are entered into the model version set.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Introduction to Model Version Set"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "model_evaluation-with-ADSEvaluator.ipynb",
    "keywords": [
      "model evaluation",
      "binary classification",
      "regression",
      "multi-class classification",
      "imbalanced dataset",
      "synthetic dataset"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 35837,
    "summary": "Train and evaluate different types of models: binary classification using an imbalanced dataset, multi-class classification using a synthetically generated dataset consisting of three equally distributed classes, and a regression using a synthetically generated dataset with positive targets.",
    "time_created": "2023-03-30T10:45:38",
    "title": "Model Evaluation with ADSEvaluator"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "text_classification-model_explanation-lime.ipynb",
    "keywords": [
      "nlp",
      "lime",
      "model_explanation",
      "text_classification",
      "text_explanation"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 16325,
    "summary": "Perform model explanations on an NLP classifier using the locally interpretable model explanations technique (LIME).",
    "time_created": "2023-03-30T10:32:35",
    "title": "Text Classification and Model Explanations using LIME"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "genome_visualization-oracle_open_data.ipynb",
    "keywords": [
      "object annotation",
      "genome visualization",
      "oracle open data"
    ],
    "license": "Universal Permissive License v 1.0 (https://oss.oracle.com/licenses/upl/)",
    "size": 14739,
    "summary": "Load visual data, define regions, and visualize objects using metadata to connect structured images to language.",
    "time_created": "2023-03-30T10:01:38",
    "title": "Visual Genome Repository"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "pipelines-ml_lifecycle.ipynb",
    "keywords": [
      "pipelines",
      "pipeline step",
      "jobs pipeline"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 36342,
    "summary": "Create and use ML pipelines through the entire machine learning lifecycle",
    "time_created": "2023-03-26T22:51:01",
    "title": "Working with Pipelines"
  },
  {
    "developed_on": "pypgx2310_p38_cpu_v1",
    "filename": "pypgx-graph_analytics-machine_learning.ipynb",
    "keywords": [
      "pypgx",
      "graph analytics",
      "pgx"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 885240,
    "summary": "Use Oracle's Graph Analytics libraries to demonstrate graph algorithms, graph machine learning models, and use the property graph query language (PGQL)",
    "time_created": "2023-03-26T22:51:01",
    "title": "Graph Analytics and Graph Machine Learning with PyPGX"
  },
  {
    "developed_on": "pyspark24_p37_cpu_v3",
    "filename": "pyspark-data_flow-application.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13085,
    "summary": "Develop local PySpark applications and work with remote clusters using Data Flow.",
    "time_created": "2023-03-30T10:01:38",
    "title": "PySpark"
  },
  {
    "developed_on": "pyspark32_p38_cpu_v2",
    "filename": "pyspark-data_flow_studio-introduction.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 144930,
    "summary": "Run interactive Spark workloads on a long lasting Oracle Cloud Infrastructure Data Flow Spark cluster through Apache Livy integration. Data Flow Spark Magic is used for interactively working with remote Spark clusters through Livy, a Spark REST server, in Jupyter notebooks. It includes a set of magic commands for interactively running Spark code.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Introduction to the Oracle Cloud Infrastructure Data Flow Studio"
  },
  {
    "developed_on": "pyspark32_p38_cpu_v1",
    "filename": "pyspark-data_flow_studio-spark_nlp.ipynb",
    "keywords": [
      "pyspark",
      "data flow"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 17270,
    "summary": "Demonstrates how to use Spark NLP within a long lasting Oracle Cloud Infrastructure Data Flow cluster.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Spark NLP within Oracle Cloud Infrastructure Data Flow Studio"
  },
  {
    "developed_on": "pytorch110_p38_cpu_v1",
    "filename": "train-register-deploy-pytorch.ipynb",
    "keywords": [
      "pytorch",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 708060,
    "summary": "Train, register, and deploy a PyTorch model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a PyTorch Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-sklearn.ipynb",
    "keywords": [
      "scikit-learn",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 12896,
    "summary": "Train, register, and deploy an scikit-learn model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, register, and deploy Sklearn Model"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "sql_magic-commands-with-autonomous_database.ipynb",
    "keywords": [
      "sql magic",
      "autonomous database"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13044,
    "summary": "Use SQL Magic commands to work with a database within a Jupyter notebook. This notebook shows how to to use both line and cell magics.",
    "time_created": "2023-03-30T10:48:51",
    "title": "Introduction to SQL Magic"
  },
  {
    "developed_on": "dataexpl_p37_cpu_v3",
    "filename": "streaming-service-introduction.ipynb",
    "keywords": [
      "streaming",
      "kafka"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 97660,
    "summary": "Connect to Oracle Cloud Insfrastructure (OCI) Streaming service with kafka.",
    "time_created": "2023-03-30T10:32:35",
    "title": "Introduction to Streaming"
  },
  {
    "developed_on": "tensorflow28_p38_cpu_v1",
    "filename": "train-register-deploy-tensorflow.ipynb",
    "keywords": [
      "tensorflow",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 25991,
    "summary": "Train, register, and deploy a TensorFlow model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy a TensorFlow Model"
  },
  {
    "developed_on": "nlp_p37_cpu_v2",
    "filename": "document-text_extraction.ipynb",
    "keywords": [
      "text extraction",
      "nlp"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 249672,
    "summary": "Extract text from common formats (e.g. PDF and Word) into plain text. Customize this process for individual use cases.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Text Extraction Using the Accelerated Data Science (ADS) SDK"
  },
  {
    "developed_on": "generalml_p38_cpu_v1",
    "filename": "train-register-deploy-xgboost.ipynb",
    "keywords": [
      "xgboost",
      "deploy model",
      "register model",
      "train model"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 11999,
    "summary": "Train, register, and deploy an XGBoost model.",
    "time_created": "2023-03-26T22:51:01",
    "title": "Train, Register, and Deploy an XGBoost Model"
  },
  {
    "developed_on": "rapids2110_p37_gpu_v1",
    "filename": "xgboost-with-rapids.ipynb",
    "keywords": [
      "xgboost",
      "rapids",
      "gpu",
      "machine learning",
      "classification"
    ],
    "license": "Universal Permissive License v 1.0",
    "size": 13296,
    "summary": "Compare training time between CPU and GPU trained models using XGBoost",
    "time_created": "2023-03-30T10:01:38",
    "title": "XGBoost with RAPIDS"
  }
]